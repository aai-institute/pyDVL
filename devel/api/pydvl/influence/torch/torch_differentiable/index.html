
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
        <link rel="canonical" href="https://aai-institute.github.io/pyDVL/stable/api/pydvl/influence/torch/torch_differentiable/">
      
      
        <link rel="prev" href="../functional/">
      
      
        <link rel="next" href="../util/">
      
      
      <link rel="icon" href="../../../../../assets/signet.svg">
      <meta name="generator" content="mkdocs-1.5.2, mkdocs-material-9.2.6">
    
    
      
        <title>Torch differentiable - pyDVL</title>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/stylesheets/main.0e669242.min.css">
      
        
        <link rel="stylesheet" href="../../../../../assets/stylesheets/palette.85d0ee34.min.css">
      
      


    
    
      
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
      <link rel="stylesheet" href="../../../../../assets/_mkdocstrings.css">
    
      <link rel="stylesheet" href="../../../../../css/extra.css">
    
      <link rel="stylesheet" href="../../../../../css/neoteroi.css">
    
      <link rel="stylesheet" href="../../../../../css/ansi-colours.css">
    
      <link rel="stylesheet" href="../../../../../css/pandas-dataframe.css">
    
    <script>__md_scope=new URL("../../../../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
   <link href="../../../../../assets/stylesheets/glightbox.min.css" rel="stylesheet"/><style>
        html.glightbox-open { overflow: initial; height: 100%; }
        .gslide-title { margin-top: 0px; user-select: text; }
        .gslide-desc { color: #666; user-select: text; }
        .gslide-image img { background: white; }
        
            .gscrollbar-fixer { padding-right: 15px; }
            .gdesc-inner { font-size: 0.75rem; }
            body[data-md-color-scheme="slate"] .gdesc-inner { background: var(--md-default-bg-color);}
            body[data-md-color-scheme="slate"] .gslide-title { color: var(--md-default-fg-color);}
            body[data-md-color-scheme="slate"] .gslide-desc { color: var(--md-default-fg-color);}
            </style> <script src="../../../../../assets/javascripts/glightbox.min.js"></script></head>
  
  
    
    
      
    
    
    
    
    <body dir="ltr" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="indigo">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pydvl.influence.torch.torch_differentiable" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
        <aside class="md-banner">
          <div class="md-banner__inner md-grid md-typeset">
            
            
<div class="announcement">
    <aside class="announcement-content">
        pyDVL is in an early stage of development. Expect changes to functionality and the API until version 1.0.0.
    </aside>
</div>

          </div>
          
        </aside>
      
    </div>
    
      <div data-md-color-scheme="default" data-md-component="outdated" hidden>
        
      </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../../../../.." title="pyDVL" class="md-header__button md-logo" aria-label="pyDVL" data-md-component="logo">
      
  <img src="../../../../../assets/signet.svg" alt="logo">

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            pyDVL
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Torch differentiable
            
          </span>
        </div>
      </div>
    </div>
    
      
        <form class="md-header__option" data-md-component="palette">
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: light)" data-md-color-scheme="default" data-md-color-primary="teal" data-md-color-accent="indigo"  aria-label="Switch to dark mode"  type="radio" name="__palette" id="__palette_1">
    
      <label class="md-header__button md-icon" title="Switch to dark mode" for="__palette_2" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
    
    
    
    <input class="md-option" data-md-color-media="(prefers-color-scheme: dark)" data-md-color-scheme="slate" data-md-color-primary="teal" data-md-color-accent="indigo"  aria-label="Switch to light mode"  type="radio" name="__palette" id="__palette_2">
    
      <label class="md-header__button md-icon" title="Switch to light mode" for="__palette_1" hidden>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12c0-2.42-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12 20 8.69Z"/></svg>
      </label>
    
  
</form>
      
    
    
    
      <label class="md-header__button md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
        <div class="md-search__suggest" data-md-component="search-suggest"></div>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
      <div class="md-header__source">
        <a href="https://github.com/aai-institute/pyDVL" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    aai-institute/pyDVL
  </div>
</a>
      </div>
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    



<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../../../../.." title="pyDVL" class="md-nav__button md-logo" aria-label="pyDVL" data-md-component="logo">
      
  <img src="../../../../../assets/signet.svg" alt="logo">

    </a>
    pyDVL
  </label>
  
    <div class="md-nav__source">
      <a href="https://github.com/aai-institute/pyDVL" title="Go to repository" class="md-source" data-md-component="source">
  <div class="md-source__icon md-icon">
    
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
  </div>
  <div class="md-source__repository">
    aai-institute/pyDVL
  </div>
</a>
    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
  
  
  
    <li class="md-nav__item">
      <a href="../../../../.." class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Home
  </span>
  

      </a>
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
        
          <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Getting Started
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_2">
            <span class="md-nav__icon md-icon"></span>
            Getting Started
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../getting-started/installation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Installation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../getting-started/first-steps/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    First steps
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" >
        
          <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Data Valuation
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3">
            <span class="md-nav__icon md-icon"></span>
            Data Valuation
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../value/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../value/notation/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Notation
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../value/shapley/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shapley Values
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../value/semi-values/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Semi-values
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../value/the-core/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    The core
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_6" >
        
          <label class="md-nav__link" for="__nav_3_6" id="__nav_3_6_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Examples
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_3_6">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/shapley_basic_spotify/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Shapley values
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/shapley_knn_flowers/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    KNN Shapley
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/shapley_utility_learning/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Data utility learning
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/least_core_basic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Least Core
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
        
          <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    The Influence Function
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4">
            <span class="md-nav__icon md-icon"></span>
            The Influence Function
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../influence/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Introduction
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4_2" >
        
          <label class="md-nav__link" for="__nav_4_2" id="__nav_4_2_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Examples
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_4_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_4_2">
            <span class="md-nav__icon md-icon"></span>
            Examples
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/influence_imagenet/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    For CNNs
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/influence_synthetic/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    For mislabeled data
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../examples/influence_wine/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    For outlier detection
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
      
      
  
  
    
  
  
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" checked>
        
          <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
            
  
  <span class="md-ellipsis">
    Code
  </span>
  

            <span class="md-nav__icon md-icon"></span>
          </label>
        
        <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5">
            <span class="md-nav__icon md-icon"></span>
            Code
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../../../CHANGELOG/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Changelog
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    API
  </span>
  

            </a>
            
              <label class="md-nav__link " for="__nav_5_2">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_5_2_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_2">
            <span class="md-nav__icon md-icon"></span>
            API
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
    
  
  
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_1" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Influence
  </span>
  

            </a>
            
              <label class="md-nav__link " for="__nav_5_2_1">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_1_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_2_1">
            <span class="md-nav__icon md-icon"></span>
            Influence
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../general/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    General
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../inversion/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Inversion
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../twice_differentiable/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Twice differentiable
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    
    
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_1_4" checked>
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Torch
  </span>
  

            </a>
            
              <label class="md-nav__link " for="__nav_5_2_1_4">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_2_1_4_label" aria-expanded="true">
          <label class="md-nav__title" for="__nav_5_2_1_4">
            <span class="md-nav__icon md-icon"></span>
            Torch
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../functional/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Functional
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          
  
  <span class="md-ellipsis">
    Torch differentiable
  </span>
  

          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        
  
  <span class="md-ellipsis">
    Torch differentiable
  </span>
  

      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable" class="md-nav__link">
    torch_differentiable
  </a>
  
    <nav class="md-nav" aria-label="torch_differentiable">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable--references" class="md-nav__link">
    References
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable" class="md-nav__link">
    TorchTwiceDifferentiable
  </a>
  
    <nav class="md-nav" aria-label="TorchTwiceDifferentiable">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.parameters" class="md-nav__link">
    parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.num_params" class="md-nav__link">
    num_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.grad" class="md-nav__link">
    grad()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.hessian" class="md-nav__link">
    hessian()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.mvp" class="md-nav__link">
    mvp()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation" class="md-nav__link">
    LowRankProductRepresentation
  </a>
  
    <nav class="md-nav" aria-label="LowRankProductRepresentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation.to" class="md-nav__link">
    to()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities" class="md-nav__link">
    TorchTensorUtilities
  </a>
  
    <nav class="md-nav" aria-label="TorchTensorUtilities">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.einsum" class="md-nav__link">
    einsum()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.cat" class="md-nav__link">
    cat()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.stack" class="md-nav__link">
    stack()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.unsqueeze" class="md-nav__link">
    unsqueeze()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.lanzcos_low_rank_hessian_approx" class="md-nav__link">
    lanzcos_low_rank_hessian_approx()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.model_hessian_low_rank" class="md-nav__link">
    model_hessian_low_rank()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.solve_linear" class="md-nav__link">
    solve_linear()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.solve_batch_cg" class="md-nav__link">
    solve_batch_cg()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.solve_cg" class="md-nav__link">
    solve_cg()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.solve_lissa" class="md-nav__link">
    solve_lissa()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.solve_arnoldi" class="md-nav__link">
    solve_arnoldi()
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../util/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Util
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_2" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../reporting/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Reporting
  </span>
  

            </a>
            
              <label class="md-nav__link " for="__nav_5_2_2">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_2_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2_2">
            <span class="md-nav__icon md-icon"></span>
            Reporting
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../reporting/plots/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Plots
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../reporting/scores/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Scores
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../utils/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Utils
  </span>
  

            </a>
            
              <label class="md-nav__link " for="__nav_5_2_3">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2_3">
            <span class="md-nav__icon md-icon"></span>
            Utils
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/caching/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Caching
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/config/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Config
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/dataset/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Dataset
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/functional/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Functional
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/numeric/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Numeric
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/progress/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Progress
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/score/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Score
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/status/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Status
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/types/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Types
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/utility/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Utility
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_3_11" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../utils/parallel/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Parallel
  </span>
  

            </a>
            
              <label class="md-nav__link " for="__nav_5_2_3_11">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_2_3_11_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2_3_11">
            <span class="md-nav__icon md-icon"></span>
            Parallel
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/parallel/backend/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Backend
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/parallel/map_reduce/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Map reduce
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_3_11_3" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../utils/parallel/backends/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Backends
  </span>
  

            </a>
            
              <label class="md-nav__link " for="__nav_5_2_3_11_3">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_5_2_3_11_3_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2_3_11_3">
            <span class="md-nav__icon md-icon"></span>
            Backends
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/parallel/backends/joblib/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Joblib
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/parallel/backends/ray/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ray
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_3_11_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../utils/parallel/futures/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Futures
  </span>
  

            </a>
            
              <label class="md-nav__link " for="__nav_5_2_3_11_4">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="5" aria-labelledby="__nav_5_2_3_11_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2_3_11_4">
            <span class="md-nav__icon md-icon"></span>
            Futures
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../utils/parallel/futures/ray/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Ray
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_4" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../value/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Value
  </span>
  

            </a>
            
              <label class="md-nav__link " for="__nav_5_2_4">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="3" aria-labelledby="__nav_5_2_4_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2_4">
            <span class="md-nav__icon md-icon"></span>
            Value
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/result/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Result
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/sampler/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Sampler
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/semivalues/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Semivalues
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/stopping/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Stopping
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_4_5" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../value/least_core/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Least core
  </span>
  

            </a>
            
              <label class="md-nav__link " for="__nav_5_2_4_5">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_2_4_5_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2_4_5">
            <span class="md-nav__icon md-icon"></span>
            Least core
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/least_core/common/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Common
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/least_core/montecarlo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Montecarlo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/least_core/naive/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Naive
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_4_6" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../value/loo/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Loo
  </span>
  

            </a>
            
              <label class="md-nav__link " for="__nav_5_2_4_6">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_2_4_6_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2_4_6">
            <span class="md-nav__icon md-icon"></span>
            Loo
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/loo/loo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Loo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/loo/naive/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Naive
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
              
                
  
  
  
    
    
    
    <li class="md-nav__item md-nav__item--nested">
      
        
        
        
        
        <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5_2_4_7" >
        
          
          
          <div class="md-nav__link md-nav__container">
            <a href="../../../value/shapley/" class="md-nav__link ">
              
  
  <span class="md-ellipsis">
    Shapley
  </span>
  

            </a>
            
              <label class="md-nav__link " for="__nav_5_2_4_7">
                <span class="md-nav__icon md-icon"></span>
              </label>
            
          </div>
        
        <nav class="md-nav" data-md-level="4" aria-labelledby="__nav_5_2_4_7_label" aria-expanded="false">
          <label class="md-nav__title" for="__nav_5_2_4_7">
            <span class="md-nav__icon md-icon"></span>
            Shapley
          </label>
          <ul class="md-nav__list" data-md-scrollfix>
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/shapley/common/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Common
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/shapley/gt/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Gt
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/shapley/knn/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Knn
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/shapley/montecarlo/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Montecarlo
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/shapley/naive/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Naive
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/shapley/owen/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Owen
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/shapley/truncated/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Truncated
  </span>
  

      </a>
    </li>
  

              
            
              
                
  
  
  
    <li class="md-nav__item">
      <a href="../../../value/shapley/types/" class="md-nav__link">
        
  
  <span class="md-ellipsis">
    Types
  </span>
  

      </a>
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

              
            
          </ul>
        </nav>
      
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable" class="md-nav__link">
    torch_differentiable
  </a>
  
    <nav class="md-nav" aria-label="torch_differentiable">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable--references" class="md-nav__link">
    References
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable" class="md-nav__link">
    TorchTwiceDifferentiable
  </a>
  
    <nav class="md-nav" aria-label="TorchTwiceDifferentiable">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.parameters" class="md-nav__link">
    parameters
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.num_params" class="md-nav__link">
    num_params
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.grad" class="md-nav__link">
    grad()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.hessian" class="md-nav__link">
    hessian()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.mvp" class="md-nav__link">
    mvp()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation" class="md-nav__link">
    LowRankProductRepresentation
  </a>
  
    <nav class="md-nav" aria-label="LowRankProductRepresentation">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation.to" class="md-nav__link">
    to()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities" class="md-nav__link">
    TorchTensorUtilities
  </a>
  
    <nav class="md-nav" aria-label="TorchTensorUtilities">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.einsum" class="md-nav__link">
    einsum()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.cat" class="md-nav__link">
    cat()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.stack" class="md-nav__link">
    stack()
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.unsqueeze" class="md-nav__link">
    unsqueeze()
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.lanzcos_low_rank_hessian_approx" class="md-nav__link">
    lanzcos_low_rank_hessian_approx()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.model_hessian_low_rank" class="md-nav__link">
    model_hessian_low_rank()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.solve_linear" class="md-nav__link">
    solve_linear()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.solve_batch_cg" class="md-nav__link">
    solve_batch_cg()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.solve_cg" class="md-nav__link">
    solve_cg()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.solve_lissa" class="md-nav__link">
    solve_lissa()
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#pydvl.influence.torch.torch_differentiable.solve_arnoldi" class="md-nav__link">
    solve_arnoldi()
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  

  
  


  <h1>Torch differentiable</h1>

<div class="doc doc-object doc-module">



<a id="pydvl.influence.torch.torch_differentiable"></a>
  <div class="doc doc-contents first">
  
      <p>Contains methods for differentiating  a pyTorch model. Most of the methods focus
on ways to calculate matrix vector products. Moreover, it contains several
methods to invert the Hessian vector product. These are used to calculate the
influence of a training point on the model.</p>
<h3 id="pydvl.influence.torch.torch_differentiable--references">References<a class="headerlink" href="#pydvl.influence.torch.torch_differentiable--references" title="Permanent link">&para;</a></h3>
<div class="footnote">
<hr />
<ol>
<li id="pydvl.influence.torch.torch_differentiable--fn:1">
<p><a name="koh_liang_2017"></a>Koh, P.W., Liang, P., 2017.
<a href="https://proceedings.mlr.press/v70/koh17a.html">Understanding Black-box Predictions via Influence Functions</a>.
In: Proceedings of the 34th International Conference on Machine Learning, pp. 18851894. PMLR.&#160;<a class="footnote-backref" href="#pydvl.influence.torch.torch_differentiable--fnref:1" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="pydvl.influence.torch.torch_differentiable--fn:2">
<p><a name="agarwal_secondorder_2017"></a>Agarwal, N., Bullins, B., Hazan, E., 2017.
<a href="https://www.jmlr.org/papers/v18/16-491.html">Second-Order Stochastic Optimization for Machine Learning in Linear Time</a>.
In: Journal of Machine Learning Research, Vol. 18, pp. 140. JMLR.&#160;<a class="footnote-backref" href="#pydvl.influence.torch.torch_differentiable--fnref:2" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
</ol>
</div>

  

  <div class="doc doc-children">








<div class="doc doc-object doc-class">




<h2 id="pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable" class="doc doc-heading">
            <code class="highlight language-python"><span class="n">TorchTwiceDifferentiable</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span></code>

<a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="pydvl.influence.twice_differentiable.TwiceDifferentiable" href="../../twice_differentiable/#pydvl.influence.twice_differentiable.TwiceDifferentiable">TwiceDifferentiable</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code></p>

  
      <p>Wraps a <a class="autorefs autorefs-external" href="https://pytorch.org/docs/stable/generated/torch.nn.Module.html#torch.nn.Module">torch.nn.Module</a>
and a loss function and provides methods to compute gradients and
second derivative of the loss wrt. the model parameters</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>model</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A (differentiable) function.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><span title="torch.Module">Module</span></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>loss</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A differentiable scalar loss <span class="arithmatex">\( L(\hat{y}, y) \)</span>,
mapping a prediction and a target to a real value.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a>[[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, <a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>], <a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>

              <details class="quote">
                <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
                <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-64">64</a></span>
<span class="normal"><a href="#__codelineno-0-65">65</a></span>
<span class="normal"><a href="#__codelineno-0-66">66</a></span>
<span class="normal"><a href="#__codelineno-0-67">67</a></span>
<span class="normal"><a href="#__codelineno-0-68">68</a></span>
<span class="normal"><a href="#__codelineno-0-69">69</a></span>
<span class="normal"><a href="#__codelineno-0-70">70</a></span>
<span class="normal"><a href="#__codelineno-0-71">71</a></span>
<span class="normal"><a href="#__codelineno-0-72">72</a></span>
<span class="normal"><a href="#__codelineno-0-73">73</a></span>
<span class="normal"><a href="#__codelineno-0-74">74</a></span>
<span class="normal"><a href="#__codelineno-0-75">75</a></span>
<span class="normal"><a href="#__codelineno-0-76">76</a></span>
<span class="normal"><a href="#__codelineno-0-77">77</a></span>
<span class="normal"><a href="#__codelineno-0-78">78</a></span>
<span class="normal"><a href="#__codelineno-0-79">79</a></span>
<span class="normal"><a href="#__codelineno-0-80">80</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-64"><a id="__codelineno-0-64" name="__codelineno-0-64"></a><span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span>
</span><span id="__span-0-65"><a id="__codelineno-0-65" name="__codelineno-0-65"></a>    <span class="bp">self</span><span class="p">,</span>
</span><span id="__span-0-66"><a id="__codelineno-0-66" name="__codelineno-0-66"></a>    <span class="n">model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
</span><span id="__span-0-67"><a id="__codelineno-0-67" name="__codelineno-0-67"></a>    <span class="n">loss</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-68"><a id="__codelineno-0-68" name="__codelineno-0-68"></a><span class="p">):</span>
</span><span id="__span-0-69"><a id="__codelineno-0-69" name="__codelineno-0-69"></a>
</span><span id="__span-0-70"><a id="__codelineno-0-70" name="__codelineno-0-70"></a>    <span class="k">if</span> <span class="n">model</span><span class="o">.</span><span class="n">training</span><span class="p">:</span>
</span><span id="__span-0-71"><a id="__codelineno-0-71" name="__codelineno-0-71"></a>        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="__span-0-72"><a id="__codelineno-0-72" name="__codelineno-0-72"></a>            <span class="s2">&quot;Passed model not in evaluation mode. This can create several issues in influence &quot;</span>
</span><span id="__span-0-73"><a id="__codelineno-0-73" name="__codelineno-0-73"></a>            <span class="s2">&quot;computation, e.g. due to batch normalization. Please call model.eval() before &quot;</span>
</span><span id="__span-0-74"><a id="__codelineno-0-74" name="__codelineno-0-74"></a>            <span class="s2">&quot;computing influences.&quot;</span>
</span><span id="__span-0-75"><a id="__codelineno-0-75" name="__codelineno-0-75"></a>        <span class="p">)</span>
</span><span id="__span-0-76"><a id="__codelineno-0-76" name="__codelineno-0-76"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span>
</span><span id="__span-0-77"><a id="__codelineno-0-77" name="__codelineno-0-77"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">model</span> <span class="o">=</span> <span class="n">model</span>
</span><span id="__span-0-78"><a id="__codelineno-0-78" name="__codelineno-0-78"></a>    <span class="n">first_param</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">())</span>
</span><span id="__span-0-79"><a id="__codelineno-0-79" name="__codelineno-0-79"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">first_param</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-80"><a id="__codelineno-0-80" name="__codelineno-0-80"></a>    <span class="bp">self</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="n">first_param</span><span class="o">.</span><span class="n">dtype</span>
</span></code></pre></div></td></tr></table></div>
              </details>

  

  <div class="doc doc-children">







<div class="doc doc-object doc-attribute">




<h3 id="pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.parameters" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">parameters</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.parameters" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <span class="doc-returns-annotation">
                  <code><a class="autorefs autorefs-external" title="typing.List" href="https://docs.python.org/3/library/typing.html#typing.List">List</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code>
              </span>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>All model parameters that require differentiating.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>
  </div>

</div>

<div class="doc doc-object doc-attribute">




<h3 id="pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.num_params" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">num_params</span><span class="p">:</span> <span class="nb">int</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-property"><code>property</code></small>
  </span>

<a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.num_params" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Get the number of parameters of model f.</p>



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <code>int</code>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>Number of parameters.</p>
            </div>
              <p>
                <span class="doc-returns-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>
                </span>
              </p>
          </td>
        </tr>
    </tbody>
  </table>
  </div>

</div>




<div class="doc doc-object doc-function">




<h3 id="pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.grad" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.grad" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Calculates gradient of model parameters with respect to the model parameters.</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>x</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A matrix [NxD] representing the features <span class="arithmatex">\( x_i \)</span>.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>y</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A matrix [NxK] representing the target values <span class="arithmatex">\( y_i \)</span>.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>create_graph</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>If True, the resulting gradient tensor can be used for further differentiation.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>False</code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <span class="doc-returns-annotation">
                  <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
              </span>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>An array [P] with the gradients of the model.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-105">105</a></span>
<span class="normal"><a href="#__codelineno-0-106">106</a></span>
<span class="normal"><a href="#__codelineno-0-107">107</a></span>
<span class="normal"><a href="#__codelineno-0-108">108</a></span>
<span class="normal"><a href="#__codelineno-0-109">109</a></span>
<span class="normal"><a href="#__codelineno-0-110">110</a></span>
<span class="normal"><a href="#__codelineno-0-111">111</a></span>
<span class="normal"><a href="#__codelineno-0-112">112</a></span>
<span class="normal"><a href="#__codelineno-0-113">113</a></span>
<span class="normal"><a href="#__codelineno-0-114">114</a></span>
<span class="normal"><a href="#__codelineno-0-115">115</a></span>
<span class="normal"><a href="#__codelineno-0-116">116</a></span>
<span class="normal"><a href="#__codelineno-0-117">117</a></span>
<span class="normal"><a href="#__codelineno-0-118">118</a></span>
<span class="normal"><a href="#__codelineno-0-119">119</a></span>
<span class="normal"><a href="#__codelineno-0-120">120</a></span>
<span class="normal"><a href="#__codelineno-0-121">121</a></span>
<span class="normal"><a href="#__codelineno-0-122">122</a></span>
<span class="normal"><a href="#__codelineno-0-123">123</a></span>
<span class="normal"><a href="#__codelineno-0-124">124</a></span>
<span class="normal"><a href="#__codelineno-0-125">125</a></span>
<span class="normal"><a href="#__codelineno-0-126">126</a></span>
<span class="normal"><a href="#__codelineno-0-127">127</a></span>
<span class="normal"><a href="#__codelineno-0-128">128</a></span>
<span class="normal"><a href="#__codelineno-0-129">129</a></span>
<span class="normal"><a href="#__codelineno-0-130">130</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-105"><a id="__codelineno-0-105" name="__codelineno-0-105"></a><span class="k">def</span> <span class="nf">grad</span><span class="p">(</span>
</span><span id="__span-0-106"><a id="__codelineno-0-106" name="__codelineno-0-106"></a>    <span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">create_graph</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="__span-0-107"><a id="__codelineno-0-107" name="__codelineno-0-107"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-108"><a id="__codelineno-0-108" name="__codelineno-0-108"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-109"><a id="__codelineno-0-109" name="__codelineno-0-109"></a><span class="sd">    Calculates gradient of model parameters with respect to the model parameters.</span>
</span><span id="__span-0-110"><a id="__codelineno-0-110" name="__codelineno-0-110"></a>
</span><span id="__span-0-111"><a id="__codelineno-0-111" name="__codelineno-0-111"></a><span class="sd">    Args:</span>
</span><span id="__span-0-112"><a id="__codelineno-0-112" name="__codelineno-0-112"></a><span class="sd">        x: A matrix [NxD] representing the features \( x_i \).</span>
</span><span id="__span-0-113"><a id="__codelineno-0-113" name="__codelineno-0-113"></a><span class="sd">        y: A matrix [NxK] representing the target values \( y_i \).</span>
</span><span id="__span-0-114"><a id="__codelineno-0-114" name="__codelineno-0-114"></a><span class="sd">        create_graph (bool): If True, the resulting gradient tensor can be used for further differentiation.</span>
</span><span id="__span-0-115"><a id="__codelineno-0-115" name="__codelineno-0-115"></a>
</span><span id="__span-0-116"><a id="__codelineno-0-116" name="__codelineno-0-116"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-117"><a id="__codelineno-0-117" name="__codelineno-0-117"></a><span class="sd">        An array [P] with the gradients of the model.</span>
</span><span id="__span-0-118"><a id="__codelineno-0-118" name="__codelineno-0-118"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-119"><a id="__codelineno-0-119" name="__codelineno-0-119"></a>
</span><span id="__span-0-120"><a id="__codelineno-0-120" name="__codelineno-0-120"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-121"><a id="__codelineno-0-121" name="__codelineno-0-121"></a>    <span class="n">y</span> <span class="o">=</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-122"><a id="__codelineno-0-122" name="__codelineno-0-122"></a>
</span><span id="__span-0-123"><a id="__codelineno-0-123" name="__codelineno-0-123"></a>    <span class="k">if</span> <span class="n">create_graph</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">:</span>
</span><span id="__span-0-124"><a id="__codelineno-0-124" name="__codelineno-0-124"></a>        <span class="n">x</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">requires_grad_</span><span class="p">(</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-125"><a id="__codelineno-0-125" name="__codelineno-0-125"></a>
</span><span id="__span-0-126"><a id="__codelineno-0-126" name="__codelineno-0-126"></a>    <span class="n">loss_value</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">(</span><span class="n">x</span><span class="p">)),</span> <span class="n">torch</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</span><span id="__span-0-127"><a id="__codelineno-0-127" name="__codelineno-0-127"></a>    <span class="n">grad_f</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span>
</span><span id="__span-0-128"><a id="__codelineno-0-128" name="__codelineno-0-128"></a>        <span class="n">loss_value</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">parameters</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="n">create_graph</span>
</span><span id="__span-0-129"><a id="__codelineno-0-129" name="__codelineno-0-129"></a>    <span class="p">)</span>
</span><span id="__span-0-130"><a id="__codelineno-0-130" name="__codelineno-0-130"></a>    <span class="k">return</span> <span class="n">flatten_tensors_to_vector</span><span class="p">(</span><span class="n">grad_f</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h3 id="pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.hessian" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">hessian</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span></code>

<a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.hessian" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Calculates the explicit hessian of model parameters given data <span class="arithmatex">\(x\)</span> and <span class="arithmatex">\(y\)</span>.</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>x</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A matrix [NxD] representing the features <span class="arithmatex">\(x_i\)</span>.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>y</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A matrix [NxK] representing the target values <span class="arithmatex">\(y_i\)</span>.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <span class="doc-returns-annotation">
                  <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
              </span>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>A tensor representing the hessian of the loss with respect to the model parameters.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-132">132</a></span>
<span class="normal"><a href="#__codelineno-0-133">133</a></span>
<span class="normal"><a href="#__codelineno-0-134">134</a></span>
<span class="normal"><a href="#__codelineno-0-135">135</a></span>
<span class="normal"><a href="#__codelineno-0-136">136</a></span>
<span class="normal"><a href="#__codelineno-0-137">137</a></span>
<span class="normal"><a href="#__codelineno-0-138">138</a></span>
<span class="normal"><a href="#__codelineno-0-139">139</a></span>
<span class="normal"><a href="#__codelineno-0-140">140</a></span>
<span class="normal"><a href="#__codelineno-0-141">141</a></span>
<span class="normal"><a href="#__codelineno-0-142">142</a></span>
<span class="normal"><a href="#__codelineno-0-143">143</a></span>
<span class="normal"><a href="#__codelineno-0-144">144</a></span>
<span class="normal"><a href="#__codelineno-0-145">145</a></span>
<span class="normal"><a href="#__codelineno-0-146">146</a></span>
<span class="normal"><a href="#__codelineno-0-147">147</a></span>
<span class="normal"><a href="#__codelineno-0-148">148</a></span>
<span class="normal"><a href="#__codelineno-0-149">149</a></span>
<span class="normal"><a href="#__codelineno-0-150">150</a></span>
<span class="normal"><a href="#__codelineno-0-151">151</a></span>
<span class="normal"><a href="#__codelineno-0-152">152</a></span>
<span class="normal"><a href="#__codelineno-0-153">153</a></span>
<span class="normal"><a href="#__codelineno-0-154">154</a></span>
<span class="normal"><a href="#__codelineno-0-155">155</a></span>
<span class="normal"><a href="#__codelineno-0-156">156</a></span>
<span class="normal"><a href="#__codelineno-0-157">157</a></span>
<span class="normal"><a href="#__codelineno-0-158">158</a></span>
<span class="normal"><a href="#__codelineno-0-159">159</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-132"><a id="__codelineno-0-132" name="__codelineno-0-132"></a><span class="k">def</span> <span class="nf">hessian</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">y</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-133"><a id="__codelineno-0-133" name="__codelineno-0-133"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-134"><a id="__codelineno-0-134" name="__codelineno-0-134"></a><span class="sd">    Calculates the explicit hessian of model parameters given data \(x\) and \(y\).</span>
</span><span id="__span-0-135"><a id="__codelineno-0-135" name="__codelineno-0-135"></a>
</span><span id="__span-0-136"><a id="__codelineno-0-136" name="__codelineno-0-136"></a><span class="sd">    Args:</span>
</span><span id="__span-0-137"><a id="__codelineno-0-137" name="__codelineno-0-137"></a><span class="sd">        x: A matrix [NxD] representing the features \(x_i\).</span>
</span><span id="__span-0-138"><a id="__codelineno-0-138" name="__codelineno-0-138"></a><span class="sd">        y: A matrix [NxK] representing the target values \(y_i\).</span>
</span><span id="__span-0-139"><a id="__codelineno-0-139" name="__codelineno-0-139"></a>
</span><span id="__span-0-140"><a id="__codelineno-0-140" name="__codelineno-0-140"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-141"><a id="__codelineno-0-141" name="__codelineno-0-141"></a><span class="sd">        A tensor representing the hessian of the loss with respect to the model parameters.</span>
</span><span id="__span-0-142"><a id="__codelineno-0-142" name="__codelineno-0-142"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-143"><a id="__codelineno-0-143" name="__codelineno-0-143"></a>
</span><span id="__span-0-144"><a id="__codelineno-0-144" name="__codelineno-0-144"></a>    <span class="k">def</span> <span class="nf">model_func</span><span class="p">(</span><span class="n">param</span><span class="p">):</span>
</span><span id="__span-0-145"><a id="__codelineno-0-145" name="__codelineno-0-145"></a>        <span class="n">outputs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">functional_call</span><span class="p">(</span>
</span><span id="__span-0-146"><a id="__codelineno-0-146" name="__codelineno-0-146"></a>            <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-147"><a id="__codelineno-0-147" name="__codelineno-0-147"></a>            <span class="n">align_structure</span><span class="p">(</span>
</span><span id="__span-0-148"><a id="__codelineno-0-148" name="__codelineno-0-148"></a>                <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">p</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">},</span>
</span><span id="__span-0-149"><a id="__codelineno-0-149" name="__codelineno-0-149"></a>                <span class="n">param</span><span class="p">,</span>
</span><span id="__span-0-150"><a id="__codelineno-0-150" name="__codelineno-0-150"></a>            <span class="p">),</span>
</span><span id="__span-0-151"><a id="__codelineno-0-151" name="__codelineno-0-151"></a>            <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">),),</span>
</span><span id="__span-0-152"><a id="__codelineno-0-152" name="__codelineno-0-152"></a>            <span class="n">strict</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-153"><a id="__codelineno-0-153" name="__codelineno-0-153"></a>        <span class="p">)</span>
</span><span id="__span-0-154"><a id="__codelineno-0-154" name="__codelineno-0-154"></a>        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">loss</span><span class="p">(</span><span class="n">outputs</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device</span><span class="p">))</span>
</span><span id="__span-0-155"><a id="__codelineno-0-155" name="__codelineno-0-155"></a>
</span><span id="__span-0-156"><a id="__codelineno-0-156" name="__codelineno-0-156"></a>    <span class="n">params</span> <span class="o">=</span> <span class="n">flatten_tensors_to_vector</span><span class="p">(</span>
</span><span id="__span-0-157"><a id="__codelineno-0-157" name="__codelineno-0-157"></a>        <span class="n">p</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span> <span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="bp">self</span><span class="o">.</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">()</span> <span class="k">if</span> <span class="n">p</span><span class="o">.</span><span class="n">requires_grad</span>
</span><span id="__span-0-158"><a id="__codelineno-0-158" name="__codelineno-0-158"></a>    <span class="p">)</span>
</span><span id="__span-0-159"><a id="__codelineno-0-159" name="__codelineno-0-159"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">func</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">model_func</span><span class="p">)(</span><span class="n">params</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h3 id="pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.mvp" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">mvp</span><span class="p">(</span><span class="n">grad_xy</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">backprop_on</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable.mvp" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Calculates the second-order derivative of the model along directions v.
This second-order derivative can be selected through the <code>backprop_on</code> argument.</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>grad_xy</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>An array [P] holding the gradients of the model parameters with respect to input
<span class="arithmatex">\(x\)</span> and labels <span class="arithmatex">\(y\)</span>, where P is the number of parameters of the model.
It is typically obtained through <code>self.grad</code>.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>v</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>An array ([DxP] or even one-dimensional [D]) which multiplies the matrix,
where D is the number of directions.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>progress</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>If True, progress will be printed.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>False</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>backprop_on</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Tensor used in the second backpropagation
(the first one is defined via grad_xy).</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <span class="doc-returns-annotation">
                  <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
              </span>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>A matrix representing the implicit matrix-vector product of the model along the given directions.
The output shape is [DxM], with M being the number of elements of <code>backprop_on</code>.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-161">161</a></span>
<span class="normal"><a href="#__codelineno-0-162">162</a></span>
<span class="normal"><a href="#__codelineno-0-163">163</a></span>
<span class="normal"><a href="#__codelineno-0-164">164</a></span>
<span class="normal"><a href="#__codelineno-0-165">165</a></span>
<span class="normal"><a href="#__codelineno-0-166">166</a></span>
<span class="normal"><a href="#__codelineno-0-167">167</a></span>
<span class="normal"><a href="#__codelineno-0-168">168</a></span>
<span class="normal"><a href="#__codelineno-0-169">169</a></span>
<span class="normal"><a href="#__codelineno-0-170">170</a></span>
<span class="normal"><a href="#__codelineno-0-171">171</a></span>
<span class="normal"><a href="#__codelineno-0-172">172</a></span>
<span class="normal"><a href="#__codelineno-0-173">173</a></span>
<span class="normal"><a href="#__codelineno-0-174">174</a></span>
<span class="normal"><a href="#__codelineno-0-175">175</a></span>
<span class="normal"><a href="#__codelineno-0-176">176</a></span>
<span class="normal"><a href="#__codelineno-0-177">177</a></span>
<span class="normal"><a href="#__codelineno-0-178">178</a></span>
<span class="normal"><a href="#__codelineno-0-179">179</a></span>
<span class="normal"><a href="#__codelineno-0-180">180</a></span>
<span class="normal"><a href="#__codelineno-0-181">181</a></span>
<span class="normal"><a href="#__codelineno-0-182">182</a></span>
<span class="normal"><a href="#__codelineno-0-183">183</a></span>
<span class="normal"><a href="#__codelineno-0-184">184</a></span>
<span class="normal"><a href="#__codelineno-0-185">185</a></span>
<span class="normal"><a href="#__codelineno-0-186">186</a></span>
<span class="normal"><a href="#__codelineno-0-187">187</a></span>
<span class="normal"><a href="#__codelineno-0-188">188</a></span>
<span class="normal"><a href="#__codelineno-0-189">189</a></span>
<span class="normal"><a href="#__codelineno-0-190">190</a></span>
<span class="normal"><a href="#__codelineno-0-191">191</a></span>
<span class="normal"><a href="#__codelineno-0-192">192</a></span>
<span class="normal"><a href="#__codelineno-0-193">193</a></span>
<span class="normal"><a href="#__codelineno-0-194">194</a></span>
<span class="normal"><a href="#__codelineno-0-195">195</a></span>
<span class="normal"><a href="#__codelineno-0-196">196</a></span>
<span class="normal"><a href="#__codelineno-0-197">197</a></span>
<span class="normal"><a href="#__codelineno-0-198">198</a></span>
<span class="normal"><a href="#__codelineno-0-199">199</a></span>
<span class="normal"><a href="#__codelineno-0-200">200</a></span>
<span class="normal"><a href="#__codelineno-0-201">201</a></span>
<span class="normal"><a href="#__codelineno-0-202">202</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-161"><a id="__codelineno-0-161" name="__codelineno-0-161"></a><span class="nd">@staticmethod</span>
</span><span id="__span-0-162"><a id="__codelineno-0-162" name="__codelineno-0-162"></a><span class="k">def</span> <span class="nf">mvp</span><span class="p">(</span>
</span><span id="__span-0-163"><a id="__codelineno-0-163" name="__codelineno-0-163"></a>    <span class="n">grad_xy</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-164"><a id="__codelineno-0-164" name="__codelineno-0-164"></a>    <span class="n">v</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-165"><a id="__codelineno-0-165" name="__codelineno-0-165"></a>    <span class="n">backprop_on</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-166"><a id="__codelineno-0-166" name="__codelineno-0-166"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-167"><a id="__codelineno-0-167" name="__codelineno-0-167"></a>    <span class="n">progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-168"><a id="__codelineno-0-168" name="__codelineno-0-168"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-169"><a id="__codelineno-0-169" name="__codelineno-0-169"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-170"><a id="__codelineno-0-170" name="__codelineno-0-170"></a><span class="sd">    Calculates the second-order derivative of the model along directions v.</span>
</span><span id="__span-0-171"><a id="__codelineno-0-171" name="__codelineno-0-171"></a><span class="sd">    This second-order derivative can be selected through the `backprop_on` argument.</span>
</span><span id="__span-0-172"><a id="__codelineno-0-172" name="__codelineno-0-172"></a>
</span><span id="__span-0-173"><a id="__codelineno-0-173" name="__codelineno-0-173"></a><span class="sd">    Args:</span>
</span><span id="__span-0-174"><a id="__codelineno-0-174" name="__codelineno-0-174"></a><span class="sd">        grad_xy: An array [P] holding the gradients of the model parameters with respect to input</span>
</span><span id="__span-0-175"><a id="__codelineno-0-175" name="__codelineno-0-175"></a><span class="sd">            \(x\) and labels \(y\), where P is the number of parameters of the model.</span>
</span><span id="__span-0-176"><a id="__codelineno-0-176" name="__codelineno-0-176"></a><span class="sd">            It is typically obtained through `self.grad`.</span>
</span><span id="__span-0-177"><a id="__codelineno-0-177" name="__codelineno-0-177"></a><span class="sd">        v: An array ([DxP] or even one-dimensional [D]) which multiplies the matrix,</span>
</span><span id="__span-0-178"><a id="__codelineno-0-178" name="__codelineno-0-178"></a><span class="sd">            where D is the number of directions.</span>
</span><span id="__span-0-179"><a id="__codelineno-0-179" name="__codelineno-0-179"></a><span class="sd">        progress: If True, progress will be printed.</span>
</span><span id="__span-0-180"><a id="__codelineno-0-180" name="__codelineno-0-180"></a><span class="sd">        backprop_on: Tensor used in the second backpropagation</span>
</span><span id="__span-0-181"><a id="__codelineno-0-181" name="__codelineno-0-181"></a><span class="sd">            (the first one is defined via grad_xy).</span>
</span><span id="__span-0-182"><a id="__codelineno-0-182" name="__codelineno-0-182"></a>
</span><span id="__span-0-183"><a id="__codelineno-0-183" name="__codelineno-0-183"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-184"><a id="__codelineno-0-184" name="__codelineno-0-184"></a><span class="sd">        A matrix representing the implicit matrix-vector product of the model along the given directions.</span>
</span><span id="__span-0-185"><a id="__codelineno-0-185" name="__codelineno-0-185"></a><span class="sd">            The output shape is [DxM], with M being the number of elements of `backprop_on`.</span>
</span><span id="__span-0-186"><a id="__codelineno-0-186" name="__codelineno-0-186"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-187"><a id="__codelineno-0-187" name="__codelineno-0-187"></a>
</span><span id="__span-0-188"><a id="__codelineno-0-188" name="__codelineno-0-188"></a>    <span class="n">device</span> <span class="o">=</span> <span class="n">grad_xy</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-189"><a id="__codelineno-0-189" name="__codelineno-0-189"></a>    <span class="n">v</span> <span class="o">=</span> <span class="n">as_tensor</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">warn</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-190"><a id="__codelineno-0-190" name="__codelineno-0-190"></a>    <span class="k">if</span> <span class="n">v</span><span class="o">.</span><span class="n">ndim</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
</span><span id="__span-0-191"><a id="__codelineno-0-191" name="__codelineno-0-191"></a>        <span class="n">v</span> <span class="o">=</span> <span class="n">v</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">)</span>
</span><span id="__span-0-192"><a id="__codelineno-0-192" name="__codelineno-0-192"></a>
</span><span id="__span-0-193"><a id="__codelineno-0-193" name="__codelineno-0-193"></a>    <span class="n">z</span> <span class="o">=</span> <span class="p">(</span><span class="n">grad_xy</span> <span class="o">*</span> <span class="n">Variable</span><span class="p">(</span><span class="n">v</span><span class="p">))</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</span><span id="__span-0-194"><a id="__codelineno-0-194" name="__codelineno-0-194"></a>
</span><span id="__span-0-195"><a id="__codelineno-0-195" name="__codelineno-0-195"></a>    <span class="n">mvp</span> <span class="o">=</span> <span class="p">[]</span>
</span><span id="__span-0-196"><a id="__codelineno-0-196" name="__codelineno-0-196"></a>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">maybe_progress</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">z</span><span class="p">)),</span> <span class="n">progress</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;MVP&quot;</span><span class="p">):</span>
</span><span id="__span-0-197"><a id="__codelineno-0-197" name="__codelineno-0-197"></a>        <span class="n">mvp</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
</span><span id="__span-0-198"><a id="__codelineno-0-198" name="__codelineno-0-198"></a>            <span class="n">flatten_tensors_to_vector</span><span class="p">(</span>
</span><span id="__span-0-199"><a id="__codelineno-0-199" name="__codelineno-0-199"></a>                <span class="n">autograd</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">z</span><span class="p">[</span><span class="n">i</span><span class="p">],</span> <span class="n">backprop_on</span><span class="p">,</span> <span class="n">retain_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-200"><a id="__codelineno-0-200" name="__codelineno-0-200"></a>            <span class="p">)</span>
</span><span id="__span-0-201"><a id="__codelineno-0-201" name="__codelineno-0-201"></a>        <span class="p">)</span>
</span><span id="__span-0-202"><a id="__codelineno-0-202" name="__codelineno-0-202"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">grad</span><span class="o">.</span><span class="n">contiguous</span><span class="p">()</span><span class="o">.</span><span class="n">view</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span> <span class="k">for</span> <span class="n">grad</span> <span class="ow">in</span> <span class="n">mvp</span><span class="p">])</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h2 id="pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation" class="doc doc-heading">
          <code>LowRankProductRepresentation</code>

  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-dataclass"><code>dataclass</code></small>
  </span>

<a href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">

  
      <p>Representation of a low rank product of the form <span class="arithmatex">\(H = V D V^T\)</span>,
where D is a diagonal matrix and V is orthogonal.</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>eigen_vals</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Diagonal of D.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>projections</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The matrix V.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>


  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h3 id="pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation.to" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span></code>

<a href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation.to" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Move the representing tensors to a device</p>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-227">227</a></span>
<span class="normal"><a href="#__codelineno-0-228">228</a></span>
<span class="normal"><a href="#__codelineno-0-229">229</a></span>
<span class="normal"><a href="#__codelineno-0-230">230</a></span>
<span class="normal"><a href="#__codelineno-0-231">231</a></span>
<span class="normal"><a href="#__codelineno-0-232">232</a></span>
<span class="normal"><a href="#__codelineno-0-233">233</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-227"><a id="__codelineno-0-227" name="__codelineno-0-227"></a><span class="k">def</span> <span class="nf">to</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">):</span>
</span><span id="__span-0-228"><a id="__codelineno-0-228" name="__codelineno-0-228"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-229"><a id="__codelineno-0-229" name="__codelineno-0-229"></a><span class="sd">    Move the representing tensors to a device</span>
</span><span id="__span-0-230"><a id="__codelineno-0-230" name="__codelineno-0-230"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-231"><a id="__codelineno-0-231" name="__codelineno-0-231"></a>    <span class="k">return</span> <span class="n">LowRankProductRepresentation</span><span class="p">(</span>
</span><span id="__span-0-232"><a id="__codelineno-0-232" name="__codelineno-0-232"></a>        <span class="bp">self</span><span class="o">.</span><span class="n">eigen_vals</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="bp">self</span><span class="o">.</span><span class="n">projections</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</span><span id="__span-0-233"><a id="__codelineno-0-233" name="__codelineno-0-233"></a>    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

<div class="doc doc-object doc-class">




<h2 id="pydvl.influence.torch.torch_differentiable.TorchTensorUtilities" class="doc doc-heading">
          <code>TorchTensorUtilities</code>


<a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
          <p class="doc doc-class-bases">
            Bases: <code><a class="autorefs autorefs-internal" title="pydvl.influence.twice_differentiable.TensorUtilities" href="../../twice_differentiable/#pydvl.influence.twice_differentiable.TensorUtilities">TensorUtilities</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>, <a class="autorefs autorefs-internal" title="pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable" href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable">TorchTwiceDifferentiable</a>]</code></p>



  

  <div class="doc doc-children">










<div class="doc doc-object doc-function">




<h3 id="pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.einsum" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">einsum</span><span class="p">(</span><span class="n">equation</span><span class="p">,</span> <span class="o">*</span><span class="n">operands</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.einsum" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Sums the product of the elements of the input :attr:<code>operands</code> along dimensions specified using a notation
based on the Einstein summation convention.</p>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-426">426</a></span>
<span class="normal"><a href="#__codelineno-0-427">427</a></span>
<span class="normal"><a href="#__codelineno-0-428">428</a></span>
<span class="normal"><a href="#__codelineno-0-429">429</a></span>
<span class="normal"><a href="#__codelineno-0-430">430</a></span>
<span class="normal"><a href="#__codelineno-0-431">431</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-426"><a id="__codelineno-0-426" name="__codelineno-0-426"></a><span class="nd">@staticmethod</span>
</span><span id="__span-0-427"><a id="__codelineno-0-427" name="__codelineno-0-427"></a><span class="k">def</span> <span class="nf">einsum</span><span class="p">(</span><span class="n">equation</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="n">operands</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-428"><a id="__codelineno-0-428" name="__codelineno-0-428"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Sums the product of the elements of the input :attr:`operands` along dimensions specified using a notation</span>
</span><span id="__span-0-429"><a id="__codelineno-0-429" name="__codelineno-0-429"></a><span class="sd">    based on the Einstein summation convention.</span>
</span><span id="__span-0-430"><a id="__codelineno-0-430" name="__codelineno-0-430"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-431"><a id="__codelineno-0-431" name="__codelineno-0-431"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">einsum</span><span class="p">(</span><span class="n">equation</span><span class="p">,</span> <span class="o">*</span><span class="n">operands</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h3 id="pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.cat" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">cat</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.cat" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Concatenates a sequence of tensors into a single torch tensor</p>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-433">433</a></span>
<span class="normal"><a href="#__codelineno-0-434">434</a></span>
<span class="normal"><a href="#__codelineno-0-435">435</a></span>
<span class="normal"><a href="#__codelineno-0-436">436</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-433"><a id="__codelineno-0-433" name="__codelineno-0-433"></a><span class="nd">@staticmethod</span>
</span><span id="__span-0-434"><a id="__codelineno-0-434" name="__codelineno-0-434"></a><span class="k">def</span> <span class="nf">cat</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-435"><a id="__codelineno-0-435" name="__codelineno-0-435"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Concatenates a sequence of tensors into a single torch tensor&quot;&quot;&quot;</span>
</span><span id="__span-0-436"><a id="__codelineno-0-436" name="__codelineno-0-436"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h3 id="pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.stack" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">stack</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.stack" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Stacks a sequence of tensors into a single torch tensor</p>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-438">438</a></span>
<span class="normal"><a href="#__codelineno-0-439">439</a></span>
<span class="normal"><a href="#__codelineno-0-440">440</a></span>
<span class="normal"><a href="#__codelineno-0-441">441</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-438"><a id="__codelineno-0-438" name="__codelineno-0-438"></a><span class="nd">@staticmethod</span>
</span><span id="__span-0-439"><a id="__codelineno-0-439" name="__codelineno-0-439"></a><span class="k">def</span> <span class="nf">stack</span><span class="p">(</span><span class="n">a</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-440"><a id="__codelineno-0-440" name="__codelineno-0-440"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;Stacks a sequence of tensors into a single torch tensor&quot;&quot;&quot;</span>
</span><span id="__span-0-441"><a id="__codelineno-0-441" name="__codelineno-0-441"></a>    <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h3 id="pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.unsqueeze" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span></code>
  
  <span class="doc doc-labels">
      <small class="doc doc-label doc-label-staticmethod"><code>staticmethod</code></small>
  </span>

<a href="#pydvl.influence.torch.torch_differentiable.TorchTensorUtilities.unsqueeze" class="headerlink" title="Permanent link">&para;</a></h3>


  <div class="doc doc-contents ">
  
      <p>Add a singleton dimension at a specified position in a tensor.</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>x</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A PyTorch tensor.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>dim</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The position at which to add the singleton dimension. Zero-based indexing.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <span class="doc-returns-annotation">
                  <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
              </span>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>A new tensor with an additional singleton dimension.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-443">443</a></span>
<span class="normal"><a href="#__codelineno-0-444">444</a></span>
<span class="normal"><a href="#__codelineno-0-445">445</a></span>
<span class="normal"><a href="#__codelineno-0-446">446</a></span>
<span class="normal"><a href="#__codelineno-0-447">447</a></span>
<span class="normal"><a href="#__codelineno-0-448">448</a></span>
<span class="normal"><a href="#__codelineno-0-449">449</a></span>
<span class="normal"><a href="#__codelineno-0-450">450</a></span>
<span class="normal"><a href="#__codelineno-0-451">451</a></span>
<span class="normal"><a href="#__codelineno-0-452">452</a></span>
<span class="normal"><a href="#__codelineno-0-453">453</a></span>
<span class="normal"><a href="#__codelineno-0-454">454</a></span>
<span class="normal"><a href="#__codelineno-0-455">455</a></span>
<span class="normal"><a href="#__codelineno-0-456">456</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-443"><a id="__codelineno-0-443" name="__codelineno-0-443"></a><span class="nd">@staticmethod</span>
</span><span id="__span-0-444"><a id="__codelineno-0-444" name="__codelineno-0-444"></a><span class="k">def</span> <span class="nf">unsqueeze</span><span class="p">(</span><span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">dim</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-445"><a id="__codelineno-0-445" name="__codelineno-0-445"></a><span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-446"><a id="__codelineno-0-446" name="__codelineno-0-446"></a><span class="sd">    Add a singleton dimension at a specified position in a tensor.</span>
</span><span id="__span-0-447"><a id="__codelineno-0-447" name="__codelineno-0-447"></a>
</span><span id="__span-0-448"><a id="__codelineno-0-448" name="__codelineno-0-448"></a><span class="sd">    Args:</span>
</span><span id="__span-0-449"><a id="__codelineno-0-449" name="__codelineno-0-449"></a><span class="sd">        x: A PyTorch tensor.</span>
</span><span id="__span-0-450"><a id="__codelineno-0-450" name="__codelineno-0-450"></a><span class="sd">        dim: The position at which to add the singleton dimension. Zero-based indexing.</span>
</span><span id="__span-0-451"><a id="__codelineno-0-451" name="__codelineno-0-451"></a>
</span><span id="__span-0-452"><a id="__codelineno-0-452" name="__codelineno-0-452"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-453"><a id="__codelineno-0-453" name="__codelineno-0-453"></a><span class="sd">        A new tensor with an additional singleton dimension.</span>
</span><span id="__span-0-454"><a id="__codelineno-0-454" name="__codelineno-0-454"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-455"><a id="__codelineno-0-455" name="__codelineno-0-455"></a>
</span><span id="__span-0-456"><a id="__codelineno-0-456" name="__codelineno-0-456"></a>    <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="n">dim</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>



<div class="doc doc-object doc-function">




<h2 id="pydvl.influence.torch.torch_differentiable.lanzcos_low_rank_hessian_approx" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">lanzcos_low_rank_hessian_approx</span><span class="p">(</span><span class="n">hessian_vp</span><span class="p">,</span> <span class="n">matrix_shape</span><span class="p">,</span> <span class="n">hessian_perturbation</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">rank_estimate</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">krylov_dimension</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eigen_computation_on_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">torch_dtype</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#pydvl.influence.torch.torch_differentiable.lanzcos_low_rank_hessian_approx" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Calculates a low-rank approximation of the Hessian matrix of a scalar-valued
function using the implicitly restarted Lanczos algorithm, i.e.:</p>
<div class="arithmatex">\[ H_{\text{approx}} = V D V^T\]</div>
<p>where <span class="arithmatex">\(D\)</span> is a diagonal matrix with the top (in absolute value) <code>rank_estimate</code> eigenvalues of the Hessian
and <span class="arithmatex">\(V\)</span> contains the corresponding eigenvectors.</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>hessian_vp</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A function that takes a vector and returns the product of
the Hessian of the loss function.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a>[[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>], <a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>matrix_shape</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The shape of the matrix, represented by the hessian vector
product.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Tuple" href="https://docs.python.org/3/library/typing.html#typing.Tuple">Tuple</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>, <a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>]</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>hessian_perturbation</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Regularization parameter added to the
Hessian-vector product for numerical stability.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>0.0</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>rank_estimate</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The number of eigenvalues and corresponding eigenvectors
to compute. Represents the desired rank of the Hessian approximation.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>10</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>krylov_dimension</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The number of Krylov vectors to use for the Lanczos
method. If not provided, it defaults to
<span class="arithmatex">\( \min(\text{model.num_parameters}, \max(2 \times \text{rank_estimate} + 1, 20)) \)</span>.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>tol</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The stopping criteria for the Lanczos algorithm, which stops when
the difference in the approximated eigenvalue is less than <code>tol</code>.
Defaults to 1e-6.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>1e-06</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>max_iter</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The maximum number of iterations for the Lanczos method. If
not provided, it defaults to <span class="arithmatex">\( 10 \cdot \text{model.num_parameters}\)</span>.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>device</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The device to use for executing the hessian vector product.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" title="torch.device" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.device">device</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>eigen_computation_on_gpu</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>If True, tries to execute the eigen pair
approximation on the provided device via <a href="https://cupy.dev/">cupy</a>
implementation. Ensure that either your model is small enough, or you
use a small rank_estimate to fit your device's memory. If False, the
eigen pair approximation is executed on the CPU with scipy's wrapper to
ARPACK.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>False</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>torch_dtype</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>If not provided, the current torch default dtype is used for
conversion to torch.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.dtype" href="https://pytorch.org/docs/stable/tensor_attributes.html#torch.dtype">dtype</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <span class="doc-returns-annotation">
                  <code><a class="autorefs autorefs-internal" title="pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation" href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation">LowRankProductRepresentation</a></code>
              </span>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>A <a class="autorefs autorefs-internal" href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation">LowRankProductRepresentation</a>
instance that contains the top (up until rank_estimate) eigenvalues
and corresponding eigenvectors of the Hessian.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-240">240</a></span>
<span class="normal"><a href="#__codelineno-0-241">241</a></span>
<span class="normal"><a href="#__codelineno-0-242">242</a></span>
<span class="normal"><a href="#__codelineno-0-243">243</a></span>
<span class="normal"><a href="#__codelineno-0-244">244</a></span>
<span class="normal"><a href="#__codelineno-0-245">245</a></span>
<span class="normal"><a href="#__codelineno-0-246">246</a></span>
<span class="normal"><a href="#__codelineno-0-247">247</a></span>
<span class="normal"><a href="#__codelineno-0-248">248</a></span>
<span class="normal"><a href="#__codelineno-0-249">249</a></span>
<span class="normal"><a href="#__codelineno-0-250">250</a></span>
<span class="normal"><a href="#__codelineno-0-251">251</a></span>
<span class="normal"><a href="#__codelineno-0-252">252</a></span>
<span class="normal"><a href="#__codelineno-0-253">253</a></span>
<span class="normal"><a href="#__codelineno-0-254">254</a></span>
<span class="normal"><a href="#__codelineno-0-255">255</a></span>
<span class="normal"><a href="#__codelineno-0-256">256</a></span>
<span class="normal"><a href="#__codelineno-0-257">257</a></span>
<span class="normal"><a href="#__codelineno-0-258">258</a></span>
<span class="normal"><a href="#__codelineno-0-259">259</a></span>
<span class="normal"><a href="#__codelineno-0-260">260</a></span>
<span class="normal"><a href="#__codelineno-0-261">261</a></span>
<span class="normal"><a href="#__codelineno-0-262">262</a></span>
<span class="normal"><a href="#__codelineno-0-263">263</a></span>
<span class="normal"><a href="#__codelineno-0-264">264</a></span>
<span class="normal"><a href="#__codelineno-0-265">265</a></span>
<span class="normal"><a href="#__codelineno-0-266">266</a></span>
<span class="normal"><a href="#__codelineno-0-267">267</a></span>
<span class="normal"><a href="#__codelineno-0-268">268</a></span>
<span class="normal"><a href="#__codelineno-0-269">269</a></span>
<span class="normal"><a href="#__codelineno-0-270">270</a></span>
<span class="normal"><a href="#__codelineno-0-271">271</a></span>
<span class="normal"><a href="#__codelineno-0-272">272</a></span>
<span class="normal"><a href="#__codelineno-0-273">273</a></span>
<span class="normal"><a href="#__codelineno-0-274">274</a></span>
<span class="normal"><a href="#__codelineno-0-275">275</a></span>
<span class="normal"><a href="#__codelineno-0-276">276</a></span>
<span class="normal"><a href="#__codelineno-0-277">277</a></span>
<span class="normal"><a href="#__codelineno-0-278">278</a></span>
<span class="normal"><a href="#__codelineno-0-279">279</a></span>
<span class="normal"><a href="#__codelineno-0-280">280</a></span>
<span class="normal"><a href="#__codelineno-0-281">281</a></span>
<span class="normal"><a href="#__codelineno-0-282">282</a></span>
<span class="normal"><a href="#__codelineno-0-283">283</a></span>
<span class="normal"><a href="#__codelineno-0-284">284</a></span>
<span class="normal"><a href="#__codelineno-0-285">285</a></span>
<span class="normal"><a href="#__codelineno-0-286">286</a></span>
<span class="normal"><a href="#__codelineno-0-287">287</a></span>
<span class="normal"><a href="#__codelineno-0-288">288</a></span>
<span class="normal"><a href="#__codelineno-0-289">289</a></span>
<span class="normal"><a href="#__codelineno-0-290">290</a></span>
<span class="normal"><a href="#__codelineno-0-291">291</a></span>
<span class="normal"><a href="#__codelineno-0-292">292</a></span>
<span class="normal"><a href="#__codelineno-0-293">293</a></span>
<span class="normal"><a href="#__codelineno-0-294">294</a></span>
<span class="normal"><a href="#__codelineno-0-295">295</a></span>
<span class="normal"><a href="#__codelineno-0-296">296</a></span>
<span class="normal"><a href="#__codelineno-0-297">297</a></span>
<span class="normal"><a href="#__codelineno-0-298">298</a></span>
<span class="normal"><a href="#__codelineno-0-299">299</a></span>
<span class="normal"><a href="#__codelineno-0-300">300</a></span>
<span class="normal"><a href="#__codelineno-0-301">301</a></span>
<span class="normal"><a href="#__codelineno-0-302">302</a></span>
<span class="normal"><a href="#__codelineno-0-303">303</a></span>
<span class="normal"><a href="#__codelineno-0-304">304</a></span>
<span class="normal"><a href="#__codelineno-0-305">305</a></span>
<span class="normal"><a href="#__codelineno-0-306">306</a></span>
<span class="normal"><a href="#__codelineno-0-307">307</a></span>
<span class="normal"><a href="#__codelineno-0-308">308</a></span>
<span class="normal"><a href="#__codelineno-0-309">309</a></span>
<span class="normal"><a href="#__codelineno-0-310">310</a></span>
<span class="normal"><a href="#__codelineno-0-311">311</a></span>
<span class="normal"><a href="#__codelineno-0-312">312</a></span>
<span class="normal"><a href="#__codelineno-0-313">313</a></span>
<span class="normal"><a href="#__codelineno-0-314">314</a></span>
<span class="normal"><a href="#__codelineno-0-315">315</a></span>
<span class="normal"><a href="#__codelineno-0-316">316</a></span>
<span class="normal"><a href="#__codelineno-0-317">317</a></span>
<span class="normal"><a href="#__codelineno-0-318">318</a></span>
<span class="normal"><a href="#__codelineno-0-319">319</a></span>
<span class="normal"><a href="#__codelineno-0-320">320</a></span>
<span class="normal"><a href="#__codelineno-0-321">321</a></span>
<span class="normal"><a href="#__codelineno-0-322">322</a></span>
<span class="normal"><a href="#__codelineno-0-323">323</a></span>
<span class="normal"><a href="#__codelineno-0-324">324</a></span>
<span class="normal"><a href="#__codelineno-0-325">325</a></span>
<span class="normal"><a href="#__codelineno-0-326">326</a></span>
<span class="normal"><a href="#__codelineno-0-327">327</a></span>
<span class="normal"><a href="#__codelineno-0-328">328</a></span>
<span class="normal"><a href="#__codelineno-0-329">329</a></span>
<span class="normal"><a href="#__codelineno-0-330">330</a></span>
<span class="normal"><a href="#__codelineno-0-331">331</a></span>
<span class="normal"><a href="#__codelineno-0-332">332</a></span>
<span class="normal"><a href="#__codelineno-0-333">333</a></span>
<span class="normal"><a href="#__codelineno-0-334">334</a></span>
<span class="normal"><a href="#__codelineno-0-335">335</a></span>
<span class="normal"><a href="#__codelineno-0-336">336</a></span>
<span class="normal"><a href="#__codelineno-0-337">337</a></span>
<span class="normal"><a href="#__codelineno-0-338">338</a></span>
<span class="normal"><a href="#__codelineno-0-339">339</a></span>
<span class="normal"><a href="#__codelineno-0-340">340</a></span>
<span class="normal"><a href="#__codelineno-0-341">341</a></span>
<span class="normal"><a href="#__codelineno-0-342">342</a></span>
<span class="normal"><a href="#__codelineno-0-343">343</a></span>
<span class="normal"><a href="#__codelineno-0-344">344</a></span>
<span class="normal"><a href="#__codelineno-0-345">345</a></span>
<span class="normal"><a href="#__codelineno-0-346">346</a></span>
<span class="normal"><a href="#__codelineno-0-347">347</a></span>
<span class="normal"><a href="#__codelineno-0-348">348</a></span>
<span class="normal"><a href="#__codelineno-0-349">349</a></span>
<span class="normal"><a href="#__codelineno-0-350">350</a></span>
<span class="normal"><a href="#__codelineno-0-351">351</a></span>
<span class="normal"><a href="#__codelineno-0-352">352</a></span>
<span class="normal"><a href="#__codelineno-0-353">353</a></span>
<span class="normal"><a href="#__codelineno-0-354">354</a></span>
<span class="normal"><a href="#__codelineno-0-355">355</a></span>
<span class="normal"><a href="#__codelineno-0-356">356</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-240"><a id="__codelineno-0-240" name="__codelineno-0-240"></a><span class="k">def</span> <span class="nf">lanzcos_low_rank_hessian_approx</span><span class="p">(</span>
</span><span id="__span-0-241"><a id="__codelineno-0-241" name="__codelineno-0-241"></a>    <span class="n">hessian_vp</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-242"><a id="__codelineno-0-242" name="__codelineno-0-242"></a>    <span class="n">matrix_shape</span><span class="p">:</span> <span class="n">Tuple</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="nb">int</span><span class="p">],</span>
</span><span id="__span-0-243"><a id="__codelineno-0-243" name="__codelineno-0-243"></a>    <span class="n">hessian_perturbation</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-244"><a id="__codelineno-0-244" name="__codelineno-0-244"></a>    <span class="n">rank_estimate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
</span><span id="__span-0-245"><a id="__codelineno-0-245" name="__codelineno-0-245"></a>    <span class="n">krylov_dimension</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-246"><a id="__codelineno-0-246" name="__codelineno-0-246"></a>    <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
</span><span id="__span-0-247"><a id="__codelineno-0-247" name="__codelineno-0-247"></a>    <span class="n">max_iter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-248"><a id="__codelineno-0-248" name="__codelineno-0-248"></a>    <span class="n">device</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-249"><a id="__codelineno-0-249" name="__codelineno-0-249"></a>    <span class="n">eigen_computation_on_gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-250"><a id="__codelineno-0-250" name="__codelineno-0-250"></a>    <span class="n">torch_dtype</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">dtype</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-251"><a id="__codelineno-0-251" name="__codelineno-0-251"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LowRankProductRepresentation</span><span class="p">:</span>
</span><span id="__span-0-252"><a id="__codelineno-0-252" name="__codelineno-0-252"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-253"><a id="__codelineno-0-253" name="__codelineno-0-253"></a><span class="sd">    Calculates a low-rank approximation of the Hessian matrix of a scalar-valued</span>
</span><span id="__span-0-254"><a id="__codelineno-0-254" name="__codelineno-0-254"></a><span class="sd">    function using the implicitly restarted Lanczos algorithm, i.e.:</span>
</span><span id="__span-0-255"><a id="__codelineno-0-255" name="__codelineno-0-255"></a>
</span><span id="__span-0-256"><a id="__codelineno-0-256" name="__codelineno-0-256"></a><span class="sd">    \[ H_{\text{approx}} = V D V^T\]</span>
</span><span id="__span-0-257"><a id="__codelineno-0-257" name="__codelineno-0-257"></a>
</span><span id="__span-0-258"><a id="__codelineno-0-258" name="__codelineno-0-258"></a><span class="sd">    where \(D\) is a diagonal matrix with the top (in absolute value) `rank_estimate` eigenvalues of the Hessian</span>
</span><span id="__span-0-259"><a id="__codelineno-0-259" name="__codelineno-0-259"></a><span class="sd">    and \(V\) contains the corresponding eigenvectors.</span>
</span><span id="__span-0-260"><a id="__codelineno-0-260" name="__codelineno-0-260"></a>
</span><span id="__span-0-261"><a id="__codelineno-0-261" name="__codelineno-0-261"></a><span class="sd">    Args:</span>
</span><span id="__span-0-262"><a id="__codelineno-0-262" name="__codelineno-0-262"></a><span class="sd">        hessian_vp: A function that takes a vector and returns the product of</span>
</span><span id="__span-0-263"><a id="__codelineno-0-263" name="__codelineno-0-263"></a><span class="sd">            the Hessian of the loss function.</span>
</span><span id="__span-0-264"><a id="__codelineno-0-264" name="__codelineno-0-264"></a><span class="sd">        matrix_shape: The shape of the matrix, represented by the hessian vector</span>
</span><span id="__span-0-265"><a id="__codelineno-0-265" name="__codelineno-0-265"></a><span class="sd">            product.</span>
</span><span id="__span-0-266"><a id="__codelineno-0-266" name="__codelineno-0-266"></a><span class="sd">        hessian_perturbation: Regularization parameter added to the</span>
</span><span id="__span-0-267"><a id="__codelineno-0-267" name="__codelineno-0-267"></a><span class="sd">            Hessian-vector product for numerical stability.</span>
</span><span id="__span-0-268"><a id="__codelineno-0-268" name="__codelineno-0-268"></a><span class="sd">        rank_estimate: The number of eigenvalues and corresponding eigenvectors</span>
</span><span id="__span-0-269"><a id="__codelineno-0-269" name="__codelineno-0-269"></a><span class="sd">            to compute. Represents the desired rank of the Hessian approximation.</span>
</span><span id="__span-0-270"><a id="__codelineno-0-270" name="__codelineno-0-270"></a><span class="sd">        krylov_dimension: The number of Krylov vectors to use for the Lanczos</span>
</span><span id="__span-0-271"><a id="__codelineno-0-271" name="__codelineno-0-271"></a><span class="sd">            method. If not provided, it defaults to</span>
</span><span id="__span-0-272"><a id="__codelineno-0-272" name="__codelineno-0-272"></a><span class="sd">            \( \min(\text{model.num_parameters}, \max(2 \times \text{rank_estimate} + 1, 20)) \).</span>
</span><span id="__span-0-273"><a id="__codelineno-0-273" name="__codelineno-0-273"></a><span class="sd">        tol: The stopping criteria for the Lanczos algorithm, which stops when</span>
</span><span id="__span-0-274"><a id="__codelineno-0-274" name="__codelineno-0-274"></a><span class="sd">            the difference in the approximated eigenvalue is less than `tol`.</span>
</span><span id="__span-0-275"><a id="__codelineno-0-275" name="__codelineno-0-275"></a><span class="sd">            Defaults to 1e-6.</span>
</span><span id="__span-0-276"><a id="__codelineno-0-276" name="__codelineno-0-276"></a><span class="sd">        max_iter: The maximum number of iterations for the Lanczos method. If</span>
</span><span id="__span-0-277"><a id="__codelineno-0-277" name="__codelineno-0-277"></a><span class="sd">            not provided, it defaults to \( 10 \cdot \text{model.num_parameters}\).</span>
</span><span id="__span-0-278"><a id="__codelineno-0-278" name="__codelineno-0-278"></a><span class="sd">        device: The device to use for executing the hessian vector product.</span>
</span><span id="__span-0-279"><a id="__codelineno-0-279" name="__codelineno-0-279"></a><span class="sd">        eigen_computation_on_gpu: If True, tries to execute the eigen pair</span>
</span><span id="__span-0-280"><a id="__codelineno-0-280" name="__codelineno-0-280"></a><span class="sd">            approximation on the provided device via [cupy](https://cupy.dev/)</span>
</span><span id="__span-0-281"><a id="__codelineno-0-281" name="__codelineno-0-281"></a><span class="sd">            implementation. Ensure that either your model is small enough, or you</span>
</span><span id="__span-0-282"><a id="__codelineno-0-282" name="__codelineno-0-282"></a><span class="sd">            use a small rank_estimate to fit your device&#39;s memory. If False, the</span>
</span><span id="__span-0-283"><a id="__codelineno-0-283" name="__codelineno-0-283"></a><span class="sd">            eigen pair approximation is executed on the CPU with scipy&#39;s wrapper to</span>
</span><span id="__span-0-284"><a id="__codelineno-0-284" name="__codelineno-0-284"></a><span class="sd">            ARPACK.</span>
</span><span id="__span-0-285"><a id="__codelineno-0-285" name="__codelineno-0-285"></a><span class="sd">        torch_dtype: If not provided, the current torch default dtype is used for</span>
</span><span id="__span-0-286"><a id="__codelineno-0-286" name="__codelineno-0-286"></a><span class="sd">            conversion to torch.</span>
</span><span id="__span-0-287"><a id="__codelineno-0-287" name="__codelineno-0-287"></a>
</span><span id="__span-0-288"><a id="__codelineno-0-288" name="__codelineno-0-288"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-289"><a id="__codelineno-0-289" name="__codelineno-0-289"></a><span class="sd">        A [LowRankProductRepresentation][pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation]</span>
</span><span id="__span-0-290"><a id="__codelineno-0-290" name="__codelineno-0-290"></a><span class="sd">            instance that contains the top (up until rank_estimate) eigenvalues</span>
</span><span id="__span-0-291"><a id="__codelineno-0-291" name="__codelineno-0-291"></a><span class="sd">            and corresponding eigenvectors of the Hessian.</span>
</span><span id="__span-0-292"><a id="__codelineno-0-292" name="__codelineno-0-292"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-293"><a id="__codelineno-0-293" name="__codelineno-0-293"></a>
</span><span id="__span-0-294"><a id="__codelineno-0-294" name="__codelineno-0-294"></a>    <span class="n">torch_dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">get_default_dtype</span><span class="p">()</span> <span class="k">if</span> <span class="n">torch_dtype</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">torch_dtype</span>
</span><span id="__span-0-295"><a id="__codelineno-0-295" name="__codelineno-0-295"></a>
</span><span id="__span-0-296"><a id="__codelineno-0-296" name="__codelineno-0-296"></a>    <span class="k">if</span> <span class="n">eigen_computation_on_gpu</span><span class="p">:</span>
</span><span id="__span-0-297"><a id="__codelineno-0-297" name="__codelineno-0-297"></a>        <span class="k">try</span><span class="p">:</span>
</span><span id="__span-0-298"><a id="__codelineno-0-298" name="__codelineno-0-298"></a>            <span class="kn">import</span> <span class="nn">cupy</span> <span class="k">as</span> <span class="nn">cp</span>
</span><span id="__span-0-299"><a id="__codelineno-0-299" name="__codelineno-0-299"></a>            <span class="kn">from</span> <span class="nn">cupyx.scipy.sparse.linalg</span> <span class="kn">import</span> <span class="n">LinearOperator</span><span class="p">,</span> <span class="n">eigsh</span>
</span><span id="__span-0-300"><a id="__codelineno-0-300" name="__codelineno-0-300"></a>            <span class="kn">from</span> <span class="nn">torch.utils.dlpack</span> <span class="kn">import</span> <span class="n">from_dlpack</span><span class="p">,</span> <span class="n">to_dlpack</span>
</span><span id="__span-0-301"><a id="__codelineno-0-301" name="__codelineno-0-301"></a>        <span class="k">except</span> <span class="ne">ImportError</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="__span-0-302"><a id="__codelineno-0-302" name="__codelineno-0-302"></a>            <span class="k">raise</span> <span class="ne">ImportError</span><span class="p">(</span>
</span><span id="__span-0-303"><a id="__codelineno-0-303" name="__codelineno-0-303"></a>                <span class="sa">f</span><span class="s2">&quot;Try to install missing dependencies or set eigen_computation_on_gpu to False: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="__span-0-304"><a id="__codelineno-0-304" name="__codelineno-0-304"></a>            <span class="p">)</span>
</span><span id="__span-0-305"><a id="__codelineno-0-305" name="__codelineno-0-305"></a>
</span><span id="__span-0-306"><a id="__codelineno-0-306" name="__codelineno-0-306"></a>        <span class="k">if</span> <span class="n">device</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-307"><a id="__codelineno-0-307" name="__codelineno-0-307"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-308"><a id="__codelineno-0-308" name="__codelineno-0-308"></a>                <span class="s2">&quot;Without setting an explicit device, cupy is not supported&quot;</span>
</span><span id="__span-0-309"><a id="__codelineno-0-309" name="__codelineno-0-309"></a>            <span class="p">)</span>
</span><span id="__span-0-310"><a id="__codelineno-0-310" name="__codelineno-0-310"></a>
</span><span id="__span-0-311"><a id="__codelineno-0-311" name="__codelineno-0-311"></a>        <span class="k">def</span> <span class="nf">to_torch_conversion_function</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span><span id="__span-0-312"><a id="__codelineno-0-312" name="__codelineno-0-312"></a>            <span class="k">return</span> <span class="n">from_dlpack</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">toDlpack</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">torch_dtype</span><span class="p">)</span>
</span><span id="__span-0-313"><a id="__codelineno-0-313" name="__codelineno-0-313"></a>
</span><span id="__span-0-314"><a id="__codelineno-0-314" name="__codelineno-0-314"></a>        <span class="k">def</span> <span class="nf">mv</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span><span id="__span-0-315"><a id="__codelineno-0-315" name="__codelineno-0-315"></a>            <span class="n">x</span> <span class="o">=</span> <span class="n">to_torch_conversion_function</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-316"><a id="__codelineno-0-316" name="__codelineno-0-316"></a>            <span class="n">y</span> <span class="o">=</span> <span class="n">hessian_vp</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">+</span> <span class="n">hessian_perturbation</span> <span class="o">*</span> <span class="n">x</span>
</span><span id="__span-0-317"><a id="__codelineno-0-317" name="__codelineno-0-317"></a>            <span class="k">return</span> <span class="n">cp</span><span class="o">.</span><span class="n">from_dlpack</span><span class="p">(</span><span class="n">to_dlpack</span><span class="p">(</span><span class="n">y</span><span class="p">))</span>
</span><span id="__span-0-318"><a id="__codelineno-0-318" name="__codelineno-0-318"></a>
</span><span id="__span-0-319"><a id="__codelineno-0-319" name="__codelineno-0-319"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-320"><a id="__codelineno-0-320" name="__codelineno-0-320"></a>        <span class="kn">from</span> <span class="nn">scipy.sparse.linalg</span> <span class="kn">import</span> <span class="n">LinearOperator</span><span class="p">,</span> <span class="n">eigsh</span>
</span><span id="__span-0-321"><a id="__codelineno-0-321" name="__codelineno-0-321"></a>
</span><span id="__span-0-322"><a id="__codelineno-0-322" name="__codelineno-0-322"></a>        <span class="k">def</span> <span class="nf">mv</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
</span><span id="__span-0-323"><a id="__codelineno-0-323" name="__codelineno-0-323"></a>            <span class="n">x_torch</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch_dtype</span><span class="p">)</span>
</span><span id="__span-0-324"><a id="__codelineno-0-324" name="__codelineno-0-324"></a>            <span class="n">y</span><span class="p">:</span> <span class="n">NDArray</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-325"><a id="__codelineno-0-325" name="__codelineno-0-325"></a>                <span class="p">(</span><span class="n">hessian_vp</span><span class="p">(</span><span class="n">x_torch</span><span class="p">)</span> <span class="o">+</span> <span class="n">hessian_perturbation</span> <span class="o">*</span> <span class="n">x_torch</span><span class="p">)</span>
</span><span id="__span-0-326"><a id="__codelineno-0-326" name="__codelineno-0-326"></a>                <span class="o">.</span><span class="n">detach</span><span class="p">()</span>
</span><span id="__span-0-327"><a id="__codelineno-0-327" name="__codelineno-0-327"></a>                <span class="o">.</span><span class="n">cpu</span><span class="p">()</span>
</span><span id="__span-0-328"><a id="__codelineno-0-328" name="__codelineno-0-328"></a>                <span class="o">.</span><span class="n">numpy</span><span class="p">()</span>
</span><span id="__span-0-329"><a id="__codelineno-0-329" name="__codelineno-0-329"></a>            <span class="p">)</span>
</span><span id="__span-0-330"><a id="__codelineno-0-330" name="__codelineno-0-330"></a>            <span class="k">return</span> <span class="n">y</span>
</span><span id="__span-0-331"><a id="__codelineno-0-331" name="__codelineno-0-331"></a>
</span><span id="__span-0-332"><a id="__codelineno-0-332" name="__codelineno-0-332"></a>        <span class="n">to_torch_conversion_function</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">as_tensor</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch_dtype</span><span class="p">)</span>
</span><span id="__span-0-333"><a id="__codelineno-0-333" name="__codelineno-0-333"></a>
</span><span id="__span-0-334"><a id="__codelineno-0-334" name="__codelineno-0-334"></a>    <span class="k">try</span><span class="p">:</span>
</span><span id="__span-0-335"><a id="__codelineno-0-335" name="__codelineno-0-335"></a>        <span class="n">eigen_vals</span><span class="p">,</span> <span class="n">eigen_vecs</span> <span class="o">=</span> <span class="n">eigsh</span><span class="p">(</span>
</span><span id="__span-0-336"><a id="__codelineno-0-336" name="__codelineno-0-336"></a>            <span class="n">LinearOperator</span><span class="p">(</span><span class="n">matrix_shape</span><span class="p">,</span> <span class="n">matvec</span><span class="o">=</span><span class="n">mv</span><span class="p">),</span>
</span><span id="__span-0-337"><a id="__codelineno-0-337" name="__codelineno-0-337"></a>            <span class="n">k</span><span class="o">=</span><span class="n">rank_estimate</span><span class="p">,</span>
</span><span id="__span-0-338"><a id="__codelineno-0-338" name="__codelineno-0-338"></a>            <span class="n">maxiter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
</span><span id="__span-0-339"><a id="__codelineno-0-339" name="__codelineno-0-339"></a>            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
</span><span id="__span-0-340"><a id="__codelineno-0-340" name="__codelineno-0-340"></a>            <span class="n">ncv</span><span class="o">=</span><span class="n">krylov_dimension</span><span class="p">,</span>
</span><span id="__span-0-341"><a id="__codelineno-0-341" name="__codelineno-0-341"></a>            <span class="n">return_eigenvectors</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
</span><span id="__span-0-342"><a id="__codelineno-0-342" name="__codelineno-0-342"></a>        <span class="p">)</span>
</span><span id="__span-0-343"><a id="__codelineno-0-343" name="__codelineno-0-343"></a>
</span><span id="__span-0-344"><a id="__codelineno-0-344" name="__codelineno-0-344"></a>    <span class="k">except</span> <span class="n">ArpackNoConvergence</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
</span><span id="__span-0-345"><a id="__codelineno-0-345" name="__codelineno-0-345"></a>        <span class="n">logger</span><span class="o">.</span><span class="n">warning</span><span class="p">(</span>
</span><span id="__span-0-346"><a id="__codelineno-0-346" name="__codelineno-0-346"></a>            <span class="sa">f</span><span class="s2">&quot;ARPACK did not converge for parameters </span><span class="si">{</span><span class="n">max_iter</span><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><span class="n">tol</span><span class="si">=}</span><span class="s2">, </span><span class="si">{</span><span class="n">krylov_dimension</span><span class="si">=}</span><span class="s2">, &quot;</span>
</span><span id="__span-0-347"><a id="__codelineno-0-347" name="__codelineno-0-347"></a>            <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">rank_estimate</span><span class="si">=}</span><span class="s2">. </span><span class="se">\n</span><span class="s2"> Returning the best approximation found so far. Use those with care or &quot;</span>
</span><span id="__span-0-348"><a id="__codelineno-0-348" name="__codelineno-0-348"></a>            <span class="sa">f</span><span class="s2">&quot;modify parameters.</span><span class="se">\n</span><span class="s2"> Original error: </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s2">&quot;</span>
</span><span id="__span-0-349"><a id="__codelineno-0-349" name="__codelineno-0-349"></a>        <span class="p">)</span>
</span><span id="__span-0-350"><a id="__codelineno-0-350" name="__codelineno-0-350"></a>
</span><span id="__span-0-351"><a id="__codelineno-0-351" name="__codelineno-0-351"></a>        <span class="n">eigen_vals</span><span class="p">,</span> <span class="n">eigen_vecs</span> <span class="o">=</span> <span class="n">e</span><span class="o">.</span><span class="n">eigenvalues</span><span class="p">,</span> <span class="n">e</span><span class="o">.</span><span class="n">eigenvectors</span>
</span><span id="__span-0-352"><a id="__codelineno-0-352" name="__codelineno-0-352"></a>
</span><span id="__span-0-353"><a id="__codelineno-0-353" name="__codelineno-0-353"></a>    <span class="n">eigen_vals</span> <span class="o">=</span> <span class="n">to_torch_conversion_function</span><span class="p">(</span><span class="n">eigen_vals</span><span class="p">)</span>
</span><span id="__span-0-354"><a id="__codelineno-0-354" name="__codelineno-0-354"></a>    <span class="n">eigen_vecs</span> <span class="o">=</span> <span class="n">to_torch_conversion_function</span><span class="p">(</span><span class="n">eigen_vecs</span><span class="p">)</span>
</span><span id="__span-0-355"><a id="__codelineno-0-355" name="__codelineno-0-355"></a>
</span><span id="__span-0-356"><a id="__codelineno-0-356" name="__codelineno-0-356"></a>    <span class="k">return</span> <span class="n">LowRankProductRepresentation</span><span class="p">(</span><span class="n">eigen_vals</span><span class="p">,</span> <span class="n">eigen_vecs</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pydvl.influence.torch.torch_differentiable.model_hessian_low_rank" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">model_hessian_low_rank</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">hessian_perturbation</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">rank_estimate</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">krylov_dimension</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eigen_computation_on_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#pydvl.influence.torch.torch_differentiable.model_hessian_low_rank" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Calculates a low-rank approximation of the Hessian matrix of the model's loss function using the implicitly
restarted Lanczos algorithm, i.e.</p>
<div class="arithmatex">\[ H_{\text{approx}} = V D V^T\]</div>
<p>where <span class="arithmatex">\(D\)</span> is a diagonal matrix with the top (in absolute value) <code>rank_estimate</code> eigenvalues of the Hessian
and <span class="arithmatex">\(V\)</span> contains the corresponding eigenvectors.</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>model</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A PyTorch model instance that is twice differentiable, wrapped into <code>TorchTwiceDifferential</code>.
The Hessian will be calculated with respect to this model's parameters.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-internal" title="pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable" href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable">TorchTwiceDifferentiable</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>training_data</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A DataLoader instance that provides the model's training data.
Used in calculating the Hessian-vector products.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.utils.data.DataLoader" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">DataLoader</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>hessian_perturbation</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Optional regularization parameter added to the Hessian-vector product
for numerical stability.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>0.0</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>rank_estimate</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The number of eigenvalues and corresponding eigenvectors to compute.
Represents the desired rank of the Hessian approximation.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>10</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>krylov_dimension</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The number of Krylov vectors to use for the Lanczos method.
If not provided, it defaults to min(model.num_parameters, max(2*rank_estimate + 1, 20)).</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>tol</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The stopping criteria for the Lanczos algorithm, which stops when the difference
in the approximated eigenvalue is less than <code>tol</code>. Defaults to 1e-6.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>1e-06</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>max_iter</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The maximum number of iterations for the Lanczos method. If not provided, it defaults to
10*model.num_parameters.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>eigen_computation_on_gpu</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>If True, tries to execute the eigen pair approximation on the provided
device via cupy implementation.
Make sure, that either your model is small enough or you use a
small rank_estimate to fit your device's memory.
If False, the eigen pair approximation is executed on the CPU by scipy wrapper to
ARPACK.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>False</code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <span class="doc-returns-annotation">
                  <code><a class="autorefs autorefs-internal" title="pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation" href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation">LowRankProductRepresentation</a></code>
              </span>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>A <a class="autorefs autorefs-internal" href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation">LowRankProductRepresentation</a>
instance that contains the top (up until rank_estimate) eigenvalues
and corresponding eigenvectors of the Hessian.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-359">359</a></span>
<span class="normal"><a href="#__codelineno-0-360">360</a></span>
<span class="normal"><a href="#__codelineno-0-361">361</a></span>
<span class="normal"><a href="#__codelineno-0-362">362</a></span>
<span class="normal"><a href="#__codelineno-0-363">363</a></span>
<span class="normal"><a href="#__codelineno-0-364">364</a></span>
<span class="normal"><a href="#__codelineno-0-365">365</a></span>
<span class="normal"><a href="#__codelineno-0-366">366</a></span>
<span class="normal"><a href="#__codelineno-0-367">367</a></span>
<span class="normal"><a href="#__codelineno-0-368">368</a></span>
<span class="normal"><a href="#__codelineno-0-369">369</a></span>
<span class="normal"><a href="#__codelineno-0-370">370</a></span>
<span class="normal"><a href="#__codelineno-0-371">371</a></span>
<span class="normal"><a href="#__codelineno-0-372">372</a></span>
<span class="normal"><a href="#__codelineno-0-373">373</a></span>
<span class="normal"><a href="#__codelineno-0-374">374</a></span>
<span class="normal"><a href="#__codelineno-0-375">375</a></span>
<span class="normal"><a href="#__codelineno-0-376">376</a></span>
<span class="normal"><a href="#__codelineno-0-377">377</a></span>
<span class="normal"><a href="#__codelineno-0-378">378</a></span>
<span class="normal"><a href="#__codelineno-0-379">379</a></span>
<span class="normal"><a href="#__codelineno-0-380">380</a></span>
<span class="normal"><a href="#__codelineno-0-381">381</a></span>
<span class="normal"><a href="#__codelineno-0-382">382</a></span>
<span class="normal"><a href="#__codelineno-0-383">383</a></span>
<span class="normal"><a href="#__codelineno-0-384">384</a></span>
<span class="normal"><a href="#__codelineno-0-385">385</a></span>
<span class="normal"><a href="#__codelineno-0-386">386</a></span>
<span class="normal"><a href="#__codelineno-0-387">387</a></span>
<span class="normal"><a href="#__codelineno-0-388">388</a></span>
<span class="normal"><a href="#__codelineno-0-389">389</a></span>
<span class="normal"><a href="#__codelineno-0-390">390</a></span>
<span class="normal"><a href="#__codelineno-0-391">391</a></span>
<span class="normal"><a href="#__codelineno-0-392">392</a></span>
<span class="normal"><a href="#__codelineno-0-393">393</a></span>
<span class="normal"><a href="#__codelineno-0-394">394</a></span>
<span class="normal"><a href="#__codelineno-0-395">395</a></span>
<span class="normal"><a href="#__codelineno-0-396">396</a></span>
<span class="normal"><a href="#__codelineno-0-397">397</a></span>
<span class="normal"><a href="#__codelineno-0-398">398</a></span>
<span class="normal"><a href="#__codelineno-0-399">399</a></span>
<span class="normal"><a href="#__codelineno-0-400">400</a></span>
<span class="normal"><a href="#__codelineno-0-401">401</a></span>
<span class="normal"><a href="#__codelineno-0-402">402</a></span>
<span class="normal"><a href="#__codelineno-0-403">403</a></span>
<span class="normal"><a href="#__codelineno-0-404">404</a></span>
<span class="normal"><a href="#__codelineno-0-405">405</a></span>
<span class="normal"><a href="#__codelineno-0-406">406</a></span>
<span class="normal"><a href="#__codelineno-0-407">407</a></span>
<span class="normal"><a href="#__codelineno-0-408">408</a></span>
<span class="normal"><a href="#__codelineno-0-409">409</a></span>
<span class="normal"><a href="#__codelineno-0-410">410</a></span>
<span class="normal"><a href="#__codelineno-0-411">411</a></span>
<span class="normal"><a href="#__codelineno-0-412">412</a></span>
<span class="normal"><a href="#__codelineno-0-413">413</a></span>
<span class="normal"><a href="#__codelineno-0-414">414</a></span>
<span class="normal"><a href="#__codelineno-0-415">415</a></span>
<span class="normal"><a href="#__codelineno-0-416">416</a></span>
<span class="normal"><a href="#__codelineno-0-417">417</a></span>
<span class="normal"><a href="#__codelineno-0-418">418</a></span>
<span class="normal"><a href="#__codelineno-0-419">419</a></span>
<span class="normal"><a href="#__codelineno-0-420">420</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-359"><a id="__codelineno-0-359" name="__codelineno-0-359"></a><span class="k">def</span> <span class="nf">model_hessian_low_rank</span><span class="p">(</span>
</span><span id="__span-0-360"><a id="__codelineno-0-360" name="__codelineno-0-360"></a>    <span class="n">model</span><span class="p">:</span> <span class="n">TorchTwiceDifferentiable</span><span class="p">,</span>
</span><span id="__span-0-361"><a id="__codelineno-0-361" name="__codelineno-0-361"></a>    <span class="n">training_data</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
</span><span id="__span-0-362"><a id="__codelineno-0-362" name="__codelineno-0-362"></a>    <span class="n">hessian_perturbation</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-363"><a id="__codelineno-0-363" name="__codelineno-0-363"></a>    <span class="n">rank_estimate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
</span><span id="__span-0-364"><a id="__codelineno-0-364" name="__codelineno-0-364"></a>    <span class="n">krylov_dimension</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-365"><a id="__codelineno-0-365" name="__codelineno-0-365"></a>    <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
</span><span id="__span-0-366"><a id="__codelineno-0-366" name="__codelineno-0-366"></a>    <span class="n">max_iter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-367"><a id="__codelineno-0-367" name="__codelineno-0-367"></a>    <span class="n">eigen_computation_on_gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-368"><a id="__codelineno-0-368" name="__codelineno-0-368"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">LowRankProductRepresentation</span><span class="p">:</span>
</span><span id="__span-0-369"><a id="__codelineno-0-369" name="__codelineno-0-369"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-370"><a id="__codelineno-0-370" name="__codelineno-0-370"></a><span class="sd">    Calculates a low-rank approximation of the Hessian matrix of the model&#39;s loss function using the implicitly</span>
</span><span id="__span-0-371"><a id="__codelineno-0-371" name="__codelineno-0-371"></a><span class="sd">    restarted Lanczos algorithm, i.e.</span>
</span><span id="__span-0-372"><a id="__codelineno-0-372" name="__codelineno-0-372"></a>
</span><span id="__span-0-373"><a id="__codelineno-0-373" name="__codelineno-0-373"></a><span class="sd">    \[ H_{\text{approx}} = V D V^T\]</span>
</span><span id="__span-0-374"><a id="__codelineno-0-374" name="__codelineno-0-374"></a>
</span><span id="__span-0-375"><a id="__codelineno-0-375" name="__codelineno-0-375"></a><span class="sd">    where \(D\) is a diagonal matrix with the top (in absolute value) `rank_estimate` eigenvalues of the Hessian</span>
</span><span id="__span-0-376"><a id="__codelineno-0-376" name="__codelineno-0-376"></a><span class="sd">    and \(V\) contains the corresponding eigenvectors.</span>
</span><span id="__span-0-377"><a id="__codelineno-0-377" name="__codelineno-0-377"></a>
</span><span id="__span-0-378"><a id="__codelineno-0-378" name="__codelineno-0-378"></a>
</span><span id="__span-0-379"><a id="__codelineno-0-379" name="__codelineno-0-379"></a><span class="sd">    Args:</span>
</span><span id="__span-0-380"><a id="__codelineno-0-380" name="__codelineno-0-380"></a><span class="sd">        model: A PyTorch model instance that is twice differentiable, wrapped into `TorchTwiceDifferential`.</span>
</span><span id="__span-0-381"><a id="__codelineno-0-381" name="__codelineno-0-381"></a><span class="sd">            The Hessian will be calculated with respect to this model&#39;s parameters.</span>
</span><span id="__span-0-382"><a id="__codelineno-0-382" name="__codelineno-0-382"></a><span class="sd">        training_data: A DataLoader instance that provides the model&#39;s training data.</span>
</span><span id="__span-0-383"><a id="__codelineno-0-383" name="__codelineno-0-383"></a><span class="sd">            Used in calculating the Hessian-vector products.</span>
</span><span id="__span-0-384"><a id="__codelineno-0-384" name="__codelineno-0-384"></a><span class="sd">        hessian_perturbation: Optional regularization parameter added to the Hessian-vector product</span>
</span><span id="__span-0-385"><a id="__codelineno-0-385" name="__codelineno-0-385"></a><span class="sd">            for numerical stability.</span>
</span><span id="__span-0-386"><a id="__codelineno-0-386" name="__codelineno-0-386"></a><span class="sd">        rank_estimate: The number of eigenvalues and corresponding eigenvectors to compute.</span>
</span><span id="__span-0-387"><a id="__codelineno-0-387" name="__codelineno-0-387"></a><span class="sd">            Represents the desired rank of the Hessian approximation.</span>
</span><span id="__span-0-388"><a id="__codelineno-0-388" name="__codelineno-0-388"></a><span class="sd">        krylov_dimension: The number of Krylov vectors to use for the Lanczos method.</span>
</span><span id="__span-0-389"><a id="__codelineno-0-389" name="__codelineno-0-389"></a><span class="sd">            If not provided, it defaults to min(model.num_parameters, max(2*rank_estimate + 1, 20)).</span>
</span><span id="__span-0-390"><a id="__codelineno-0-390" name="__codelineno-0-390"></a><span class="sd">        tol: The stopping criteria for the Lanczos algorithm, which stops when the difference</span>
</span><span id="__span-0-391"><a id="__codelineno-0-391" name="__codelineno-0-391"></a><span class="sd">            in the approximated eigenvalue is less than `tol`. Defaults to 1e-6.</span>
</span><span id="__span-0-392"><a id="__codelineno-0-392" name="__codelineno-0-392"></a><span class="sd">        max_iter: The maximum number of iterations for the Lanczos method. If not provided, it defaults to</span>
</span><span id="__span-0-393"><a id="__codelineno-0-393" name="__codelineno-0-393"></a><span class="sd">            10*model.num_parameters.</span>
</span><span id="__span-0-394"><a id="__codelineno-0-394" name="__codelineno-0-394"></a><span class="sd">        eigen_computation_on_gpu: If True, tries to execute the eigen pair approximation on the provided</span>
</span><span id="__span-0-395"><a id="__codelineno-0-395" name="__codelineno-0-395"></a><span class="sd">            device via cupy implementation.</span>
</span><span id="__span-0-396"><a id="__codelineno-0-396" name="__codelineno-0-396"></a><span class="sd">            Make sure, that either your model is small enough or you use a</span>
</span><span id="__span-0-397"><a id="__codelineno-0-397" name="__codelineno-0-397"></a><span class="sd">            small rank_estimate to fit your device&#39;s memory.</span>
</span><span id="__span-0-398"><a id="__codelineno-0-398" name="__codelineno-0-398"></a><span class="sd">            If False, the eigen pair approximation is executed on the CPU by scipy wrapper to</span>
</span><span id="__span-0-399"><a id="__codelineno-0-399" name="__codelineno-0-399"></a><span class="sd">            ARPACK.</span>
</span><span id="__span-0-400"><a id="__codelineno-0-400" name="__codelineno-0-400"></a>
</span><span id="__span-0-401"><a id="__codelineno-0-401" name="__codelineno-0-401"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-402"><a id="__codelineno-0-402" name="__codelineno-0-402"></a><span class="sd">        A [LowRankProductRepresentation][pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation]</span>
</span><span id="__span-0-403"><a id="__codelineno-0-403" name="__codelineno-0-403"></a><span class="sd">            instance that contains the top (up until rank_estimate) eigenvalues</span>
</span><span id="__span-0-404"><a id="__codelineno-0-404" name="__codelineno-0-404"></a><span class="sd">            and corresponding eigenvectors of the Hessian.</span>
</span><span id="__span-0-405"><a id="__codelineno-0-405" name="__codelineno-0-405"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-406"><a id="__codelineno-0-406" name="__codelineno-0-406"></a>    <span class="n">raw_hvp</span> <span class="o">=</span> <span class="n">get_hvp_function</span><span class="p">(</span>
</span><span id="__span-0-407"><a id="__codelineno-0-407" name="__codelineno-0-407"></a>        <span class="n">model</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">use_hessian_avg</span><span class="o">=</span><span class="kc">True</span>
</span><span id="__span-0-408"><a id="__codelineno-0-408" name="__codelineno-0-408"></a>    <span class="p">)</span>
</span><span id="__span-0-409"><a id="__codelineno-0-409" name="__codelineno-0-409"></a>
</span><span id="__span-0-410"><a id="__codelineno-0-410" name="__codelineno-0-410"></a>    <span class="k">return</span> <span class="n">lanzcos_low_rank_hessian_approx</span><span class="p">(</span>
</span><span id="__span-0-411"><a id="__codelineno-0-411" name="__codelineno-0-411"></a>        <span class="n">hessian_vp</span><span class="o">=</span><span class="n">raw_hvp</span><span class="p">,</span>
</span><span id="__span-0-412"><a id="__codelineno-0-412" name="__codelineno-0-412"></a>        <span class="n">matrix_shape</span><span class="o">=</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">num_params</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">num_params</span><span class="p">),</span>
</span><span id="__span-0-413"><a id="__codelineno-0-413" name="__codelineno-0-413"></a>        <span class="n">hessian_perturbation</span><span class="o">=</span><span class="n">hessian_perturbation</span><span class="p">,</span>
</span><span id="__span-0-414"><a id="__codelineno-0-414" name="__codelineno-0-414"></a>        <span class="n">rank_estimate</span><span class="o">=</span><span class="n">rank_estimate</span><span class="p">,</span>
</span><span id="__span-0-415"><a id="__codelineno-0-415" name="__codelineno-0-415"></a>        <span class="n">krylov_dimension</span><span class="o">=</span><span class="n">krylov_dimension</span><span class="p">,</span>
</span><span id="__span-0-416"><a id="__codelineno-0-416" name="__codelineno-0-416"></a>        <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
</span><span id="__span-0-417"><a id="__codelineno-0-417" name="__codelineno-0-417"></a>        <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
</span><span id="__span-0-418"><a id="__codelineno-0-418" name="__codelineno-0-418"></a>        <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;device&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-419"><a id="__codelineno-0-419" name="__codelineno-0-419"></a>        <span class="n">eigen_computation_on_gpu</span><span class="o">=</span><span class="n">eigen_computation_on_gpu</span><span class="p">,</span>
</span><span id="__span-0-420"><a id="__codelineno-0-420" name="__codelineno-0-420"></a>    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pydvl.influence.torch.torch_differentiable.solve_linear" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">solve_linear</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hessian_perturbation</span><span class="o">=</span><span class="mf">0.0</span><span class="p">)</span></code>

<a href="#pydvl.influence.torch.torch_differentiable.solve_linear" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Given a model and training data, it finds x such that <span class="arithmatex">\(Hx = b\)</span>, with <span class="arithmatex">\(H\)</span> being the model hessian.</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>model</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A model wrapped in the TwiceDifferentiable interface.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-internal" title="pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable" href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable">TorchTwiceDifferentiable</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>training_data</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A DataLoader containing the training data.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.utils.data.DataLoader" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">DataLoader</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>b</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A vector or matrix, the right hand side of the equation <span class="arithmatex">\(Hx = b\)</span>.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>hessian_perturbation</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Regularization of the hessian.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>0.0</code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <span class="doc-returns-annotation">
                  <code><a class="autorefs autorefs-internal" title="pydvl.influence.twice_differentiable.InverseHvpResult" href="../../twice_differentiable/#pydvl.influence.twice_differentiable.InverseHvpResult">InverseHvpResult</a></code>
              </span>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>Instance of <a class="autorefs autorefs-internal" href="../../twice_differentiable/#pydvl.influence.twice_differentiable.InverseHvpResult">InverseHvpResult</a>,
having an array that solves the inverse problem, i.e. it returns <span class="arithmatex">\(x\)</span> such that <span class="arithmatex">\(Hx = b\)</span>,
and a dictionary containing information about the solution.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-499">499</a></span>
<span class="normal"><a href="#__codelineno-0-500">500</a></span>
<span class="normal"><a href="#__codelineno-0-501">501</a></span>
<span class="normal"><a href="#__codelineno-0-502">502</a></span>
<span class="normal"><a href="#__codelineno-0-503">503</a></span>
<span class="normal"><a href="#__codelineno-0-504">504</a></span>
<span class="normal"><a href="#__codelineno-0-505">505</a></span>
<span class="normal"><a href="#__codelineno-0-506">506</a></span>
<span class="normal"><a href="#__codelineno-0-507">507</a></span>
<span class="normal"><a href="#__codelineno-0-508">508</a></span>
<span class="normal"><a href="#__codelineno-0-509">509</a></span>
<span class="normal"><a href="#__codelineno-0-510">510</a></span>
<span class="normal"><a href="#__codelineno-0-511">511</a></span>
<span class="normal"><a href="#__codelineno-0-512">512</a></span>
<span class="normal"><a href="#__codelineno-0-513">513</a></span>
<span class="normal"><a href="#__codelineno-0-514">514</a></span>
<span class="normal"><a href="#__codelineno-0-515">515</a></span>
<span class="normal"><a href="#__codelineno-0-516">516</a></span>
<span class="normal"><a href="#__codelineno-0-517">517</a></span>
<span class="normal"><a href="#__codelineno-0-518">518</a></span>
<span class="normal"><a href="#__codelineno-0-519">519</a></span>
<span class="normal"><a href="#__codelineno-0-520">520</a></span>
<span class="normal"><a href="#__codelineno-0-521">521</a></span>
<span class="normal"><a href="#__codelineno-0-522">522</a></span>
<span class="normal"><a href="#__codelineno-0-523">523</a></span>
<span class="normal"><a href="#__codelineno-0-524">524</a></span>
<span class="normal"><a href="#__codelineno-0-525">525</a></span>
<span class="normal"><a href="#__codelineno-0-526">526</a></span>
<span class="normal"><a href="#__codelineno-0-527">527</a></span>
<span class="normal"><a href="#__codelineno-0-528">528</a></span>
<span class="normal"><a href="#__codelineno-0-529">529</a></span>
<span class="normal"><a href="#__codelineno-0-530">530</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-499"><a id="__codelineno-0-499" name="__codelineno-0-499"></a><span class="nd">@InversionRegistry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">TorchTwiceDifferentiable</span><span class="p">,</span> <span class="n">InversionMethod</span><span class="o">.</span><span class="n">Direct</span><span class="p">)</span>
</span><span id="__span-0-500"><a id="__codelineno-0-500" name="__codelineno-0-500"></a><span class="k">def</span> <span class="nf">solve_linear</span><span class="p">(</span>
</span><span id="__span-0-501"><a id="__codelineno-0-501" name="__codelineno-0-501"></a>    <span class="n">model</span><span class="p">:</span> <span class="n">TorchTwiceDifferentiable</span><span class="p">,</span>
</span><span id="__span-0-502"><a id="__codelineno-0-502" name="__codelineno-0-502"></a>    <span class="n">training_data</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
</span><span id="__span-0-503"><a id="__codelineno-0-503" name="__codelineno-0-503"></a>    <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-504"><a id="__codelineno-0-504" name="__codelineno-0-504"></a>    <span class="n">hessian_perturbation</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-505"><a id="__codelineno-0-505" name="__codelineno-0-505"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">InverseHvpResult</span><span class="p">:</span>
</span><span id="__span-0-506"><a id="__codelineno-0-506" name="__codelineno-0-506"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-507"><a id="__codelineno-0-507" name="__codelineno-0-507"></a><span class="sd">    Given a model and training data, it finds x such that \(Hx = b\), with \(H\) being the model hessian.</span>
</span><span id="__span-0-508"><a id="__codelineno-0-508" name="__codelineno-0-508"></a>
</span><span id="__span-0-509"><a id="__codelineno-0-509" name="__codelineno-0-509"></a><span class="sd">    Args:</span>
</span><span id="__span-0-510"><a id="__codelineno-0-510" name="__codelineno-0-510"></a><span class="sd">        model: A model wrapped in the TwiceDifferentiable interface.</span>
</span><span id="__span-0-511"><a id="__codelineno-0-511" name="__codelineno-0-511"></a><span class="sd">        training_data: A DataLoader containing the training data.</span>
</span><span id="__span-0-512"><a id="__codelineno-0-512" name="__codelineno-0-512"></a><span class="sd">        b: A vector or matrix, the right hand side of the equation \(Hx = b\).</span>
</span><span id="__span-0-513"><a id="__codelineno-0-513" name="__codelineno-0-513"></a><span class="sd">        hessian_perturbation: Regularization of the hessian.</span>
</span><span id="__span-0-514"><a id="__codelineno-0-514" name="__codelineno-0-514"></a>
</span><span id="__span-0-515"><a id="__codelineno-0-515" name="__codelineno-0-515"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-516"><a id="__codelineno-0-516" name="__codelineno-0-516"></a><span class="sd">        Instance of [InverseHvpResult][pydvl.influence.twice_differentiable.InverseHvpResult],</span>
</span><span id="__span-0-517"><a id="__codelineno-0-517" name="__codelineno-0-517"></a><span class="sd">            having an array that solves the inverse problem, i.e. it returns \(x\) such that \(Hx = b\),</span>
</span><span id="__span-0-518"><a id="__codelineno-0-518" name="__codelineno-0-518"></a><span class="sd">            and a dictionary containing information about the solution.</span>
</span><span id="__span-0-519"><a id="__codelineno-0-519" name="__codelineno-0-519"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-520"><a id="__codelineno-0-520" name="__codelineno-0-520"></a>
</span><span id="__span-0-521"><a id="__codelineno-0-521" name="__codelineno-0-521"></a>    <span class="n">all_x</span><span class="p">,</span> <span class="n">all_y</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
</span><span id="__span-0-522"><a id="__codelineno-0-522" name="__codelineno-0-522"></a>    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">training_data</span><span class="p">:</span>
</span><span id="__span-0-523"><a id="__codelineno-0-523" name="__codelineno-0-523"></a>        <span class="n">all_x</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-524"><a id="__codelineno-0-524" name="__codelineno-0-524"></a>        <span class="n">all_y</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</span><span id="__span-0-525"><a id="__codelineno-0-525" name="__codelineno-0-525"></a>    <span class="n">hessian</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">hessian</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_x</span><span class="p">),</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">(</span><span class="n">all_y</span><span class="p">))</span>
</span><span id="__span-0-526"><a id="__codelineno-0-526" name="__codelineno-0-526"></a>    <span class="n">matrix</span> <span class="o">=</span> <span class="n">hessian</span> <span class="o">+</span> <span class="n">hessian_perturbation</span> <span class="o">*</span> <span class="n">torch</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span>
</span><span id="__span-0-527"><a id="__codelineno-0-527" name="__codelineno-0-527"></a>        <span class="n">model</span><span class="o">.</span><span class="n">num_params</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">model</span><span class="o">.</span><span class="n">device</span>
</span><span id="__span-0-528"><a id="__codelineno-0-528" name="__codelineno-0-528"></a>    <span class="p">)</span>
</span><span id="__span-0-529"><a id="__codelineno-0-529" name="__codelineno-0-529"></a>    <span class="n">info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;hessian&quot;</span><span class="p">:</span> <span class="n">hessian</span><span class="p">}</span>
</span><span id="__span-0-530"><a id="__codelineno-0-530" name="__codelineno-0-530"></a>    <span class="k">return</span> <span class="n">InverseHvpResult</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">T</span><span class="p">)</span><span class="o">.</span><span class="n">T</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pydvl.influence.torch.torch_differentiable.solve_batch_cg" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">solve_batch_cg</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hessian_perturbation</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#pydvl.influence.torch.torch_differentiable.solve_batch_cg" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Given a model and training data, it uses conjugate gradient to calculate the
inverse of the Hessian Vector Product. More precisely, it finds x such that <span class="arithmatex">\(Hx =
b\)</span>, with <span class="arithmatex">\(H\)</span> being the model hessian. For more info, see
<a href="https://en.wikipedia.org/wiki/Conjugate_gradient_method">Wikipedia</a>.</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>model</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A model wrapped in the TwiceDifferentiable interface.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-internal" title="pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable" href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable">TorchTwiceDifferentiable</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>training_data</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A DataLoader containing the training data.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.utils.data.DataLoader" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">DataLoader</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>b</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A vector or matrix, the right hand side of the equation <span class="arithmatex">\(Hx = b\)</span>.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>hessian_perturbation</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Regularization of the hessian.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>0.0</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>x0</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Initial guess for hvp. If None, defaults to b.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>rtol</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Maximum relative tolerance of result.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>1e-07</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>atol</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Absolute tolerance of result.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>1e-07</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>maxiter</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Maximum number of iterations. If None, defaults to 10*len(b).</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>progress</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>If True, display progress bars.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>False</code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <span class="doc-returns-annotation">
                  <code><a class="autorefs autorefs-internal" title="pydvl.influence.twice_differentiable.InverseHvpResult" href="../../twice_differentiable/#pydvl.influence.twice_differentiable.InverseHvpResult">InverseHvpResult</a></code>
              </span>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>Instance of <a class="autorefs autorefs-internal" href="../../twice_differentiable/#pydvl.influence.twice_differentiable.InverseHvpResult">InverseHvpResult</a>,
having a matrix of shape [NxP] with each line being a solution of <span class="arithmatex">\(Ax=b\)</span>,
and a dictionary containing information about the convergence of CG,
one entry for each line of the matrix.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-533">533</a></span>
<span class="normal"><a href="#__codelineno-0-534">534</a></span>
<span class="normal"><a href="#__codelineno-0-535">535</a></span>
<span class="normal"><a href="#__codelineno-0-536">536</a></span>
<span class="normal"><a href="#__codelineno-0-537">537</a></span>
<span class="normal"><a href="#__codelineno-0-538">538</a></span>
<span class="normal"><a href="#__codelineno-0-539">539</a></span>
<span class="normal"><a href="#__codelineno-0-540">540</a></span>
<span class="normal"><a href="#__codelineno-0-541">541</a></span>
<span class="normal"><a href="#__codelineno-0-542">542</a></span>
<span class="normal"><a href="#__codelineno-0-543">543</a></span>
<span class="normal"><a href="#__codelineno-0-544">544</a></span>
<span class="normal"><a href="#__codelineno-0-545">545</a></span>
<span class="normal"><a href="#__codelineno-0-546">546</a></span>
<span class="normal"><a href="#__codelineno-0-547">547</a></span>
<span class="normal"><a href="#__codelineno-0-548">548</a></span>
<span class="normal"><a href="#__codelineno-0-549">549</a></span>
<span class="normal"><a href="#__codelineno-0-550">550</a></span>
<span class="normal"><a href="#__codelineno-0-551">551</a></span>
<span class="normal"><a href="#__codelineno-0-552">552</a></span>
<span class="normal"><a href="#__codelineno-0-553">553</a></span>
<span class="normal"><a href="#__codelineno-0-554">554</a></span>
<span class="normal"><a href="#__codelineno-0-555">555</a></span>
<span class="normal"><a href="#__codelineno-0-556">556</a></span>
<span class="normal"><a href="#__codelineno-0-557">557</a></span>
<span class="normal"><a href="#__codelineno-0-558">558</a></span>
<span class="normal"><a href="#__codelineno-0-559">559</a></span>
<span class="normal"><a href="#__codelineno-0-560">560</a></span>
<span class="normal"><a href="#__codelineno-0-561">561</a></span>
<span class="normal"><a href="#__codelineno-0-562">562</a></span>
<span class="normal"><a href="#__codelineno-0-563">563</a></span>
<span class="normal"><a href="#__codelineno-0-564">564</a></span>
<span class="normal"><a href="#__codelineno-0-565">565</a></span>
<span class="normal"><a href="#__codelineno-0-566">566</a></span>
<span class="normal"><a href="#__codelineno-0-567">567</a></span>
<span class="normal"><a href="#__codelineno-0-568">568</a></span>
<span class="normal"><a href="#__codelineno-0-569">569</a></span>
<span class="normal"><a href="#__codelineno-0-570">570</a></span>
<span class="normal"><a href="#__codelineno-0-571">571</a></span>
<span class="normal"><a href="#__codelineno-0-572">572</a></span>
<span class="normal"><a href="#__codelineno-0-573">573</a></span>
<span class="normal"><a href="#__codelineno-0-574">574</a></span>
<span class="normal"><a href="#__codelineno-0-575">575</a></span>
<span class="normal"><a href="#__codelineno-0-576">576</a></span>
<span class="normal"><a href="#__codelineno-0-577">577</a></span>
<span class="normal"><a href="#__codelineno-0-578">578</a></span>
<span class="normal"><a href="#__codelineno-0-579">579</a></span>
<span class="normal"><a href="#__codelineno-0-580">580</a></span>
<span class="normal"><a href="#__codelineno-0-581">581</a></span>
<span class="normal"><a href="#__codelineno-0-582">582</a></span>
<span class="normal"><a href="#__codelineno-0-583">583</a></span>
<span class="normal"><a href="#__codelineno-0-584">584</a></span>
<span class="normal"><a href="#__codelineno-0-585">585</a></span>
<span class="normal"><a href="#__codelineno-0-586">586</a></span>
<span class="normal"><a href="#__codelineno-0-587">587</a></span>
<span class="normal"><a href="#__codelineno-0-588">588</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-533"><a id="__codelineno-0-533" name="__codelineno-0-533"></a><span class="nd">@InversionRegistry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">TorchTwiceDifferentiable</span><span class="p">,</span> <span class="n">InversionMethod</span><span class="o">.</span><span class="n">Cg</span><span class="p">)</span>
</span><span id="__span-0-534"><a id="__codelineno-0-534" name="__codelineno-0-534"></a><span class="k">def</span> <span class="nf">solve_batch_cg</span><span class="p">(</span>
</span><span id="__span-0-535"><a id="__codelineno-0-535" name="__codelineno-0-535"></a>    <span class="n">model</span><span class="p">:</span> <span class="n">TorchTwiceDifferentiable</span><span class="p">,</span>
</span><span id="__span-0-536"><a id="__codelineno-0-536" name="__codelineno-0-536"></a>    <span class="n">training_data</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
</span><span id="__span-0-537"><a id="__codelineno-0-537" name="__codelineno-0-537"></a>    <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-538"><a id="__codelineno-0-538" name="__codelineno-0-538"></a>    <span class="n">hessian_perturbation</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-539"><a id="__codelineno-0-539" name="__codelineno-0-539"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-540"><a id="__codelineno-0-540" name="__codelineno-0-540"></a>    <span class="n">x0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-541"><a id="__codelineno-0-541" name="__codelineno-0-541"></a>    <span class="n">rtol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-7</span><span class="p">,</span>
</span><span id="__span-0-542"><a id="__codelineno-0-542" name="__codelineno-0-542"></a>    <span class="n">atol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-7</span><span class="p">,</span>
</span><span id="__span-0-543"><a id="__codelineno-0-543" name="__codelineno-0-543"></a>    <span class="n">maxiter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-544"><a id="__codelineno-0-544" name="__codelineno-0-544"></a>    <span class="n">progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-545"><a id="__codelineno-0-545" name="__codelineno-0-545"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">InverseHvpResult</span><span class="p">:</span>
</span><span id="__span-0-546"><a id="__codelineno-0-546" name="__codelineno-0-546"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-547"><a id="__codelineno-0-547" name="__codelineno-0-547"></a><span class="sd">    Given a model and training data, it uses conjugate gradient to calculate the</span>
</span><span id="__span-0-548"><a id="__codelineno-0-548" name="__codelineno-0-548"></a><span class="sd">    inverse of the Hessian Vector Product. More precisely, it finds x such that \(Hx =</span>
</span><span id="__span-0-549"><a id="__codelineno-0-549" name="__codelineno-0-549"></a><span class="sd">    b\), with \(H\) being the model hessian. For more info, see</span>
</span><span id="__span-0-550"><a id="__codelineno-0-550" name="__codelineno-0-550"></a><span class="sd">    [Wikipedia](https://en.wikipedia.org/wiki/Conjugate_gradient_method).</span>
</span><span id="__span-0-551"><a id="__codelineno-0-551" name="__codelineno-0-551"></a>
</span><span id="__span-0-552"><a id="__codelineno-0-552" name="__codelineno-0-552"></a><span class="sd">    Args:</span>
</span><span id="__span-0-553"><a id="__codelineno-0-553" name="__codelineno-0-553"></a><span class="sd">        model: A model wrapped in the TwiceDifferentiable interface.</span>
</span><span id="__span-0-554"><a id="__codelineno-0-554" name="__codelineno-0-554"></a><span class="sd">        training_data: A DataLoader containing the training data.</span>
</span><span id="__span-0-555"><a id="__codelineno-0-555" name="__codelineno-0-555"></a><span class="sd">        b: A vector or matrix, the right hand side of the equation \(Hx = b\).</span>
</span><span id="__span-0-556"><a id="__codelineno-0-556" name="__codelineno-0-556"></a><span class="sd">        hessian_perturbation: Regularization of the hessian.</span>
</span><span id="__span-0-557"><a id="__codelineno-0-557" name="__codelineno-0-557"></a><span class="sd">        x0: Initial guess for hvp. If None, defaults to b.</span>
</span><span id="__span-0-558"><a id="__codelineno-0-558" name="__codelineno-0-558"></a><span class="sd">        rtol: Maximum relative tolerance of result.</span>
</span><span id="__span-0-559"><a id="__codelineno-0-559" name="__codelineno-0-559"></a><span class="sd">        atol: Absolute tolerance of result.</span>
</span><span id="__span-0-560"><a id="__codelineno-0-560" name="__codelineno-0-560"></a><span class="sd">        maxiter: Maximum number of iterations. If None, defaults to 10*len(b).</span>
</span><span id="__span-0-561"><a id="__codelineno-0-561" name="__codelineno-0-561"></a><span class="sd">        progress: If True, display progress bars.</span>
</span><span id="__span-0-562"><a id="__codelineno-0-562" name="__codelineno-0-562"></a>
</span><span id="__span-0-563"><a id="__codelineno-0-563" name="__codelineno-0-563"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-564"><a id="__codelineno-0-564" name="__codelineno-0-564"></a><span class="sd">        Instance of [InverseHvpResult][pydvl.influence.twice_differentiable.InverseHvpResult],</span>
</span><span id="__span-0-565"><a id="__codelineno-0-565" name="__codelineno-0-565"></a><span class="sd">            having a matrix of shape [NxP] with each line being a solution of \(Ax=b\),</span>
</span><span id="__span-0-566"><a id="__codelineno-0-566" name="__codelineno-0-566"></a><span class="sd">            and a dictionary containing information about the convergence of CG,</span>
</span><span id="__span-0-567"><a id="__codelineno-0-567" name="__codelineno-0-567"></a><span class="sd">            one entry for each line of the matrix.</span>
</span><span id="__span-0-568"><a id="__codelineno-0-568" name="__codelineno-0-568"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-569"><a id="__codelineno-0-569" name="__codelineno-0-569"></a>
</span><span id="__span-0-570"><a id="__codelineno-0-570" name="__codelineno-0-570"></a>    <span class="n">total_grad_xy</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-571"><a id="__codelineno-0-571" name="__codelineno-0-571"></a>    <span class="n">total_points</span> <span class="o">=</span> <span class="mi">0</span>
</span><span id="__span-0-572"><a id="__codelineno-0-572" name="__codelineno-0-572"></a>    <span class="k">for</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="ow">in</span> <span class="n">maybe_progress</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">progress</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Batch Train Gradients&quot;</span><span class="p">):</span>
</span><span id="__span-0-573"><a id="__codelineno-0-573" name="__codelineno-0-573"></a>        <span class="n">grad_xy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-574"><a id="__codelineno-0-574" name="__codelineno-0-574"></a>        <span class="n">total_grad_xy</span> <span class="o">+=</span> <span class="n">grad_xy</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-575"><a id="__codelineno-0-575" name="__codelineno-0-575"></a>        <span class="n">total_points</span> <span class="o">+=</span> <span class="nb">len</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
</span><span id="__span-0-576"><a id="__codelineno-0-576" name="__codelineno-0-576"></a>    <span class="n">backprop_on</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span>
</span><span id="__span-0-577"><a id="__codelineno-0-577" name="__codelineno-0-577"></a>    <span class="n">reg_hvp</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">mvp</span><span class="p">(</span>
</span><span id="__span-0-578"><a id="__codelineno-0-578" name="__codelineno-0-578"></a>        <span class="n">total_grad_xy</span> <span class="o">/</span> <span class="n">total_points</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">backprop_on</span>
</span><span id="__span-0-579"><a id="__codelineno-0-579" name="__codelineno-0-579"></a>    <span class="p">)</span> <span class="o">+</span> <span class="n">hessian_perturbation</span> <span class="o">*</span> <span class="n">v</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="__span-0-580"><a id="__codelineno-0-580" name="__codelineno-0-580"></a>    <span class="n">batch_cg</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</span><span id="__span-0-581"><a id="__codelineno-0-581" name="__codelineno-0-581"></a>    <span class="n">info</span> <span class="o">=</span> <span class="p">{}</span>
</span><span id="__span-0-582"><a id="__codelineno-0-582" name="__codelineno-0-582"></a>    <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">bi</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">maybe_progress</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">progress</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Conjugate gradient&quot;</span><span class="p">)):</span>
</span><span id="__span-0-583"><a id="__codelineno-0-583" name="__codelineno-0-583"></a>        <span class="n">batch_result</span><span class="p">,</span> <span class="n">batch_info</span> <span class="o">=</span> <span class="n">solve_cg</span><span class="p">(</span>
</span><span id="__span-0-584"><a id="__codelineno-0-584" name="__codelineno-0-584"></a>            <span class="n">reg_hvp</span><span class="p">,</span> <span class="n">bi</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="n">x0</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="n">rtol</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="n">atol</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="n">maxiter</span>
</span><span id="__span-0-585"><a id="__codelineno-0-585" name="__codelineno-0-585"></a>        <span class="p">)</span>
</span><span id="__span-0-586"><a id="__codelineno-0-586" name="__codelineno-0-586"></a>        <span class="n">batch_cg</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_result</span>
</span><span id="__span-0-587"><a id="__codelineno-0-587" name="__codelineno-0-587"></a>        <span class="n">info</span><span class="p">[</span><span class="sa">f</span><span class="s2">&quot;batch_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">batch_info</span>
</span><span id="__span-0-588"><a id="__codelineno-0-588" name="__codelineno-0-588"></a>    <span class="k">return</span> <span class="n">InverseHvpResult</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">batch_cg</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pydvl.influence.torch.torch_differentiable.solve_cg" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">solve_cg</span><span class="p">(</span><span class="n">hvp</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">x0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-07</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span></code>

<a href="#pydvl.influence.torch.torch_differentiable.solve_cg" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Conjugate gradient solver for the Hessian vector product.</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>hvp</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A callable Hvp, operating with tensors of size N.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Callable" href="https://docs.python.org/3/library/typing.html#typing.Callable">Callable</a>[[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>], <a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>b</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A vector or matrix, the right hand side of the equation <span class="arithmatex">\(Hx = b\)</span>.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>x0</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Initial guess for hvp.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>rtol</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Maximum relative tolerance of result.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>1e-07</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>atol</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Absolute tolerance of result.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>1e-07</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>maxiter</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Maximum number of iterations. If None, defaults to 10*len(b).</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <span class="doc-returns-annotation">
                  <code><a class="autorefs autorefs-internal" title="pydvl.influence.twice_differentiable.InverseHvpResult" href="../../twice_differentiable/#pydvl.influence.twice_differentiable.InverseHvpResult">InverseHvpResult</a></code>
              </span>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>Instance of <a class="autorefs autorefs-internal" href="../../twice_differentiable/#pydvl.influence.twice_differentiable.InverseHvpResult">InverseHvpResult</a>,
with a vector x, solution of <span class="arithmatex">\(Ax=b\)</span>, and a dictionary containing
information about the convergence of CG.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-591">591</a></span>
<span class="normal"><a href="#__codelineno-0-592">592</a></span>
<span class="normal"><a href="#__codelineno-0-593">593</a></span>
<span class="normal"><a href="#__codelineno-0-594">594</a></span>
<span class="normal"><a href="#__codelineno-0-595">595</a></span>
<span class="normal"><a href="#__codelineno-0-596">596</a></span>
<span class="normal"><a href="#__codelineno-0-597">597</a></span>
<span class="normal"><a href="#__codelineno-0-598">598</a></span>
<span class="normal"><a href="#__codelineno-0-599">599</a></span>
<span class="normal"><a href="#__codelineno-0-600">600</a></span>
<span class="normal"><a href="#__codelineno-0-601">601</a></span>
<span class="normal"><a href="#__codelineno-0-602">602</a></span>
<span class="normal"><a href="#__codelineno-0-603">603</a></span>
<span class="normal"><a href="#__codelineno-0-604">604</a></span>
<span class="normal"><a href="#__codelineno-0-605">605</a></span>
<span class="normal"><a href="#__codelineno-0-606">606</a></span>
<span class="normal"><a href="#__codelineno-0-607">607</a></span>
<span class="normal"><a href="#__codelineno-0-608">608</a></span>
<span class="normal"><a href="#__codelineno-0-609">609</a></span>
<span class="normal"><a href="#__codelineno-0-610">610</a></span>
<span class="normal"><a href="#__codelineno-0-611">611</a></span>
<span class="normal"><a href="#__codelineno-0-612">612</a></span>
<span class="normal"><a href="#__codelineno-0-613">613</a></span>
<span class="normal"><a href="#__codelineno-0-614">614</a></span>
<span class="normal"><a href="#__codelineno-0-615">615</a></span>
<span class="normal"><a href="#__codelineno-0-616">616</a></span>
<span class="normal"><a href="#__codelineno-0-617">617</a></span>
<span class="normal"><a href="#__codelineno-0-618">618</a></span>
<span class="normal"><a href="#__codelineno-0-619">619</a></span>
<span class="normal"><a href="#__codelineno-0-620">620</a></span>
<span class="normal"><a href="#__codelineno-0-621">621</a></span>
<span class="normal"><a href="#__codelineno-0-622">622</a></span>
<span class="normal"><a href="#__codelineno-0-623">623</a></span>
<span class="normal"><a href="#__codelineno-0-624">624</a></span>
<span class="normal"><a href="#__codelineno-0-625">625</a></span>
<span class="normal"><a href="#__codelineno-0-626">626</a></span>
<span class="normal"><a href="#__codelineno-0-627">627</a></span>
<span class="normal"><a href="#__codelineno-0-628">628</a></span>
<span class="normal"><a href="#__codelineno-0-629">629</a></span>
<span class="normal"><a href="#__codelineno-0-630">630</a></span>
<span class="normal"><a href="#__codelineno-0-631">631</a></span>
<span class="normal"><a href="#__codelineno-0-632">632</a></span>
<span class="normal"><a href="#__codelineno-0-633">633</a></span>
<span class="normal"><a href="#__codelineno-0-634">634</a></span>
<span class="normal"><a href="#__codelineno-0-635">635</a></span>
<span class="normal"><a href="#__codelineno-0-636">636</a></span>
<span class="normal"><a href="#__codelineno-0-637">637</a></span>
<span class="normal"><a href="#__codelineno-0-638">638</a></span>
<span class="normal"><a href="#__codelineno-0-639">639</a></span>
<span class="normal"><a href="#__codelineno-0-640">640</a></span>
<span class="normal"><a href="#__codelineno-0-641">641</a></span>
<span class="normal"><a href="#__codelineno-0-642">642</a></span>
<span class="normal"><a href="#__codelineno-0-643">643</a></span>
<span class="normal"><a href="#__codelineno-0-644">644</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-591"><a id="__codelineno-0-591" name="__codelineno-0-591"></a><span class="k">def</span> <span class="nf">solve_cg</span><span class="p">(</span>
</span><span id="__span-0-592"><a id="__codelineno-0-592" name="__codelineno-0-592"></a>    <span class="n">hvp</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span>
</span><span id="__span-0-593"><a id="__codelineno-0-593" name="__codelineno-0-593"></a>    <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-594"><a id="__codelineno-0-594" name="__codelineno-0-594"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-595"><a id="__codelineno-0-595" name="__codelineno-0-595"></a>    <span class="n">x0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-596"><a id="__codelineno-0-596" name="__codelineno-0-596"></a>    <span class="n">rtol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-7</span><span class="p">,</span>
</span><span id="__span-0-597"><a id="__codelineno-0-597" name="__codelineno-0-597"></a>    <span class="n">atol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-7</span><span class="p">,</span>
</span><span id="__span-0-598"><a id="__codelineno-0-598" name="__codelineno-0-598"></a>    <span class="n">maxiter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-599"><a id="__codelineno-0-599" name="__codelineno-0-599"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">InverseHvpResult</span><span class="p">:</span>
</span><span id="__span-0-600"><a id="__codelineno-0-600" name="__codelineno-0-600"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-601"><a id="__codelineno-0-601" name="__codelineno-0-601"></a><span class="sd">    Conjugate gradient solver for the Hessian vector product.</span>
</span><span id="__span-0-602"><a id="__codelineno-0-602" name="__codelineno-0-602"></a>
</span><span id="__span-0-603"><a id="__codelineno-0-603" name="__codelineno-0-603"></a><span class="sd">    Args:</span>
</span><span id="__span-0-604"><a id="__codelineno-0-604" name="__codelineno-0-604"></a><span class="sd">        hvp: A callable Hvp, operating with tensors of size N.</span>
</span><span id="__span-0-605"><a id="__codelineno-0-605" name="__codelineno-0-605"></a><span class="sd">        b: A vector or matrix, the right hand side of the equation \(Hx = b\).</span>
</span><span id="__span-0-606"><a id="__codelineno-0-606" name="__codelineno-0-606"></a><span class="sd">        x0: Initial guess for hvp.</span>
</span><span id="__span-0-607"><a id="__codelineno-0-607" name="__codelineno-0-607"></a><span class="sd">        rtol: Maximum relative tolerance of result.</span>
</span><span id="__span-0-608"><a id="__codelineno-0-608" name="__codelineno-0-608"></a><span class="sd">        atol: Absolute tolerance of result.</span>
</span><span id="__span-0-609"><a id="__codelineno-0-609" name="__codelineno-0-609"></a><span class="sd">        maxiter: Maximum number of iterations. If None, defaults to 10*len(b).</span>
</span><span id="__span-0-610"><a id="__codelineno-0-610" name="__codelineno-0-610"></a>
</span><span id="__span-0-611"><a id="__codelineno-0-611" name="__codelineno-0-611"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-612"><a id="__codelineno-0-612" name="__codelineno-0-612"></a><span class="sd">        Instance of [InverseHvpResult][pydvl.influence.twice_differentiable.InverseHvpResult],</span>
</span><span id="__span-0-613"><a id="__codelineno-0-613" name="__codelineno-0-613"></a><span class="sd">            with a vector x, solution of \(Ax=b\), and a dictionary containing</span>
</span><span id="__span-0-614"><a id="__codelineno-0-614" name="__codelineno-0-614"></a><span class="sd">            information about the convergence of CG.</span>
</span><span id="__span-0-615"><a id="__codelineno-0-615" name="__codelineno-0-615"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-616"><a id="__codelineno-0-616" name="__codelineno-0-616"></a>
</span><span id="__span-0-617"><a id="__codelineno-0-617" name="__codelineno-0-617"></a>    <span class="k">if</span> <span class="n">x0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-618"><a id="__codelineno-0-618" name="__codelineno-0-618"></a>        <span class="n">x0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</span><span id="__span-0-619"><a id="__codelineno-0-619" name="__codelineno-0-619"></a>    <span class="k">if</span> <span class="n">maxiter</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-620"><a id="__codelineno-0-620" name="__codelineno-0-620"></a>        <span class="n">maxiter</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">b</span><span class="p">)</span> <span class="o">*</span> <span class="mi">10</span>
</span><span id="__span-0-621"><a id="__codelineno-0-621" name="__codelineno-0-621"></a>
</span><span id="__span-0-622"><a id="__codelineno-0-622" name="__codelineno-0-622"></a>    <span class="n">y_norm</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="n">b</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span id="__span-0-623"><a id="__codelineno-0-623" name="__codelineno-0-623"></a>    <span class="n">stopping_val</span> <span class="o">=</span> <span class="nb">max</span><span class="p">([</span><span class="n">rtol</span><span class="o">**</span><span class="mi">2</span> <span class="o">*</span> <span class="n">y_norm</span><span class="p">,</span> <span class="n">atol</span><span class="o">**</span><span class="mi">2</span><span class="p">])</span>
</span><span id="__span-0-624"><a id="__codelineno-0-624" name="__codelineno-0-624"></a>
</span><span id="__span-0-625"><a id="__codelineno-0-625" name="__codelineno-0-625"></a>    <span class="n">x</span> <span class="o">=</span> <span class="n">x0</span>
</span><span id="__span-0-626"><a id="__codelineno-0-626" name="__codelineno-0-626"></a>    <span class="n">p</span> <span class="o">=</span> <span class="n">r</span> <span class="o">=</span> <span class="p">(</span><span class="n">b</span> <span class="o">-</span> <span class="n">hvp</span><span class="p">(</span><span class="n">x</span><span class="p">))</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">type</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">float64</span><span class="p">)</span>
</span><span id="__span-0-627"><a id="__codelineno-0-627" name="__codelineno-0-627"></a>    <span class="n">gamma</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">r</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span id="__span-0-628"><a id="__codelineno-0-628" name="__codelineno-0-628"></a>    <span class="n">optimal</span> <span class="o">=</span> <span class="kc">False</span>
</span><span id="__span-0-629"><a id="__codelineno-0-629" name="__codelineno-0-629"></a>
</span><span id="__span-0-630"><a id="__codelineno-0-630" name="__codelineno-0-630"></a>    <span class="k">for</span> <span class="n">k</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">maxiter</span><span class="p">):</span>
</span><span id="__span-0-631"><a id="__codelineno-0-631" name="__codelineno-0-631"></a>        <span class="k">if</span> <span class="n">gamma</span> <span class="o">&lt;</span> <span class="n">stopping_val</span><span class="p">:</span>
</span><span id="__span-0-632"><a id="__codelineno-0-632" name="__codelineno-0-632"></a>            <span class="n">optimal</span> <span class="o">=</span> <span class="kc">True</span>
</span><span id="__span-0-633"><a id="__codelineno-0-633" name="__codelineno-0-633"></a>            <span class="k">break</span>
</span><span id="__span-0-634"><a id="__codelineno-0-634" name="__codelineno-0-634"></a>        <span class="n">Ap</span> <span class="o">=</span> <span class="n">hvp</span><span class="p">(</span><span class="n">p</span><span class="p">)</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span>
</span><span id="__span-0-635"><a id="__codelineno-0-635" name="__codelineno-0-635"></a>        <span class="n">alpha</span> <span class="o">=</span> <span class="n">gamma</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">p</span><span class="p">,</span> <span class="n">Ap</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span id="__span-0-636"><a id="__codelineno-0-636" name="__codelineno-0-636"></a>        <span class="n">x</span> <span class="o">+=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">p</span>
</span><span id="__span-0-637"><a id="__codelineno-0-637" name="__codelineno-0-637"></a>        <span class="n">r</span> <span class="o">-=</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">Ap</span>
</span><span id="__span-0-638"><a id="__codelineno-0-638" name="__codelineno-0-638"></a>        <span class="n">gamma_</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">r</span><span class="p">))</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
</span><span id="__span-0-639"><a id="__codelineno-0-639" name="__codelineno-0-639"></a>        <span class="n">beta</span> <span class="o">=</span> <span class="n">gamma_</span> <span class="o">/</span> <span class="n">gamma</span>
</span><span id="__span-0-640"><a id="__codelineno-0-640" name="__codelineno-0-640"></a>        <span class="n">gamma</span> <span class="o">=</span> <span class="n">gamma_</span>
</span><span id="__span-0-641"><a id="__codelineno-0-641" name="__codelineno-0-641"></a>        <span class="n">p</span> <span class="o">=</span> <span class="n">r</span> <span class="o">+</span> <span class="n">beta</span> <span class="o">*</span> <span class="n">p</span>
</span><span id="__span-0-642"><a id="__codelineno-0-642" name="__codelineno-0-642"></a>
</span><span id="__span-0-643"><a id="__codelineno-0-643" name="__codelineno-0-643"></a>    <span class="n">info</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;niter&quot;</span><span class="p">:</span> <span class="n">k</span><span class="p">,</span> <span class="s2">&quot;optimal&quot;</span><span class="p">:</span> <span class="n">optimal</span><span class="p">,</span> <span class="s2">&quot;gamma&quot;</span><span class="p">:</span> <span class="n">gamma</span><span class="p">}</span>
</span><span id="__span-0-644"><a id="__codelineno-0-644" name="__codelineno-0-644"></a>    <span class="k">return</span> <span class="n">InverseHvpResult</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">x</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pydvl.influence.torch.torch_differentiable.solve_lissa" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">solve_lissa</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hessian_perturbation</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">maxiter</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">dampen</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">scale</span><span class="o">=</span><span class="mf">10.0</span><span class="p">,</span> <span class="n">h0</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">rtol</span><span class="o">=</span><span class="mf">0.0001</span><span class="p">,</span> <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#pydvl.influence.torch.torch_differentiable.solve_lissa" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Uses LISSA, Linear time Stochastic Second-Order Algorithm, to iteratively
approximate the inverse Hessian. More precisely, it finds x s.t. <span class="arithmatex">\(Hx = b\)</span>,
with <span class="arithmatex">\(H\)</span> being the model's second derivative wrt. the parameters.
This is done with the update</p>
<div class="arithmatex">\[H^{-1}_{j+1} b = b + (I - d) \ H - \frac{H^{-1}_j b}{s},\]</div>
<p>where <span class="arithmatex">\(I\)</span> is the identity matrix, <span class="arithmatex">\(d\)</span> is a dampening term and <span class="arithmatex">\(s\)</span> a scaling
factor that are applied to help convergence. For details, see
(Koh and Liang, 2017)<sup><a href="#koh_liang_2017">1</a></sup> and the original paper
(Agarwal et. al.)<sup><a href="#agarwal_secondorder_2017">2</a></sup>.</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>model</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A model wrapped in the TwiceDifferentiable interface.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-internal" title="pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable" href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable">TorchTwiceDifferentiable</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>training_data</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A DataLoader containing the training data.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.utils.data.DataLoader" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">DataLoader</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>b</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A vector or matrix, the right hand side of the equation <span class="arithmatex">\(Hx = b\)</span>.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>hessian_perturbation</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Regularization of the hessian.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>0.0</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>maxiter</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Maximum number of iterations.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>1000</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>dampen</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Dampening factor, defaults to 0 for no dampening.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>0.0</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>scale</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Scaling factor, defaults to 10.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>10.0</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>h0</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Initial guess for hvp.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>rtol</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>tolerance to use for early stopping</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>0.0001</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>progress</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>If True, display progress bars.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>False</code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <span class="doc-returns-annotation">
                  <code><a class="autorefs autorefs-internal" title="pydvl.influence.twice_differentiable.InverseHvpResult" href="../../twice_differentiable/#pydvl.influence.twice_differentiable.InverseHvpResult">InverseHvpResult</a></code>
              </span>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>Instance of <a class="autorefs autorefs-internal" href="../../twice_differentiable/#pydvl.influence.twice_differentiable.InverseHvpResult">InverseHvpResult</a>, with a matrix of shape [NxP] with each line being a solution of <span class="arithmatex">\(Ax=b\)</span>,
and a dictionary containing information about the accuracy of the solution.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-647">647</a></span>
<span class="normal"><a href="#__codelineno-0-648">648</a></span>
<span class="normal"><a href="#__codelineno-0-649">649</a></span>
<span class="normal"><a href="#__codelineno-0-650">650</a></span>
<span class="normal"><a href="#__codelineno-0-651">651</a></span>
<span class="normal"><a href="#__codelineno-0-652">652</a></span>
<span class="normal"><a href="#__codelineno-0-653">653</a></span>
<span class="normal"><a href="#__codelineno-0-654">654</a></span>
<span class="normal"><a href="#__codelineno-0-655">655</a></span>
<span class="normal"><a href="#__codelineno-0-656">656</a></span>
<span class="normal"><a href="#__codelineno-0-657">657</a></span>
<span class="normal"><a href="#__codelineno-0-658">658</a></span>
<span class="normal"><a href="#__codelineno-0-659">659</a></span>
<span class="normal"><a href="#__codelineno-0-660">660</a></span>
<span class="normal"><a href="#__codelineno-0-661">661</a></span>
<span class="normal"><a href="#__codelineno-0-662">662</a></span>
<span class="normal"><a href="#__codelineno-0-663">663</a></span>
<span class="normal"><a href="#__codelineno-0-664">664</a></span>
<span class="normal"><a href="#__codelineno-0-665">665</a></span>
<span class="normal"><a href="#__codelineno-0-666">666</a></span>
<span class="normal"><a href="#__codelineno-0-667">667</a></span>
<span class="normal"><a href="#__codelineno-0-668">668</a></span>
<span class="normal"><a href="#__codelineno-0-669">669</a></span>
<span class="normal"><a href="#__codelineno-0-670">670</a></span>
<span class="normal"><a href="#__codelineno-0-671">671</a></span>
<span class="normal"><a href="#__codelineno-0-672">672</a></span>
<span class="normal"><a href="#__codelineno-0-673">673</a></span>
<span class="normal"><a href="#__codelineno-0-674">674</a></span>
<span class="normal"><a href="#__codelineno-0-675">675</a></span>
<span class="normal"><a href="#__codelineno-0-676">676</a></span>
<span class="normal"><a href="#__codelineno-0-677">677</a></span>
<span class="normal"><a href="#__codelineno-0-678">678</a></span>
<span class="normal"><a href="#__codelineno-0-679">679</a></span>
<span class="normal"><a href="#__codelineno-0-680">680</a></span>
<span class="normal"><a href="#__codelineno-0-681">681</a></span>
<span class="normal"><a href="#__codelineno-0-682">682</a></span>
<span class="normal"><a href="#__codelineno-0-683">683</a></span>
<span class="normal"><a href="#__codelineno-0-684">684</a></span>
<span class="normal"><a href="#__codelineno-0-685">685</a></span>
<span class="normal"><a href="#__codelineno-0-686">686</a></span>
<span class="normal"><a href="#__codelineno-0-687">687</a></span>
<span class="normal"><a href="#__codelineno-0-688">688</a></span>
<span class="normal"><a href="#__codelineno-0-689">689</a></span>
<span class="normal"><a href="#__codelineno-0-690">690</a></span>
<span class="normal"><a href="#__codelineno-0-691">691</a></span>
<span class="normal"><a href="#__codelineno-0-692">692</a></span>
<span class="normal"><a href="#__codelineno-0-693">693</a></span>
<span class="normal"><a href="#__codelineno-0-694">694</a></span>
<span class="normal"><a href="#__codelineno-0-695">695</a></span>
<span class="normal"><a href="#__codelineno-0-696">696</a></span>
<span class="normal"><a href="#__codelineno-0-697">697</a></span>
<span class="normal"><a href="#__codelineno-0-698">698</a></span>
<span class="normal"><a href="#__codelineno-0-699">699</a></span>
<span class="normal"><a href="#__codelineno-0-700">700</a></span>
<span class="normal"><a href="#__codelineno-0-701">701</a></span>
<span class="normal"><a href="#__codelineno-0-702">702</a></span>
<span class="normal"><a href="#__codelineno-0-703">703</a></span>
<span class="normal"><a href="#__codelineno-0-704">704</a></span>
<span class="normal"><a href="#__codelineno-0-705">705</a></span>
<span class="normal"><a href="#__codelineno-0-706">706</a></span>
<span class="normal"><a href="#__codelineno-0-707">707</a></span>
<span class="normal"><a href="#__codelineno-0-708">708</a></span>
<span class="normal"><a href="#__codelineno-0-709">709</a></span>
<span class="normal"><a href="#__codelineno-0-710">710</a></span>
<span class="normal"><a href="#__codelineno-0-711">711</a></span>
<span class="normal"><a href="#__codelineno-0-712">712</a></span>
<span class="normal"><a href="#__codelineno-0-713">713</a></span>
<span class="normal"><a href="#__codelineno-0-714">714</a></span>
<span class="normal"><a href="#__codelineno-0-715">715</a></span>
<span class="normal"><a href="#__codelineno-0-716">716</a></span>
<span class="normal"><a href="#__codelineno-0-717">717</a></span>
<span class="normal"><a href="#__codelineno-0-718">718</a></span>
<span class="normal"><a href="#__codelineno-0-719">719</a></span>
<span class="normal"><a href="#__codelineno-0-720">720</a></span>
<span class="normal"><a href="#__codelineno-0-721">721</a></span>
<span class="normal"><a href="#__codelineno-0-722">722</a></span>
<span class="normal"><a href="#__codelineno-0-723">723</a></span>
<span class="normal"><a href="#__codelineno-0-724">724</a></span>
<span class="normal"><a href="#__codelineno-0-725">725</a></span>
<span class="normal"><a href="#__codelineno-0-726">726</a></span>
<span class="normal"><a href="#__codelineno-0-727">727</a></span>
<span class="normal"><a href="#__codelineno-0-728">728</a></span>
<span class="normal"><a href="#__codelineno-0-729">729</a></span>
<span class="normal"><a href="#__codelineno-0-730">730</a></span>
<span class="normal"><a href="#__codelineno-0-731">731</a></span>
<span class="normal"><a href="#__codelineno-0-732">732</a></span>
<span class="normal"><a href="#__codelineno-0-733">733</a></span>
<span class="normal"><a href="#__codelineno-0-734">734</a></span>
<span class="normal"><a href="#__codelineno-0-735">735</a></span>
<span class="normal"><a href="#__codelineno-0-736">736</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-647"><a id="__codelineno-0-647" name="__codelineno-0-647"></a><span class="nd">@InversionRegistry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">TorchTwiceDifferentiable</span><span class="p">,</span> <span class="n">InversionMethod</span><span class="o">.</span><span class="n">Lissa</span><span class="p">)</span>
</span><span id="__span-0-648"><a id="__codelineno-0-648" name="__codelineno-0-648"></a><span class="k">def</span> <span class="nf">solve_lissa</span><span class="p">(</span>
</span><span id="__span-0-649"><a id="__codelineno-0-649" name="__codelineno-0-649"></a>    <span class="n">model</span><span class="p">:</span> <span class="n">TorchTwiceDifferentiable</span><span class="p">,</span>
</span><span id="__span-0-650"><a id="__codelineno-0-650" name="__codelineno-0-650"></a>    <span class="n">training_data</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
</span><span id="__span-0-651"><a id="__codelineno-0-651" name="__codelineno-0-651"></a>    <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-652"><a id="__codelineno-0-652" name="__codelineno-0-652"></a>    <span class="n">hessian_perturbation</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-653"><a id="__codelineno-0-653" name="__codelineno-0-653"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-654"><a id="__codelineno-0-654" name="__codelineno-0-654"></a>    <span class="n">maxiter</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1000</span><span class="p">,</span>
</span><span id="__span-0-655"><a id="__codelineno-0-655" name="__codelineno-0-655"></a>    <span class="n">dampen</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-656"><a id="__codelineno-0-656" name="__codelineno-0-656"></a>    <span class="n">scale</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">10.0</span><span class="p">,</span>
</span><span id="__span-0-657"><a id="__codelineno-0-657" name="__codelineno-0-657"></a>    <span class="n">h0</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-658"><a id="__codelineno-0-658" name="__codelineno-0-658"></a>    <span class="n">rtol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-4</span><span class="p">,</span>
</span><span id="__span-0-659"><a id="__codelineno-0-659" name="__codelineno-0-659"></a>    <span class="n">progress</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-660"><a id="__codelineno-0-660" name="__codelineno-0-660"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">InverseHvpResult</span><span class="p">:</span>
</span><span id="__span-0-661"><a id="__codelineno-0-661" name="__codelineno-0-661"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-662"><a id="__codelineno-0-662" name="__codelineno-0-662"></a><span class="sd">    Uses LISSA, Linear time Stochastic Second-Order Algorithm, to iteratively</span>
</span><span id="__span-0-663"><a id="__codelineno-0-663" name="__codelineno-0-663"></a><span class="sd">    approximate the inverse Hessian. More precisely, it finds x s.t. \(Hx = b\),</span>
</span><span id="__span-0-664"><a id="__codelineno-0-664" name="__codelineno-0-664"></a><span class="sd">    with \(H\) being the model&#39;s second derivative wrt. the parameters.</span>
</span><span id="__span-0-665"><a id="__codelineno-0-665" name="__codelineno-0-665"></a><span class="sd">    This is done with the update</span>
</span><span id="__span-0-666"><a id="__codelineno-0-666" name="__codelineno-0-666"></a>
</span><span id="__span-0-667"><a id="__codelineno-0-667" name="__codelineno-0-667"></a><span class="sd">    \[H^{-1}_{j+1} b = b + (I - d) \ H - \frac{H^{-1}_j b}{s},\]</span>
</span><span id="__span-0-668"><a id="__codelineno-0-668" name="__codelineno-0-668"></a>
</span><span id="__span-0-669"><a id="__codelineno-0-669" name="__codelineno-0-669"></a><span class="sd">    where \(I\) is the identity matrix, \(d\) is a dampening term and \(s\) a scaling</span>
</span><span id="__span-0-670"><a id="__codelineno-0-670" name="__codelineno-0-670"></a><span class="sd">    factor that are applied to help convergence. For details, see</span>
</span><span id="__span-0-671"><a id="__codelineno-0-671" name="__codelineno-0-671"></a><span class="sd">    (Koh and Liang, 2017)&lt;sup&gt;&lt;a href=&quot;#koh_liang_2017&quot;&gt;1&lt;/a&gt;&lt;/sup&gt; and the original paper</span>
</span><span id="__span-0-672"><a id="__codelineno-0-672" name="__codelineno-0-672"></a><span class="sd">    (Agarwal et. al.)&lt;sup&gt;&lt;a href=&quot;#agarwal_secondorder_2017&quot;&gt;2&lt;/a&gt;&lt;/sup&gt;.</span>
</span><span id="__span-0-673"><a id="__codelineno-0-673" name="__codelineno-0-673"></a>
</span><span id="__span-0-674"><a id="__codelineno-0-674" name="__codelineno-0-674"></a><span class="sd">    Args:</span>
</span><span id="__span-0-675"><a id="__codelineno-0-675" name="__codelineno-0-675"></a><span class="sd">        model: A model wrapped in the TwiceDifferentiable interface.</span>
</span><span id="__span-0-676"><a id="__codelineno-0-676" name="__codelineno-0-676"></a><span class="sd">        training_data: A DataLoader containing the training data.</span>
</span><span id="__span-0-677"><a id="__codelineno-0-677" name="__codelineno-0-677"></a><span class="sd">        b: A vector or matrix, the right hand side of the equation \(Hx = b\).</span>
</span><span id="__span-0-678"><a id="__codelineno-0-678" name="__codelineno-0-678"></a><span class="sd">        hessian_perturbation: Regularization of the hessian.</span>
</span><span id="__span-0-679"><a id="__codelineno-0-679" name="__codelineno-0-679"></a><span class="sd">        maxiter: Maximum number of iterations.</span>
</span><span id="__span-0-680"><a id="__codelineno-0-680" name="__codelineno-0-680"></a><span class="sd">        dampen: Dampening factor, defaults to 0 for no dampening.</span>
</span><span id="__span-0-681"><a id="__codelineno-0-681" name="__codelineno-0-681"></a><span class="sd">        scale: Scaling factor, defaults to 10.</span>
</span><span id="__span-0-682"><a id="__codelineno-0-682" name="__codelineno-0-682"></a><span class="sd">        h0: Initial guess for hvp.</span>
</span><span id="__span-0-683"><a id="__codelineno-0-683" name="__codelineno-0-683"></a><span class="sd">        rtol: tolerance to use for early stopping</span>
</span><span id="__span-0-684"><a id="__codelineno-0-684" name="__codelineno-0-684"></a><span class="sd">        progress: If True, display progress bars.</span>
</span><span id="__span-0-685"><a id="__codelineno-0-685" name="__codelineno-0-685"></a>
</span><span id="__span-0-686"><a id="__codelineno-0-686" name="__codelineno-0-686"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-687"><a id="__codelineno-0-687" name="__codelineno-0-687"></a><span class="sd">        Instance of [InverseHvpResult][pydvl.influence.twice_differentiable.InverseHvpResult], with a matrix of shape [NxP] with each line being a solution of \(Ax=b\),</span>
</span><span id="__span-0-688"><a id="__codelineno-0-688" name="__codelineno-0-688"></a><span class="sd">            and a dictionary containing information about the accuracy of the solution.</span>
</span><span id="__span-0-689"><a id="__codelineno-0-689" name="__codelineno-0-689"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-690"><a id="__codelineno-0-690" name="__codelineno-0-690"></a>
</span><span id="__span-0-691"><a id="__codelineno-0-691" name="__codelineno-0-691"></a>    <span class="k">if</span> <span class="n">h0</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-692"><a id="__codelineno-0-692" name="__codelineno-0-692"></a>        <span class="n">h_estimate</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">clone</span><span class="p">(</span><span class="n">b</span><span class="p">)</span>
</span><span id="__span-0-693"><a id="__codelineno-0-693" name="__codelineno-0-693"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-694"><a id="__codelineno-0-694" name="__codelineno-0-694"></a>        <span class="n">h_estimate</span> <span class="o">=</span> <span class="n">h0</span>
</span><span id="__span-0-695"><a id="__codelineno-0-695" name="__codelineno-0-695"></a>    <span class="n">shuffled_training_data</span> <span class="o">=</span> <span class="n">DataLoader</span><span class="p">(</span>
</span><span id="__span-0-696"><a id="__codelineno-0-696" name="__codelineno-0-696"></a>        <span class="n">training_data</span><span class="o">.</span><span class="n">dataset</span><span class="p">,</span> <span class="n">training_data</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="kc">True</span>
</span><span id="__span-0-697"><a id="__codelineno-0-697" name="__codelineno-0-697"></a>    <span class="p">)</span>
</span><span id="__span-0-698"><a id="__codelineno-0-698" name="__codelineno-0-698"></a>
</span><span id="__span-0-699"><a id="__codelineno-0-699" name="__codelineno-0-699"></a>    <span class="k">def</span> <span class="nf">lissa_step</span><span class="p">(</span>
</span><span id="__span-0-700"><a id="__codelineno-0-700" name="__codelineno-0-700"></a>        <span class="n">h</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">reg_hvp</span><span class="p">:</span> <span class="n">Callable</span><span class="p">[[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">],</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]</span>
</span><span id="__span-0-701"><a id="__codelineno-0-701" name="__codelineno-0-701"></a>    <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
</span><span id="__span-0-702"><a id="__codelineno-0-702" name="__codelineno-0-702"></a><span class="w">        </span><span class="sd">&quot;&quot;&quot;Given an estimate of the hessian inverse and the regularised hessian</span>
</span><span id="__span-0-703"><a id="__codelineno-0-703" name="__codelineno-0-703"></a><span class="sd">        vector product, it computes the next estimate.</span>
</span><span id="__span-0-704"><a id="__codelineno-0-704" name="__codelineno-0-704"></a>
</span><span id="__span-0-705"><a id="__codelineno-0-705" name="__codelineno-0-705"></a><span class="sd">        Args:</span>
</span><span id="__span-0-706"><a id="__codelineno-0-706" name="__codelineno-0-706"></a><span class="sd">            h: An estimate of the hessian inverse.</span>
</span><span id="__span-0-707"><a id="__codelineno-0-707" name="__codelineno-0-707"></a><span class="sd">            reg_hvp: Regularised hessian vector product.</span>
</span><span id="__span-0-708"><a id="__codelineno-0-708" name="__codelineno-0-708"></a>
</span><span id="__span-0-709"><a id="__codelineno-0-709" name="__codelineno-0-709"></a><span class="sd">        Returns:</span>
</span><span id="__span-0-710"><a id="__codelineno-0-710" name="__codelineno-0-710"></a><span class="sd">            The next estimate of the hessian inverse.</span>
</span><span id="__span-0-711"><a id="__codelineno-0-711" name="__codelineno-0-711"></a><span class="sd">        &quot;&quot;&quot;</span>
</span><span id="__span-0-712"><a id="__codelineno-0-712" name="__codelineno-0-712"></a>        <span class="k">return</span> <span class="n">b</span> <span class="o">+</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">dampen</span><span class="p">)</span> <span class="o">*</span> <span class="n">h</span> <span class="o">-</span> <span class="n">reg_hvp</span><span class="p">(</span><span class="n">h</span><span class="p">)</span> <span class="o">/</span> <span class="n">scale</span>
</span><span id="__span-0-713"><a id="__codelineno-0-713" name="__codelineno-0-713"></a>
</span><span id="__span-0-714"><a id="__codelineno-0-714" name="__codelineno-0-714"></a>    <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="n">maybe_progress</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">maxiter</span><span class="p">),</span> <span class="n">progress</span><span class="p">,</span> <span class="n">desc</span><span class="o">=</span><span class="s2">&quot;Lissa&quot;</span><span class="p">):</span>
</span><span id="__span-0-715"><a id="__codelineno-0-715" name="__codelineno-0-715"></a>        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">shuffled_training_data</span><span class="p">))</span>
</span><span id="__span-0-716"><a id="__codelineno-0-716" name="__codelineno-0-716"></a>        <span class="n">grad_xy</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">grad</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">create_graph</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</span><span id="__span-0-717"><a id="__codelineno-0-717" name="__codelineno-0-717"></a>        <span class="n">reg_hvp</span> <span class="o">=</span> <span class="p">(</span>
</span><span id="__span-0-718"><a id="__codelineno-0-718" name="__codelineno-0-718"></a>            <span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">model</span><span class="o">.</span><span class="n">mvp</span><span class="p">(</span><span class="n">grad_xy</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">)</span> <span class="o">+</span> <span class="n">hessian_perturbation</span> <span class="o">*</span> <span class="n">v</span>
</span><span id="__span-0-719"><a id="__codelineno-0-719" name="__codelineno-0-719"></a>        <span class="p">)</span>
</span><span id="__span-0-720"><a id="__codelineno-0-720" name="__codelineno-0-720"></a>        <span class="n">residual</span> <span class="o">=</span> <span class="n">lissa_step</span><span class="p">(</span><span class="n">h_estimate</span><span class="p">,</span> <span class="n">reg_hvp</span><span class="p">)</span> <span class="o">-</span> <span class="n">h_estimate</span>
</span><span id="__span-0-721"><a id="__codelineno-0-721" name="__codelineno-0-721"></a>        <span class="n">h_estimate</span> <span class="o">+=</span> <span class="n">residual</span>
</span><span id="__span-0-722"><a id="__codelineno-0-722" name="__codelineno-0-722"></a>        <span class="k">if</span> <span class="n">torch</span><span class="o">.</span><span class="n">isnan</span><span class="p">(</span><span class="n">h_estimate</span><span class="p">)</span><span class="o">.</span><span class="n">any</span><span class="p">():</span>
</span><span id="__span-0-723"><a id="__codelineno-0-723" name="__codelineno-0-723"></a>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span><span class="s2">&quot;NaNs in h_estimate. Increase scale or dampening.&quot;</span><span class="p">)</span>
</span><span id="__span-0-724"><a id="__codelineno-0-724" name="__codelineno-0-724"></a>        <span class="n">max_residual</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">residual</span> <span class="o">/</span> <span class="n">h_estimate</span><span class="p">))</span>
</span><span id="__span-0-725"><a id="__codelineno-0-725" name="__codelineno-0-725"></a>        <span class="k">if</span> <span class="n">max_residual</span> <span class="o">&lt;</span> <span class="n">rtol</span><span class="p">:</span>
</span><span id="__span-0-726"><a id="__codelineno-0-726" name="__codelineno-0-726"></a>            <span class="k">break</span>
</span><span id="__span-0-727"><a id="__codelineno-0-727" name="__codelineno-0-727"></a>    <span class="n">mean_residual</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">residual</span> <span class="o">/</span> <span class="n">h_estimate</span><span class="p">))</span>
</span><span id="__span-0-728"><a id="__codelineno-0-728" name="__codelineno-0-728"></a>    <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span>
</span><span id="__span-0-729"><a id="__codelineno-0-729" name="__codelineno-0-729"></a>        <span class="sa">f</span><span class="s2">&quot;Terminated Lissa with </span><span class="si">{</span><span class="n">max_residual</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.2f</span><span class="si">}</span><span class="s2"> % max residual.&quot;</span>
</span><span id="__span-0-730"><a id="__codelineno-0-730" name="__codelineno-0-730"></a>        <span class="sa">f</span><span class="s2">&quot; Mean residual: </span><span class="si">{</span><span class="n">mean_residual</span><span class="o">*</span><span class="mi">100</span><span class="si">:</span><span class="s2">.5f</span><span class="si">}</span><span class="s2"> %&quot;</span>
</span><span id="__span-0-731"><a id="__codelineno-0-731" name="__codelineno-0-731"></a>    <span class="p">)</span>
</span><span id="__span-0-732"><a id="__codelineno-0-732" name="__codelineno-0-732"></a>    <span class="n">info</span> <span class="o">=</span> <span class="p">{</span>
</span><span id="__span-0-733"><a id="__codelineno-0-733" name="__codelineno-0-733"></a>        <span class="s2">&quot;max_perc_residual&quot;</span><span class="p">:</span> <span class="n">max_residual</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span>
</span><span id="__span-0-734"><a id="__codelineno-0-734" name="__codelineno-0-734"></a>        <span class="s2">&quot;mean_perc_residual&quot;</span><span class="p">:</span> <span class="n">mean_residual</span> <span class="o">*</span> <span class="mi">100</span><span class="p">,</span>
</span><span id="__span-0-735"><a id="__codelineno-0-735" name="__codelineno-0-735"></a>    <span class="p">}</span>
</span><span id="__span-0-736"><a id="__codelineno-0-736" name="__codelineno-0-736"></a>    <span class="k">return</span> <span class="n">InverseHvpResult</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="n">h_estimate</span> <span class="o">/</span> <span class="n">scale</span><span class="p">,</span> <span class="n">info</span><span class="o">=</span><span class="n">info</span><span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>


<div class="doc doc-object doc-function">




<h2 id="pydvl.influence.torch.torch_differentiable.solve_arnoldi" class="doc doc-heading">
          <code class="highlight language-python"><span class="n">solve_arnoldi</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">training_data</span><span class="p">,</span> <span class="n">b</span><span class="p">,</span> <span class="n">hessian_perturbation</span><span class="o">=</span><span class="mf">0.0</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">rank_estimate</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">krylov_dimension</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">low_rank_representation</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-06</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">eigen_computation_on_gpu</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span></code>

<a href="#pydvl.influence.torch.torch_differentiable.solve_arnoldi" class="headerlink" title="Permanent link">&para;</a></h2>


  <div class="doc doc-contents ">
  
      <p>Solves the linear system Hx = b, where H is the Hessian of the model's loss function and b is the given
right-hand side vector.
It employs the <a href="https://en.wikipedia.org/wiki/Arnoldi_iteration">implicitly restarted Arnoldi method</a> for
computing a partial eigen decomposition, which is used fo the inversion i.e.</p>
<div class="arithmatex">\[x = V D^{-1} V^T b\]</div>
<p>where <span class="arithmatex">\(D\)</span> is a diagonal matrix with the top (in absolute value) <code>rank_estimate</code> eigenvalues of the Hessian
and <span class="arithmatex">\(V\)</span> contains the corresponding eigenvectors.</p>



  <table>
    <thead>
      <tr>
        <th><b>PARAMETER</b></th>
        <th><b> DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td><code>model</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A PyTorch model instance that is twice differentiable, wrapped into
<a class="autorefs autorefs-internal" href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable">TorchTwiceDifferential</a>.
The Hessian will be calculated with respect to this model's parameters.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-internal" title="pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable" href="#pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable">TorchTwiceDifferentiable</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>training_data</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>A DataLoader instance that provides the model's training data.
Used in calculating the Hessian-vector products.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.utils.data.DataLoader" href="https://pytorch.org/docs/stable/data.html#torch.utils.data.DataLoader">DataLoader</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>b</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The right-hand side vector in the system Hx = b.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="torch.Tensor" href="https://pytorch.org/docs/stable/tensors.html#torch.Tensor">Tensor</a></code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>hessian_perturbation</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>Optional regularization parameter added to the Hessian-vector
product for numerical stability.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>0.0</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>rank_estimate</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The number of eigenvalues and corresponding eigenvectors to compute.
Represents the desired rank of the Hessian approximation.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>10</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>krylov_dimension</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The number of Krylov vectors to use for the Lanczos method.
Defaults to min(model's number of parameters, max(2 times rank_estimate + 1, 20)).</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>low_rank_representation</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>An instance of
<a class="autorefs autorefs-internal" href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation">LowRankProductRepresentation</a>
containing a previously computed low-rank representation of the Hessian. If provided, all other parameters
are ignored; otherwise, a new low-rank representation is computed
using provided parameters.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-internal" title="pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation" href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation">LowRankProductRepresentation</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>tol</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The stopping criteria for the Lanczos algorithm.
Ignored if <code>low_rank_representation</code> is provided.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#float">float</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>1e-06</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>max_iter</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>The maximum number of iterations for the Lanczos method.
Ignored if <code>low_rank_representation</code> is provided.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" title="typing.Optional" href="https://docs.python.org/3/library/typing.html#typing.Optional">Optional</a>[<a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#int">int</a>]</code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>None</code>
                </span>
            </p>
          </td>
        </tr>
        <tr>
          <td><code>eigen_computation_on_gpu</code></td>
          <td class="doc-param-details">
            <div class="doc-md-description">
              <p>If True, tries to execute the eigen pair approximation on the model's device
via a cupy implementation. Ensure the model size or rank_estimate is appropriate for device memory.
If False, the eigen pair approximation is executed on the CPU by the scipy wrapper to ARPACK.</p>
            </div>
            <p>
                <span class="doc-param-annotation">
                  <b>TYPE:</b>
                    <code><a class="autorefs autorefs-external" href="https://docs.python.org/3/library/functions.html#bool">bool</a></code>
                </span>
                <span class="doc-param-default">
                  <b>DEFAULT:</b> 
                    <code>False</code>
                </span>
            </p>
          </td>
        </tr>
    </tbody>
  </table>



  <table>
    <thead>
      <tr>
        <th><b>RETURNS</b></th>
        <th><b>DESCRIPTION</b></th>
      </tr>
    </thead>
    <tbody>
        <tr>
          <td>
              <span class="doc-returns-annotation">
                  <code><a class="autorefs autorefs-internal" title="pydvl.influence.twice_differentiable.InverseHvpResult" href="../../twice_differentiable/#pydvl.influence.twice_differentiable.InverseHvpResult">InverseHvpResult</a></code>
              </span>
          </td>
          <td class="doc-returns-details">
            <div class="doc-md-description">
              <p>Instance of <a class="autorefs autorefs-internal" href="../../twice_differentiable/#pydvl.influence.twice_differentiable.InverseHvpResult">InverseHvpResult</a>,
having the solution vector x that satisfies the system <span class="arithmatex">\(Ax = b\)</span>,
where <span class="arithmatex">\(A\)</span> is a low-rank approximation of the Hessian <span class="arithmatex">\(H\)</span> of the model's loss function, and an instance
of <a class="autorefs autorefs-internal" href="#pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation">LowRankProductRepresentation</a>,
which represents the approximation of H.</p>
            </div>
          </td>
        </tr>
    </tbody>
  </table>

          <details class="quote">
            <summary>Source code in <code>src/pydvl/influence/torch/torch_differentiable.py</code></summary>
            <div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span></span><span class="normal"><a href="#__codelineno-0-739">739</a></span>
<span class="normal"><a href="#__codelineno-0-740">740</a></span>
<span class="normal"><a href="#__codelineno-0-741">741</a></span>
<span class="normal"><a href="#__codelineno-0-742">742</a></span>
<span class="normal"><a href="#__codelineno-0-743">743</a></span>
<span class="normal"><a href="#__codelineno-0-744">744</a></span>
<span class="normal"><a href="#__codelineno-0-745">745</a></span>
<span class="normal"><a href="#__codelineno-0-746">746</a></span>
<span class="normal"><a href="#__codelineno-0-747">747</a></span>
<span class="normal"><a href="#__codelineno-0-748">748</a></span>
<span class="normal"><a href="#__codelineno-0-749">749</a></span>
<span class="normal"><a href="#__codelineno-0-750">750</a></span>
<span class="normal"><a href="#__codelineno-0-751">751</a></span>
<span class="normal"><a href="#__codelineno-0-752">752</a></span>
<span class="normal"><a href="#__codelineno-0-753">753</a></span>
<span class="normal"><a href="#__codelineno-0-754">754</a></span>
<span class="normal"><a href="#__codelineno-0-755">755</a></span>
<span class="normal"><a href="#__codelineno-0-756">756</a></span>
<span class="normal"><a href="#__codelineno-0-757">757</a></span>
<span class="normal"><a href="#__codelineno-0-758">758</a></span>
<span class="normal"><a href="#__codelineno-0-759">759</a></span>
<span class="normal"><a href="#__codelineno-0-760">760</a></span>
<span class="normal"><a href="#__codelineno-0-761">761</a></span>
<span class="normal"><a href="#__codelineno-0-762">762</a></span>
<span class="normal"><a href="#__codelineno-0-763">763</a></span>
<span class="normal"><a href="#__codelineno-0-764">764</a></span>
<span class="normal"><a href="#__codelineno-0-765">765</a></span>
<span class="normal"><a href="#__codelineno-0-766">766</a></span>
<span class="normal"><a href="#__codelineno-0-767">767</a></span>
<span class="normal"><a href="#__codelineno-0-768">768</a></span>
<span class="normal"><a href="#__codelineno-0-769">769</a></span>
<span class="normal"><a href="#__codelineno-0-770">770</a></span>
<span class="normal"><a href="#__codelineno-0-771">771</a></span>
<span class="normal"><a href="#__codelineno-0-772">772</a></span>
<span class="normal"><a href="#__codelineno-0-773">773</a></span>
<span class="normal"><a href="#__codelineno-0-774">774</a></span>
<span class="normal"><a href="#__codelineno-0-775">775</a></span>
<span class="normal"><a href="#__codelineno-0-776">776</a></span>
<span class="normal"><a href="#__codelineno-0-777">777</a></span>
<span class="normal"><a href="#__codelineno-0-778">778</a></span>
<span class="normal"><a href="#__codelineno-0-779">779</a></span>
<span class="normal"><a href="#__codelineno-0-780">780</a></span>
<span class="normal"><a href="#__codelineno-0-781">781</a></span>
<span class="normal"><a href="#__codelineno-0-782">782</a></span>
<span class="normal"><a href="#__codelineno-0-783">783</a></span>
<span class="normal"><a href="#__codelineno-0-784">784</a></span>
<span class="normal"><a href="#__codelineno-0-785">785</a></span>
<span class="normal"><a href="#__codelineno-0-786">786</a></span>
<span class="normal"><a href="#__codelineno-0-787">787</a></span>
<span class="normal"><a href="#__codelineno-0-788">788</a></span>
<span class="normal"><a href="#__codelineno-0-789">789</a></span>
<span class="normal"><a href="#__codelineno-0-790">790</a></span>
<span class="normal"><a href="#__codelineno-0-791">791</a></span>
<span class="normal"><a href="#__codelineno-0-792">792</a></span>
<span class="normal"><a href="#__codelineno-0-793">793</a></span>
<span class="normal"><a href="#__codelineno-0-794">794</a></span>
<span class="normal"><a href="#__codelineno-0-795">795</a></span>
<span class="normal"><a href="#__codelineno-0-796">796</a></span>
<span class="normal"><a href="#__codelineno-0-797">797</a></span>
<span class="normal"><a href="#__codelineno-0-798">798</a></span>
<span class="normal"><a href="#__codelineno-0-799">799</a></span>
<span class="normal"><a href="#__codelineno-0-800">800</a></span>
<span class="normal"><a href="#__codelineno-0-801">801</a></span>
<span class="normal"><a href="#__codelineno-0-802">802</a></span>
<span class="normal"><a href="#__codelineno-0-803">803</a></span>
<span class="normal"><a href="#__codelineno-0-804">804</a></span>
<span class="normal"><a href="#__codelineno-0-805">805</a></span>
<span class="normal"><a href="#__codelineno-0-806">806</a></span>
<span class="normal"><a href="#__codelineno-0-807">807</a></span>
<span class="normal"><a href="#__codelineno-0-808">808</a></span>
<span class="normal"><a href="#__codelineno-0-809">809</a></span>
<span class="normal"><a href="#__codelineno-0-810">810</a></span>
<span class="normal"><a href="#__codelineno-0-811">811</a></span>
<span class="normal"><a href="#__codelineno-0-812">812</a></span>
<span class="normal"><a href="#__codelineno-0-813">813</a></span>
<span class="normal"><a href="#__codelineno-0-814">814</a></span>
<span class="normal"><a href="#__codelineno-0-815">815</a></span>
<span class="normal"><a href="#__codelineno-0-816">816</a></span>
<span class="normal"><a href="#__codelineno-0-817">817</a></span>
<span class="normal"><a href="#__codelineno-0-818">818</a></span>
<span class="normal"><a href="#__codelineno-0-819">819</a></span>
<span class="normal"><a href="#__codelineno-0-820">820</a></span>
<span class="normal"><a href="#__codelineno-0-821">821</a></span>
<span class="normal"><a href="#__codelineno-0-822">822</a></span>
<span class="normal"><a href="#__codelineno-0-823">823</a></span>
<span class="normal"><a href="#__codelineno-0-824">824</a></span>
<span class="normal"><a href="#__codelineno-0-825">825</a></span>
<span class="normal"><a href="#__codelineno-0-826">826</a></span>
<span class="normal"><a href="#__codelineno-0-827">827</a></span>
<span class="normal"><a href="#__codelineno-0-828">828</a></span>
<span class="normal"><a href="#__codelineno-0-829">829</a></span>
<span class="normal"><a href="#__codelineno-0-830">830</a></span>
<span class="normal"><a href="#__codelineno-0-831">831</a></span>
<span class="normal"><a href="#__codelineno-0-832">832</a></span>
<span class="normal"><a href="#__codelineno-0-833">833</a></span>
<span class="normal"><a href="#__codelineno-0-834">834</a></span>
<span class="normal"><a href="#__codelineno-0-835">835</a></span>
<span class="normal"><a href="#__codelineno-0-836">836</a></span>
<span class="normal"><a href="#__codelineno-0-837">837</a></span>
<span class="normal"><a href="#__codelineno-0-838">838</a></span>
<span class="normal"><a href="#__codelineno-0-839">839</a></span>
<span class="normal"><a href="#__codelineno-0-840">840</a></span>
<span class="normal"><a href="#__codelineno-0-841">841</a></span>
<span class="normal"><a href="#__codelineno-0-842">842</a></span>
<span class="normal"><a href="#__codelineno-0-843">843</a></span>
<span class="normal"><a href="#__codelineno-0-844">844</a></span>
<span class="normal"><a href="#__codelineno-0-845">845</a></span></pre></div></td><td class="code"><div><pre><span></span><code><span id="__span-0-739"><a id="__codelineno-0-739" name="__codelineno-0-739"></a><span class="nd">@InversionRegistry</span><span class="o">.</span><span class="n">register</span><span class="p">(</span><span class="n">TorchTwiceDifferentiable</span><span class="p">,</span> <span class="n">InversionMethod</span><span class="o">.</span><span class="n">Arnoldi</span><span class="p">)</span>
</span><span id="__span-0-740"><a id="__codelineno-0-740" name="__codelineno-0-740"></a><span class="k">def</span> <span class="nf">solve_arnoldi</span><span class="p">(</span>
</span><span id="__span-0-741"><a id="__codelineno-0-741" name="__codelineno-0-741"></a>    <span class="n">model</span><span class="p">:</span> <span class="n">TorchTwiceDifferentiable</span><span class="p">,</span>
</span><span id="__span-0-742"><a id="__codelineno-0-742" name="__codelineno-0-742"></a>    <span class="n">training_data</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
</span><span id="__span-0-743"><a id="__codelineno-0-743" name="__codelineno-0-743"></a>    <span class="n">b</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span>
</span><span id="__span-0-744"><a id="__codelineno-0-744" name="__codelineno-0-744"></a>    <span class="n">hessian_perturbation</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">,</span>
</span><span id="__span-0-745"><a id="__codelineno-0-745" name="__codelineno-0-745"></a>    <span class="o">*</span><span class="p">,</span>
</span><span id="__span-0-746"><a id="__codelineno-0-746" name="__codelineno-0-746"></a>    <span class="n">rank_estimate</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
</span><span id="__span-0-747"><a id="__codelineno-0-747" name="__codelineno-0-747"></a>    <span class="n">krylov_dimension</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-748"><a id="__codelineno-0-748" name="__codelineno-0-748"></a>    <span class="n">low_rank_representation</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">LowRankProductRepresentation</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-749"><a id="__codelineno-0-749" name="__codelineno-0-749"></a>    <span class="n">tol</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">1e-6</span><span class="p">,</span>
</span><span id="__span-0-750"><a id="__codelineno-0-750" name="__codelineno-0-750"></a>    <span class="n">max_iter</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
</span><span id="__span-0-751"><a id="__codelineno-0-751" name="__codelineno-0-751"></a>    <span class="n">eigen_computation_on_gpu</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
</span><span id="__span-0-752"><a id="__codelineno-0-752" name="__codelineno-0-752"></a><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">InverseHvpResult</span><span class="p">:</span>
</span><span id="__span-0-753"><a id="__codelineno-0-753" name="__codelineno-0-753"></a><span class="w">    </span><span class="sa">r</span><span class="sd">&quot;&quot;&quot;</span>
</span><span id="__span-0-754"><a id="__codelineno-0-754" name="__codelineno-0-754"></a><span class="sd">    Solves the linear system Hx = b, where H is the Hessian of the model&#39;s loss function and b is the given</span>
</span><span id="__span-0-755"><a id="__codelineno-0-755" name="__codelineno-0-755"></a><span class="sd">    right-hand side vector.</span>
</span><span id="__span-0-756"><a id="__codelineno-0-756" name="__codelineno-0-756"></a><span class="sd">    It employs the [implicitly restarted Arnoldi method](https://en.wikipedia.org/wiki/Arnoldi_iteration) for</span>
</span><span id="__span-0-757"><a id="__codelineno-0-757" name="__codelineno-0-757"></a><span class="sd">    computing a partial eigen decomposition, which is used fo the inversion i.e.</span>
</span><span id="__span-0-758"><a id="__codelineno-0-758" name="__codelineno-0-758"></a>
</span><span id="__span-0-759"><a id="__codelineno-0-759" name="__codelineno-0-759"></a><span class="sd">    \[x = V D^{-1} V^T b\]</span>
</span><span id="__span-0-760"><a id="__codelineno-0-760" name="__codelineno-0-760"></a>
</span><span id="__span-0-761"><a id="__codelineno-0-761" name="__codelineno-0-761"></a><span class="sd">    where \(D\) is a diagonal matrix with the top (in absolute value) `rank_estimate` eigenvalues of the Hessian</span>
</span><span id="__span-0-762"><a id="__codelineno-0-762" name="__codelineno-0-762"></a><span class="sd">    and \(V\) contains the corresponding eigenvectors.</span>
</span><span id="__span-0-763"><a id="__codelineno-0-763" name="__codelineno-0-763"></a>
</span><span id="__span-0-764"><a id="__codelineno-0-764" name="__codelineno-0-764"></a><span class="sd">    Args:</span>
</span><span id="__span-0-765"><a id="__codelineno-0-765" name="__codelineno-0-765"></a><span class="sd">        model: A PyTorch model instance that is twice differentiable, wrapped into</span>
</span><span id="__span-0-766"><a id="__codelineno-0-766" name="__codelineno-0-766"></a><span class="sd">            [TorchTwiceDifferential][pydvl.influence.torch.torch_differentiable.TorchTwiceDifferentiable].</span>
</span><span id="__span-0-767"><a id="__codelineno-0-767" name="__codelineno-0-767"></a><span class="sd">            The Hessian will be calculated with respect to this model&#39;s parameters.</span>
</span><span id="__span-0-768"><a id="__codelineno-0-768" name="__codelineno-0-768"></a><span class="sd">        training_data: A DataLoader instance that provides the model&#39;s training data.</span>
</span><span id="__span-0-769"><a id="__codelineno-0-769" name="__codelineno-0-769"></a><span class="sd">            Used in calculating the Hessian-vector products.</span>
</span><span id="__span-0-770"><a id="__codelineno-0-770" name="__codelineno-0-770"></a><span class="sd">        b: The right-hand side vector in the system Hx = b.</span>
</span><span id="__span-0-771"><a id="__codelineno-0-771" name="__codelineno-0-771"></a><span class="sd">        hessian_perturbation: Optional regularization parameter added to the Hessian-vector</span>
</span><span id="__span-0-772"><a id="__codelineno-0-772" name="__codelineno-0-772"></a><span class="sd">            product for numerical stability.</span>
</span><span id="__span-0-773"><a id="__codelineno-0-773" name="__codelineno-0-773"></a><span class="sd">        rank_estimate: The number of eigenvalues and corresponding eigenvectors to compute.</span>
</span><span id="__span-0-774"><a id="__codelineno-0-774" name="__codelineno-0-774"></a><span class="sd">            Represents the desired rank of the Hessian approximation.</span>
</span><span id="__span-0-775"><a id="__codelineno-0-775" name="__codelineno-0-775"></a><span class="sd">        krylov_dimension: The number of Krylov vectors to use for the Lanczos method.</span>
</span><span id="__span-0-776"><a id="__codelineno-0-776" name="__codelineno-0-776"></a><span class="sd">            Defaults to min(model&#39;s number of parameters, max(2 times rank_estimate + 1, 20)).</span>
</span><span id="__span-0-777"><a id="__codelineno-0-777" name="__codelineno-0-777"></a><span class="sd">        low_rank_representation: An instance of</span>
</span><span id="__span-0-778"><a id="__codelineno-0-778" name="__codelineno-0-778"></a><span class="sd">            [LowRankProductRepresentation][pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation]</span>
</span><span id="__span-0-779"><a id="__codelineno-0-779" name="__codelineno-0-779"></a><span class="sd">            containing a previously computed low-rank representation of the Hessian. If provided, all other parameters</span>
</span><span id="__span-0-780"><a id="__codelineno-0-780" name="__codelineno-0-780"></a><span class="sd">            are ignored; otherwise, a new low-rank representation is computed</span>
</span><span id="__span-0-781"><a id="__codelineno-0-781" name="__codelineno-0-781"></a><span class="sd">            using provided parameters.</span>
</span><span id="__span-0-782"><a id="__codelineno-0-782" name="__codelineno-0-782"></a><span class="sd">        tol: The stopping criteria for the Lanczos algorithm.</span>
</span><span id="__span-0-783"><a id="__codelineno-0-783" name="__codelineno-0-783"></a><span class="sd">            Ignored if `low_rank_representation` is provided.</span>
</span><span id="__span-0-784"><a id="__codelineno-0-784" name="__codelineno-0-784"></a><span class="sd">        max_iter: The maximum number of iterations for the Lanczos method.</span>
</span><span id="__span-0-785"><a id="__codelineno-0-785" name="__codelineno-0-785"></a><span class="sd">            Ignored if `low_rank_representation` is provided.</span>
</span><span id="__span-0-786"><a id="__codelineno-0-786" name="__codelineno-0-786"></a><span class="sd">        eigen_computation_on_gpu: If True, tries to execute the eigen pair approximation on the model&#39;s device</span>
</span><span id="__span-0-787"><a id="__codelineno-0-787" name="__codelineno-0-787"></a><span class="sd">            via a cupy implementation. Ensure the model size or rank_estimate is appropriate for device memory.</span>
</span><span id="__span-0-788"><a id="__codelineno-0-788" name="__codelineno-0-788"></a><span class="sd">            If False, the eigen pair approximation is executed on the CPU by the scipy wrapper to ARPACK.</span>
</span><span id="__span-0-789"><a id="__codelineno-0-789" name="__codelineno-0-789"></a>
</span><span id="__span-0-790"><a id="__codelineno-0-790" name="__codelineno-0-790"></a><span class="sd">    Returns:</span>
</span><span id="__span-0-791"><a id="__codelineno-0-791" name="__codelineno-0-791"></a><span class="sd">        Instance of [InverseHvpResult][pydvl.influence.torch.torch_differentiable.InverseHvpResult],</span>
</span><span id="__span-0-792"><a id="__codelineno-0-792" name="__codelineno-0-792"></a><span class="sd">            having the solution vector x that satisfies the system \(Ax = b\),</span>
</span><span id="__span-0-793"><a id="__codelineno-0-793" name="__codelineno-0-793"></a><span class="sd">            where \(A\) is a low-rank approximation of the Hessian \(H\) of the model&#39;s loss function, and an instance</span>
</span><span id="__span-0-794"><a id="__codelineno-0-794" name="__codelineno-0-794"></a><span class="sd">            of [LowRankProductRepresentation][pydvl.influence.torch.torch_differentiable.LowRankProductRepresentation],</span>
</span><span id="__span-0-795"><a id="__codelineno-0-795" name="__codelineno-0-795"></a><span class="sd">            which represents the approximation of H.</span>
</span><span id="__span-0-796"><a id="__codelineno-0-796" name="__codelineno-0-796"></a><span class="sd">    &quot;&quot;&quot;</span>
</span><span id="__span-0-797"><a id="__codelineno-0-797" name="__codelineno-0-797"></a>
</span><span id="__span-0-798"><a id="__codelineno-0-798" name="__codelineno-0-798"></a>    <span class="n">b_device</span> <span class="o">=</span> <span class="n">b</span><span class="o">.</span><span class="n">device</span> <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">b</span><span class="p">,</span> <span class="s2">&quot;device&quot;</span><span class="p">)</span> <span class="k">else</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">)</span>
</span><span id="__span-0-799"><a id="__codelineno-0-799" name="__codelineno-0-799"></a>
</span><span id="__span-0-800"><a id="__codelineno-0-800" name="__codelineno-0-800"></a>    <span class="k">if</span> <span class="n">low_rank_representation</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
</span><span id="__span-0-801"><a id="__codelineno-0-801" name="__codelineno-0-801"></a>        <span class="k">if</span> <span class="n">b_device</span><span class="o">.</span><span class="n">type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">eigen_computation_on_gpu</span><span class="p">:</span>
</span><span id="__span-0-802"><a id="__codelineno-0-802" name="__codelineno-0-802"></a>            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span>
</span><span id="__span-0-803"><a id="__codelineno-0-803" name="__codelineno-0-803"></a>                <span class="s2">&quot;Using &#39;eigen_computation_on_gpu=False&#39; while &#39;b&#39; is on a &#39;cuda&#39; device is not supported. &quot;</span>
</span><span id="__span-0-804"><a id="__codelineno-0-804" name="__codelineno-0-804"></a>                <span class="s2">&quot;To address this, consider the following options:</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-0-805"><a id="__codelineno-0-805" name="__codelineno-0-805"></a>                <span class="s2">&quot; - Set eigen_computation_on_gpu=True if your model and data are small enough &quot;</span>
</span><span id="__span-0-806"><a id="__codelineno-0-806" name="__codelineno-0-806"></a>                <span class="s2">&quot;and if &#39;cupy&#39; is available in your environment.</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-0-807"><a id="__codelineno-0-807" name="__codelineno-0-807"></a>                <span class="s2">&quot; - Move &#39;b&#39; to the CPU with b.to(&#39;cpu&#39;).</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-0-808"><a id="__codelineno-0-808" name="__codelineno-0-808"></a>                <span class="s2">&quot; - Precompute a low rank representation and move it to the &#39;b&#39; device using:</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-0-809"><a id="__codelineno-0-809" name="__codelineno-0-809"></a>                <span class="s2">&quot;     low_rank_representation = model_hessian_low_rank(model, training_data, ..., &quot;</span>
</span><span id="__span-0-810"><a id="__codelineno-0-810" name="__codelineno-0-810"></a>                <span class="s2">&quot;eigen_computation_on_gpu=False).to(b.device)&quot;</span>
</span><span id="__span-0-811"><a id="__codelineno-0-811" name="__codelineno-0-811"></a>            <span class="p">)</span>
</span><span id="__span-0-812"><a id="__codelineno-0-812" name="__codelineno-0-812"></a>
</span><span id="__span-0-813"><a id="__codelineno-0-813" name="__codelineno-0-813"></a>        <span class="n">low_rank_representation</span> <span class="o">=</span> <span class="n">model_hessian_low_rank</span><span class="p">(</span>
</span><span id="__span-0-814"><a id="__codelineno-0-814" name="__codelineno-0-814"></a>            <span class="n">model</span><span class="p">,</span>
</span><span id="__span-0-815"><a id="__codelineno-0-815" name="__codelineno-0-815"></a>            <span class="n">training_data</span><span class="p">,</span>
</span><span id="__span-0-816"><a id="__codelineno-0-816" name="__codelineno-0-816"></a>            <span class="n">hessian_perturbation</span><span class="o">=</span><span class="n">hessian_perturbation</span><span class="p">,</span>
</span><span id="__span-0-817"><a id="__codelineno-0-817" name="__codelineno-0-817"></a>            <span class="n">rank_estimate</span><span class="o">=</span><span class="n">rank_estimate</span><span class="p">,</span>
</span><span id="__span-0-818"><a id="__codelineno-0-818" name="__codelineno-0-818"></a>            <span class="n">krylov_dimension</span><span class="o">=</span><span class="n">krylov_dimension</span><span class="p">,</span>
</span><span id="__span-0-819"><a id="__codelineno-0-819" name="__codelineno-0-819"></a>            <span class="n">tol</span><span class="o">=</span><span class="n">tol</span><span class="p">,</span>
</span><span id="__span-0-820"><a id="__codelineno-0-820" name="__codelineno-0-820"></a>            <span class="n">max_iter</span><span class="o">=</span><span class="n">max_iter</span><span class="p">,</span>
</span><span id="__span-0-821"><a id="__codelineno-0-821" name="__codelineno-0-821"></a>            <span class="n">eigen_computation_on_gpu</span><span class="o">=</span><span class="n">eigen_computation_on_gpu</span><span class="p">,</span>
</span><span id="__span-0-822"><a id="__codelineno-0-822" name="__codelineno-0-822"></a>        <span class="p">)</span>
</span><span id="__span-0-823"><a id="__codelineno-0-823" name="__codelineno-0-823"></a>    <span class="k">else</span><span class="p">:</span>
</span><span id="__span-0-824"><a id="__codelineno-0-824" name="__codelineno-0-824"></a>        <span class="k">if</span> <span class="n">b_device</span><span class="o">.</span><span class="n">type</span> <span class="o">!=</span> <span class="n">low_rank_representation</span><span class="o">.</span><span class="n">device</span><span class="o">.</span><span class="n">type</span><span class="p">:</span>
</span><span id="__span-0-825"><a id="__codelineno-0-825" name="__codelineno-0-825"></a>            <span class="k">raise</span> <span class="ne">RuntimeError</span><span class="p">(</span>
</span><span id="__span-0-826"><a id="__codelineno-0-826" name="__codelineno-0-826"></a>                <span class="sa">f</span><span class="s2">&quot;The devices for &#39;b&#39; and &#39;low_rank_representation&#39; do not match.</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-0-827"><a id="__codelineno-0-827" name="__codelineno-0-827"></a>                <span class="sa">f</span><span class="s2">&quot; - &#39;b&#39; is on device: </span><span class="si">{</span><span class="n">b_device</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-0-828"><a id="__codelineno-0-828" name="__codelineno-0-828"></a>                <span class="sa">f</span><span class="s2">&quot; - &#39;low_rank_representation&#39; is on device: </span><span class="si">{</span><span class="n">low_rank_representation</span><span class="o">.</span><span class="n">device</span><span class="si">}</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-0-829"><a id="__codelineno-0-829" name="__codelineno-0-829"></a>                <span class="sa">f</span><span class="s2">&quot;</span><span class="se">\n</span><span class="s2">To resolve this, consider moving &#39;low_rank_representation&#39; to &#39;</span><span class="si">{</span><span class="n">b_device</span><span class="si">}</span><span class="s2">&#39; by using:</span><span class="se">\n</span><span class="s2">&quot;</span>
</span><span id="__span-0-830"><a id="__codelineno-0-830" name="__codelineno-0-830"></a>                <span class="sa">f</span><span class="s2">&quot;low_rank_representation = low_rank_representation.to(b.device)&quot;</span>
</span><span id="__span-0-831"><a id="__codelineno-0-831" name="__codelineno-0-831"></a>            <span class="p">)</span>
</span><span id="__span-0-832"><a id="__codelineno-0-832" name="__codelineno-0-832"></a>
</span><span id="__span-0-833"><a id="__codelineno-0-833" name="__codelineno-0-833"></a>        <span class="n">logger</span><span class="o">.</span><span class="n">info</span><span class="p">(</span><span class="s2">&quot;Using provided low rank representation, ignoring other parameters&quot;</span><span class="p">)</span>
</span><span id="__span-0-834"><a id="__codelineno-0-834" name="__codelineno-0-834"></a>
</span><span id="__span-0-835"><a id="__codelineno-0-835" name="__codelineno-0-835"></a>    <span class="n">result</span> <span class="o">=</span> <span class="n">low_rank_representation</span><span class="o">.</span><span class="n">projections</span> <span class="o">@</span> <span class="p">(</span>
</span><span id="__span-0-836"><a id="__codelineno-0-836" name="__codelineno-0-836"></a>        <span class="n">torch</span><span class="o">.</span><span class="n">diag_embed</span><span class="p">(</span><span class="mf">1.0</span> <span class="o">/</span> <span class="n">low_rank_representation</span><span class="o">.</span><span class="n">eigen_vals</span><span class="p">)</span>
</span><span id="__span-0-837"><a id="__codelineno-0-837" name="__codelineno-0-837"></a>        <span class="o">@</span> <span class="p">(</span><span class="n">low_rank_representation</span><span class="o">.</span><span class="n">projections</span><span class="o">.</span><span class="n">t</span><span class="p">()</span> <span class="o">@</span> <span class="n">b</span><span class="o">.</span><span class="n">t</span><span class="p">())</span>
</span><span id="__span-0-838"><a id="__codelineno-0-838" name="__codelineno-0-838"></a>    <span class="p">)</span>
</span><span id="__span-0-839"><a id="__codelineno-0-839" name="__codelineno-0-839"></a>    <span class="k">return</span> <span class="n">InverseHvpResult</span><span class="p">(</span>
</span><span id="__span-0-840"><a id="__codelineno-0-840" name="__codelineno-0-840"></a>        <span class="n">x</span><span class="o">=</span><span class="n">result</span><span class="o">.</span><span class="n">t</span><span class="p">(),</span>
</span><span id="__span-0-841"><a id="__codelineno-0-841" name="__codelineno-0-841"></a>        <span class="n">info</span><span class="o">=</span><span class="p">{</span>
</span><span id="__span-0-842"><a id="__codelineno-0-842" name="__codelineno-0-842"></a>            <span class="s2">&quot;eigenvalues&quot;</span><span class="p">:</span> <span class="n">low_rank_representation</span><span class="o">.</span><span class="n">eigen_vals</span><span class="p">,</span>
</span><span id="__span-0-843"><a id="__codelineno-0-843" name="__codelineno-0-843"></a>            <span class="s2">&quot;eigenvectors&quot;</span><span class="p">:</span> <span class="n">low_rank_representation</span><span class="o">.</span><span class="n">projections</span><span class="p">,</span>
</span><span id="__span-0-844"><a id="__codelineno-0-844" name="__codelineno-0-844"></a>        <span class="p">},</span>
</span><span id="__span-0-845"><a id="__codelineno-0-845" name="__codelineno-0-845"></a>    <span class="p">)</span>
</span></code></pre></div></td></tr></table></div>
          </details>
  </div>

</div>



  </div>

  </div>

</div>

  <hr>
<div class="md-source-file">
  <small>
    
      Last update:
      <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2023-09-02</span>
      
        <br>
        Created:
        <span class="git-revision-date-localized-plugin git-revision-date-localized-plugin-iso_date">2023-09-02</span>
      
    
  </small>
</div>





                
              </article>
            </div>
          
          
        </div>
        
          <button type="button" class="md-top md-icon" data-md-component="top" hidden>
            
            <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12Z"/></svg>
            Back to top
          </button>
        
      </main>
      
        <footer class="md-footer">
  
    
      
      <nav class="md-footer__inner md-grid" aria-label="Footer" >
        
          
          <a href="../functional/" class="md-footer__link md-footer__link--prev" aria-label="Previous: Functional" rel="prev">
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
            </div>
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Previous
              </span>
              <div class="md-ellipsis">
                Functional
              </div>
            </div>
          </a>
        
        
          
          <a href="../util/" class="md-footer__link md-footer__link--next" aria-label="Next: Util" rel="next">
            <div class="md-footer__title">
              <span class="md-footer__direction">
                Next
              </span>
              <div class="md-ellipsis">
                Util
              </div>
            </div>
            <div class="md-footer__button md-icon">
              
              <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11H4Z"/></svg>
            </div>
          </a>
        
      </nav>
    
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
    <div class="md-copyright__highlight">
        
        <a href="https://appliedai-institute.de">
            Copyright &copy; AppliedAI Institute gGmbH
        </a>
        
    </div>
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
        <div class="md-social">
  
    
    
    
    
      
      
    
    <a href="https://github.com/aai-institute/pyDVL" target="_blank" rel="noopener" title="github.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://pypi.org/project/pyDVL/" target="_blank" rel="noopener" title="pypi.org" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M439.8 200.5c-7.7-30.9-22.3-54.2-53.4-54.2h-40.1v47.4c0 36.8-31.2 67.8-66.8 67.8H172.7c-29.2 0-53.4 25-53.4 54.3v101.8c0 29 25.2 46 53.4 54.3 33.8 9.9 66.3 11.7 106.8 0 26.9-7.8 53.4-23.5 53.4-54.3v-40.7H226.2v-13.6h160.2c31.1 0 42.6-21.7 53.4-54.2 11.2-33.5 10.7-65.7 0-108.6zM286.2 404c11.1 0 20.1 9.1 20.1 20.3 0 11.3-9 20.4-20.1 20.4-11 0-20.1-9.2-20.1-20.4.1-11.3 9.1-20.3 20.1-20.3zM167.8 248.1h106.8c29.7 0 53.4-24.5 53.4-54.3V91.9c0-29-24.4-50.7-53.4-55.6-35.8-5.9-74.7-5.6-106.8.1-45.2 8-53.4 24.7-53.4 55.6v40.7h106.9v13.6h-147c-31.1 0-58.3 18.7-66.8 54.2-9.8 40.7-10.2 66.1 0 108.6 7.6 31.6 25.7 54.2 56.8 54.2H101v-48.8c0-35.3 30.5-66.4 66.8-66.4zm-6.7-142.6c-11.1 0-20.1-9.1-20.1-20.3.1-11.3 9-20.4 20.1-20.4 11 0 20.1 9.2 20.1 20.4s-9 20.3-20.1 20.3z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://twitter.com/aai_transferlab" target="_blank" rel="noopener" title="twitter.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M459.37 151.716c.325 4.548.325 9.097.325 13.645 0 138.72-105.583 298.558-298.558 298.558-59.452 0-114.68-17.219-161.137-47.106 8.447.974 16.568 1.299 25.34 1.299 49.055 0 94.213-16.568 130.274-44.832-46.132-.975-84.792-31.188-98.112-72.772 6.498.974 12.995 1.624 19.818 1.624 9.421 0 18.843-1.3 27.614-3.573-48.081-9.747-84.143-51.98-84.143-102.985v-1.299c13.969 7.797 30.214 12.67 47.431 13.319-28.264-18.843-46.781-51.005-46.781-87.391 0-19.492 5.197-37.36 14.294-52.954 51.655 63.675 129.3 105.258 216.365 109.807-1.624-7.797-2.599-15.918-2.599-24.04 0-57.828 46.782-104.934 104.934-104.934 30.213 0 57.502 12.67 76.67 33.137 23.715-4.548 46.456-13.32 66.599-25.34-7.798 24.366-24.366 44.833-46.132 57.827 21.117-2.273 41.584-8.122 60.426-16.243-14.292 20.791-32.161 39.308-52.628 54.253z"/></svg>
    </a>
  
    
    
    
    
      
      
    
    <a href="https://de.linkedin.com/company/appliedai-institute-for-europe-ggmbh" target="_blank" rel="noopener" title="de.linkedin.com" class="md-social__link">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Free 6.4.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2023 Fonticons, Inc.--><path d="M416 32H31.9C14.3 32 0 46.5 0 64.3v383.4C0 465.5 14.3 480 31.9 480H416c17.6 0 32-14.5 32-32.3V64.3c0-17.8-14.4-32.3-32-32.3zM135.4 416H69V202.2h66.5V416zm-33.2-243c-21.3 0-38.5-17.3-38.5-38.5S80.9 96 102.2 96c21.2 0 38.5 17.3 38.5 38.5 0 21.3-17.2 38.5-38.5 38.5zm282.1 243h-66.4V312c0-24.8-.5-56.7-34.5-56.7-34.6 0-39.9 27-39.9 54.9V416h-66.4V202.2h63.7v29.2h.9c8.9-16.8 30.6-34.5 62.9-34.5 67.2 0 79.7 44.3 79.7 101.9V416z"/></svg>
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../../../../..", "features": ["content.code.annotate", "content.code.copy", "navigation.footer", "navigation.instant", "navigation.path", "navigation.top", "navigation.tracking", "search.suggest", "search.highlight", "toc.follow"], "search": "../../../../../assets/javascripts/workers/search.dfff1995.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}, "version": {"default": "stable", "provider": "mike"}}</script>
    
    
      <script src="../../../../../assets/javascripts/bundle.78eede0e.min.js"></script>
      
        <script src="../../../../../javascripts/mathjax.js"></script>
      
        <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
      
        <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
      
    
  <script>document$.subscribe(() => {const lightbox = GLightbox({"touchNavigation": true, "loop": false, "zoomable": true, "draggable": true, "openEffect": "zoom", "closeEffect": "zoom", "slideEffect": "slide"});})</script></body>
</html>
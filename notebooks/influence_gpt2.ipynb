{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fabio/miniconda3/envs/pydvl_env/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "from datasets import load_dataset\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"dpv/finetuned-gpt2-tiny\")\n",
    "model = GPT2LMHeadModel.from_pretrained(\"dpv/finetuned-gpt2-tiny\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPT-2 size: 124.4M parameters\n"
     ]
    }
   ],
   "source": [
    "model_size = sum(t.numel() for t in model.parameters())\n",
    "print(f\"GPT-2 size: {model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mlp parameters size: 56.7M parameters\n"
     ]
    }
   ],
   "source": [
    "mlp_model_size = sum(t.numel() for name, t in model.named_parameters() if \"mlp\" in name)\n",
    "print(f\"Mlp parameters size: {mlp_model_size/1000**2:.1f}M parameters\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, t in model.named_parameters():\n",
    "    if \"mlp\" not in name:\n",
    "        t.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.wte.weight\n",
      "transformer.wpe.weight\n",
      "transformer.h.0.ln_1.weight\n",
      "transformer.h.0.ln_1.bias\n",
      "transformer.h.0.attn.c_attn.weight\n",
      "transformer.h.0.attn.c_attn.bias\n",
      "transformer.h.0.attn.c_proj.weight\n",
      "transformer.h.0.attn.c_proj.bias\n",
      "transformer.h.0.ln_2.weight\n",
      "transformer.h.0.ln_2.bias\n",
      "transformer.h.0.mlp.c_fc.weight\n",
      "transformer.h.0.mlp.c_fc.bias\n",
      "transformer.h.0.mlp.c_proj.weight\n",
      "transformer.h.0.mlp.c_proj.bias\n",
      "transformer.h.1.ln_1.weight\n",
      "transformer.h.1.ln_1.bias\n",
      "transformer.h.1.attn.c_attn.weight\n",
      "transformer.h.1.attn.c_attn.bias\n",
      "transformer.h.1.attn.c_proj.weight\n",
      "transformer.h.1.attn.c_proj.bias\n",
      "transformer.h.1.ln_2.weight\n",
      "transformer.h.1.ln_2.bias\n",
      "transformer.h.1.mlp.c_fc.weight\n",
      "transformer.h.1.mlp.c_fc.bias\n",
      "transformer.h.1.mlp.c_proj.weight\n",
      "transformer.h.1.mlp.c_proj.bias\n",
      "transformer.h.2.ln_1.weight\n",
      "transformer.h.2.ln_1.bias\n",
      "transformer.h.2.attn.c_attn.weight\n",
      "transformer.h.2.attn.c_attn.bias\n",
      "transformer.h.2.attn.c_proj.weight\n",
      "transformer.h.2.attn.c_proj.bias\n",
      "transformer.h.2.ln_2.weight\n",
      "transformer.h.2.ln_2.bias\n",
      "transformer.h.2.mlp.c_fc.weight\n",
      "transformer.h.2.mlp.c_fc.bias\n",
      "transformer.h.2.mlp.c_proj.weight\n",
      "transformer.h.2.mlp.c_proj.bias\n",
      "transformer.h.3.ln_1.weight\n",
      "transformer.h.3.ln_1.bias\n",
      "transformer.h.3.attn.c_attn.weight\n",
      "transformer.h.3.attn.c_attn.bias\n",
      "transformer.h.3.attn.c_proj.weight\n",
      "transformer.h.3.attn.c_proj.bias\n",
      "transformer.h.3.ln_2.weight\n",
      "transformer.h.3.ln_2.bias\n",
      "transformer.h.3.mlp.c_fc.weight\n",
      "transformer.h.3.mlp.c_fc.bias\n",
      "transformer.h.3.mlp.c_proj.weight\n",
      "transformer.h.3.mlp.c_proj.bias\n",
      "transformer.h.4.ln_1.weight\n",
      "transformer.h.4.ln_1.bias\n",
      "transformer.h.4.attn.c_attn.weight\n",
      "transformer.h.4.attn.c_attn.bias\n",
      "transformer.h.4.attn.c_proj.weight\n",
      "transformer.h.4.attn.c_proj.bias\n",
      "transformer.h.4.ln_2.weight\n",
      "transformer.h.4.ln_2.bias\n",
      "transformer.h.4.mlp.c_fc.weight\n",
      "transformer.h.4.mlp.c_fc.bias\n",
      "transformer.h.4.mlp.c_proj.weight\n",
      "transformer.h.4.mlp.c_proj.bias\n",
      "transformer.h.5.ln_1.weight\n",
      "transformer.h.5.ln_1.bias\n",
      "transformer.h.5.attn.c_attn.weight\n",
      "transformer.h.5.attn.c_attn.bias\n",
      "transformer.h.5.attn.c_proj.weight\n",
      "transformer.h.5.attn.c_proj.bias\n",
      "transformer.h.5.ln_2.weight\n",
      "transformer.h.5.ln_2.bias\n",
      "transformer.h.5.mlp.c_fc.weight\n",
      "transformer.h.5.mlp.c_fc.bias\n",
      "transformer.h.5.mlp.c_proj.weight\n",
      "transformer.h.5.mlp.c_proj.bias\n",
      "transformer.h.6.ln_1.weight\n",
      "transformer.h.6.ln_1.bias\n",
      "transformer.h.6.attn.c_attn.weight\n",
      "transformer.h.6.attn.c_attn.bias\n",
      "transformer.h.6.attn.c_proj.weight\n",
      "transformer.h.6.attn.c_proj.bias\n",
      "transformer.h.6.ln_2.weight\n",
      "transformer.h.6.ln_2.bias\n",
      "transformer.h.6.mlp.c_fc.weight\n",
      "transformer.h.6.mlp.c_fc.bias\n",
      "transformer.h.6.mlp.c_proj.weight\n",
      "transformer.h.6.mlp.c_proj.bias\n",
      "transformer.h.7.ln_1.weight\n",
      "transformer.h.7.ln_1.bias\n",
      "transformer.h.7.attn.c_attn.weight\n",
      "transformer.h.7.attn.c_attn.bias\n",
      "transformer.h.7.attn.c_proj.weight\n",
      "transformer.h.7.attn.c_proj.bias\n",
      "transformer.h.7.ln_2.weight\n",
      "transformer.h.7.ln_2.bias\n",
      "transformer.h.7.mlp.c_fc.weight\n",
      "transformer.h.7.mlp.c_fc.bias\n",
      "transformer.h.7.mlp.c_proj.weight\n",
      "transformer.h.7.mlp.c_proj.bias\n",
      "transformer.h.8.ln_1.weight\n",
      "transformer.h.8.ln_1.bias\n",
      "transformer.h.8.attn.c_attn.weight\n",
      "transformer.h.8.attn.c_attn.bias\n",
      "transformer.h.8.attn.c_proj.weight\n",
      "transformer.h.8.attn.c_proj.bias\n",
      "transformer.h.8.ln_2.weight\n",
      "transformer.h.8.ln_2.bias\n",
      "transformer.h.8.mlp.c_fc.weight\n",
      "transformer.h.8.mlp.c_fc.bias\n",
      "transformer.h.8.mlp.c_proj.weight\n",
      "transformer.h.8.mlp.c_proj.bias\n",
      "transformer.h.9.ln_1.weight\n",
      "transformer.h.9.ln_1.bias\n",
      "transformer.h.9.attn.c_attn.weight\n",
      "transformer.h.9.attn.c_attn.bias\n",
      "transformer.h.9.attn.c_proj.weight\n",
      "transformer.h.9.attn.c_proj.bias\n",
      "transformer.h.9.ln_2.weight\n",
      "transformer.h.9.ln_2.bias\n",
      "transformer.h.9.mlp.c_fc.weight\n",
      "transformer.h.9.mlp.c_fc.bias\n",
      "transformer.h.9.mlp.c_proj.weight\n",
      "transformer.h.9.mlp.c_proj.bias\n",
      "transformer.h.10.ln_1.weight\n",
      "transformer.h.10.ln_1.bias\n",
      "transformer.h.10.attn.c_attn.weight\n",
      "transformer.h.10.attn.c_attn.bias\n",
      "transformer.h.10.attn.c_proj.weight\n",
      "transformer.h.10.attn.c_proj.bias\n",
      "transformer.h.10.ln_2.weight\n",
      "transformer.h.10.ln_2.bias\n",
      "transformer.h.10.mlp.c_fc.weight\n",
      "transformer.h.10.mlp.c_fc.bias\n",
      "transformer.h.10.mlp.c_proj.weight\n",
      "transformer.h.10.mlp.c_proj.bias\n",
      "transformer.h.11.ln_1.weight\n",
      "transformer.h.11.ln_1.bias\n",
      "transformer.h.11.attn.c_attn.weight\n",
      "transformer.h.11.attn.c_attn.bias\n",
      "transformer.h.11.attn.c_proj.weight\n",
      "transformer.h.11.attn.c_proj.bias\n",
      "transformer.h.11.ln_2.weight\n",
      "transformer.h.11.ln_2.bias\n",
      "transformer.h.11.mlp.c_fc.weight\n",
      "transformer.h.11.mlp.c_fc.bias\n",
      "transformer.h.11.mlp.c_proj.weight\n",
      "transformer.h.11.mlp.c_proj.bias\n",
      "transformer.ln_f.weight\n",
      "transformer.ln_f.bias\n"
     ]
    }
   ],
   "source": [
    "for name, t in model.named_parameters():\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In a near future, in a little human colony, the human race\"\n",
    "encoded_input = tokenizer(text, return_tensors=\"pt\")\n",
    "# output_base = model(**encoded_input)\n",
    "output = model.generate(\n",
    "    **encoded_input, max_length=25, pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "output_text = tokenizer.decode(output[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a near future, in a little human colony, the human race will be able to create a new species of life.\n"
     ]
    }
   ],
   "source": [
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  818,   257,  1474,  2003,    11,   287,   257,  1310,  1692, 18815,\n",
       "            11,   262,  1692,  3234,   481,   307,  1498,   284,  2251,   257,\n",
       "           649,  4693,   286,  1204,    13]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Directly with model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the statement-, the the world over-, the human race will'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_input = tokenizer(text, return_tensors=\"pt\")\n",
    "model_output = model(**encoded_input, labels=encoded_input[\"input_ids\"])\n",
    "tokenizer.decode(model_output.logits.argmax(dim=2)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' will'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logits = model_output.logits[:, -1, :]\n",
    "next_token = torch.argmax(next_token_logits, dim=-1)\n",
    "tokenizer.decode(next_token, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 262, 2643,   12,   11,  262,  262,  995,  625,   12,   11,  262, 1692,\n",
       "         3234,  481]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model_output.logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the statement-, the the world over-, the human race will'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(\n",
    "    torch.argmax(model_output.logits, dim=-1)[0],\n",
    "    skip_special_tokens=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_sentence(sentence_tokens):\n",
    "    inputs_ids = []\n",
    "    label = []\n",
    "    for label_token_idx in range(1, len(sentence_tokens)):\n",
    "        input_ids = [tokenizer.eos_token_id] * (\n",
    "            len(sentence_tokens) - 1 - label_token_idx\n",
    "        ) + sentence_tokens[:label_token_idx]\n",
    "        inputs_ids.append(input_ids)\n",
    "        label.append(sentence_tokens[label_token_idx])\n",
    "    return torch.as_tensor(inputs_ids), torch.as_tensor(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_input = len(encoded_input[\"input_ids\"][0])\n",
    "batch_input_tokens, labels = batch_sentence(output[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_output = model(batch_input_tokens)\n",
    "next_token_logits = model_output.logits[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the recent-, the which world over-, a world race will be able to create a new species of life.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_tokens = torch.argmax(model_output.logits[:, -1, :], dim=-1)\n",
    "tokenizer.decode(\n",
    "    next_tokens,\n",
    "    skip_special_tokens=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare batch_input to model output with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"In \"\n",
    "encoded_input = tokenizer(text, return_tensors=\"pt\")\n",
    "# output_base = model(**encoded_input)\n",
    "output = model.generate(\n",
    "    **encoded_input, max_length=25, pad_token_id=tokenizer.eos_token_id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_input_tokens, labels = batch_sentence(output[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "next_token_logits = []\n",
    "for input_ in batch_input_tokens:\n",
    "    model_output = model(torch.as_tensor(input_))\n",
    "    next_token_logits.append(model_output.logits[-1, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dealing with train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration roneneldan--TinyStories-6ac769f186d7da53\n",
      "Found cached dataset parquet (/Users/fabio/.cache/huggingface/datasets/roneneldan___parquet/roneneldan--TinyStories-6ac769f186d7da53/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = load_dataset(\"roneneldan/TinyStories\", split=\"train\")\n",
    "\n",
    "train_ds = train_dataset.shuffle().select(range(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-47b0d3108625b787\n",
      "Found cached dataset generator (/Users/fabio/.cache/huggingface/datasets/generator/default-47b0d3108625b787/0.0.0)\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset as HFDataset\n",
    "\n",
    "\n",
    "def gen():\n",
    "    yield {\"text\": output_text}\n",
    "\n",
    "\n",
    "test_ds = HFDataset.from_generator(gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "\n",
    "class TinyStoriesDataset(Dataset):\n",
    "    def __init__(self, dataset, tokenizer):\n",
    "        self.tokenized_ds = dataset.map(\n",
    "            lambda x: tokenizer(x[\"text\"], return_tensors=\"pt\")\n",
    "        )\n",
    "        self.minimum_len = min([len(x[\"input_ids\"][0]) for x in self.tokenized_ds])\n",
    "        self.last_sentence_id = None\n",
    "        self.last_batched_sentence = None\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.tokenized_ds) * (self.minimum_len - 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sentence_id = idx // self.minimum_len\n",
    "        if sentence_id != self.last_sentence_id:\n",
    "            self.last_sentence_id = sentence_id\n",
    "            self.last_batched_sentence, self.sentence_labels = batch_sentence(\n",
    "                self.tokenized_ds[sentence_id][\"input_ids\"][0][: self.minimum_len]\n",
    "            )\n",
    "        return (\n",
    "            self.last_batched_sentence[idx % self.minimum_len],\n",
    "            self.sentence_labels[idx % self.minimum_len],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 253.91ex/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 577.01ex/s]\n"
     ]
    }
   ],
   "source": [
    "batched_train_ds = TinyStoriesDataset(train_ds, tokenizer)\n",
    "batched_test_ds = TinyStoriesDataset(test_ds, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(batched_train_ds, batch_size=4)\n",
    "test_dataloader = DataLoader(batched_test_ds, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PatchedGPT2LMHeadModel(GPT2LMHeadModel):\n",
    "    def forward(self, input_ids, **kwargs):\n",
    "        return super().forward(input_ids, **kwargs).logits[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batch Test Gradients:   0%|          | 0/6 [00:00<?, ?it/s]\n",
      "Failed to pre-allocate result tensor: squeeze(): argument 'input' (position 1) must be Tensor, not BaseModelOutputWithPastAndCrossAttentions\n",
      "Evaluate all resulting tensor and concatenate\n",
      "Batch Test Gradients:   0%|          | 0/6 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "squeeze(): argument 'input' (position 1) must be Tensor, not BaseModelOutputWithPastAndCrossAttentions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/valuation/src/pydvl/influence/general.py:116\u001b[0m, in \u001b[0;36mcompute_influence_factors\u001b[0;34m(model, training_data, test_data, inversion_method, hessian_perturbation, progress, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m     resulting_shape \u001b[39m=\u001b[39m (\u001b[39mlen\u001b[39m(test_data\u001b[39m.\u001b[39mdataset), model\u001b[39m.\u001b[39mnum_params)  \u001b[39m# type:ignore\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     rhs \u001b[39m=\u001b[39m cat_gen(\n\u001b[1;32m    117\u001b[0m         test_grads(), resulting_shape, model  \u001b[39m# type:ignore\u001b[39;49;00m\n\u001b[1;32m    118\u001b[0m     )  \u001b[39m# type:ignore\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/Desktop/valuation/src/pydvl/influence/torch/torch_differentiable.py:489\u001b[0m, in \u001b[0;36mTorchTensorUtilities.cat_gen\u001b[0;34m(a, resulting_shape, model, axis)\u001b[0m\n\u001b[1;32m    488\u001b[0m start_idx \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m--> 489\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m a:\n\u001b[1;32m    490\u001b[0m     stop_idx \u001b[39m=\u001b[39m start_idx \u001b[39m+\u001b[39m x\u001b[39m.\u001b[39mshape[axis]\n",
      "File \u001b[0;32m~/Desktop/valuation/src/pydvl/influence/general.py:106\u001b[0m, in \u001b[0;36mcompute_influence_factors.<locals>.test_grads\u001b[0;34m()\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mfor\u001b[39;00m x_test, y_test \u001b[39min\u001b[39;00m maybe_progress(\n\u001b[1;32m    103\u001b[0m     test_data, progress, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch Test Gradients\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m ):\n\u001b[1;32m    105\u001b[0m     \u001b[39myield\u001b[39;00m stack(\n\u001b[0;32m--> 106\u001b[0m         [\n\u001b[1;32m    107\u001b[0m             model\u001b[39m.\u001b[39mgrad(inpt, target)\n\u001b[1;32m    108\u001b[0m             \u001b[39mfor\u001b[39;00m inpt, target \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(unsqueeze(x_test, \u001b[39m1\u001b[39m), y_test)\n\u001b[1;32m    109\u001b[0m         ]\n\u001b[1;32m    110\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/valuation/src/pydvl/influence/general.py:107\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mfor\u001b[39;00m x_test, y_test \u001b[39min\u001b[39;00m maybe_progress(\n\u001b[1;32m    103\u001b[0m     test_data, progress, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch Test Gradients\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m ):\n\u001b[1;32m    105\u001b[0m     \u001b[39myield\u001b[39;00m stack(\n\u001b[1;32m    106\u001b[0m         [\n\u001b[0;32m--> 107\u001b[0m             model\u001b[39m.\u001b[39;49mgrad(inpt, target)\n\u001b[1;32m    108\u001b[0m             \u001b[39mfor\u001b[39;00m inpt, target \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(unsqueeze(x_test, \u001b[39m1\u001b[39m), y_test)\n\u001b[1;32m    109\u001b[0m         ]\n\u001b[1;32m    110\u001b[0m     )\n",
      "File \u001b[0;32m~/Desktop/valuation/src/pydvl/influence/torch/torch_differentiable.py:130\u001b[0m, in \u001b[0;36mTorchTwiceDifferentiable.grad\u001b[0;34m(self, x, y, create_graph)\u001b[0m\n\u001b[1;32m    128\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 130\u001b[0m loss_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(torch\u001b[39m.\u001b[39;49msqueeze(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)), torch\u001b[39m.\u001b[39msqueeze(y))\n\u001b[1;32m    131\u001b[0m grad_f \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(\n\u001b[1;32m    132\u001b[0m     loss_value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters, create_graph\u001b[39m=\u001b[39mcreate_graph\n\u001b[1;32m    133\u001b[0m )\n",
      "\u001b[0;31mTypeError\u001b[0m: squeeze(): argument 'input' (position 1) must be Tensor, not BaseModelOutputWithPastAndCrossAttentions",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb Cell 30\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb#X45sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mmlp\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m name:\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb#X45sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         t\u001b[39m.\u001b[39mrequires_grad \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb#X45sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m ekfac_train_influences \u001b[39m=\u001b[39m compute_influences(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb#X45sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m     TorchTwiceDifferentiable(model\u001b[39m.\u001b[39;49mtransformer, torch\u001b[39m.\u001b[39;49mnn\u001b[39m.\u001b[39;49mfunctional\u001b[39m.\u001b[39;49mcross_entropy),\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb#X45sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     training_data\u001b[39m=\u001b[39;49mtrain_dataloader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb#X45sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     test_data\u001b[39m=\u001b[39;49mtest_dataloader,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb#X45sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     influence_type\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mup\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb#X45sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     inversion_method\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mekfac\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb#X45sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     hessian_regularization\u001b[39m=\u001b[39;49m\u001b[39m0.1\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb#X45sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     progress\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb#X45sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/fabio/Desktop/valuation/notebooks/influence_gpt2.ipynb#X45sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m mean_ekfac_train_influences \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mmean(ekfac_train_influences\u001b[39m.\u001b[39mnumpy(), axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/valuation/src/pydvl/influence/general.py:317\u001b[0m, in \u001b[0;36mcompute_influences\u001b[0;34m(differentiable_model, training_data, test_data, input_data, inversion_method, influence_type, hessian_regularization, progress, **kwargs)\u001b[0m\n\u001b[1;32m    314\u001b[0m \u001b[39mif\u001b[39;00m test_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    315\u001b[0m     test_data \u001b[39m=\u001b[39m deepcopy(training_data)\n\u001b[0;32m--> 317\u001b[0m influence_factors, _ \u001b[39m=\u001b[39m compute_influence_factors(\n\u001b[1;32m    318\u001b[0m     differentiable_model,\n\u001b[1;32m    319\u001b[0m     training_data,\n\u001b[1;32m    320\u001b[0m     test_data,\n\u001b[1;32m    321\u001b[0m     inversion_method,\n\u001b[1;32m    322\u001b[0m     hessian_perturbation\u001b[39m=\u001b[39;49mhessian_regularization,\n\u001b[1;32m    323\u001b[0m     progress\u001b[39m=\u001b[39;49mprogress,\n\u001b[1;32m    324\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs,\n\u001b[1;32m    325\u001b[0m )\n\u001b[1;32m    327\u001b[0m \u001b[39mreturn\u001b[39;00m influence_type_registry[influence_type](\n\u001b[1;32m    328\u001b[0m     differentiable_model,\n\u001b[1;32m    329\u001b[0m     input_data,\n\u001b[1;32m    330\u001b[0m     influence_factors,\n\u001b[1;32m    331\u001b[0m     progress\u001b[39m=\u001b[39mprogress,\n\u001b[1;32m    332\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/valuation/src/pydvl/influence/general.py:124\u001b[0m, in \u001b[0;36mcompute_influence_factors\u001b[0;34m(model, training_data, test_data, inversion_method, hessian_perturbation, progress, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    120\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    121\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFailed to pre-allocate result tensor: \u001b[39m\u001b[39m{\u001b[39;00me\u001b[39m}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    122\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEvaluate all resulting tensor and concatenate\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m     )\n\u001b[0;32m--> 124\u001b[0m     rhs \u001b[39m=\u001b[39m cat(\u001b[39mlist\u001b[39;49m(test_grads()))\n\u001b[1;32m    126\u001b[0m \u001b[39mreturn\u001b[39;00m solve_hvp(\n\u001b[1;32m    127\u001b[0m     inversion_method,\n\u001b[1;32m    128\u001b[0m     model,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    132\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m    133\u001b[0m )\n",
      "File \u001b[0;32m~/Desktop/valuation/src/pydvl/influence/general.py:106\u001b[0m, in \u001b[0;36mcompute_influence_factors.<locals>.test_grads\u001b[0;34m()\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_grads\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Generator[TensorType, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m]:\n\u001b[1;32m    102\u001b[0m     \u001b[39mfor\u001b[39;00m x_test, y_test \u001b[39min\u001b[39;00m maybe_progress(\n\u001b[1;32m    103\u001b[0m         test_data, progress, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch Test Gradients\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m     ):\n\u001b[1;32m    105\u001b[0m         \u001b[39myield\u001b[39;00m stack(\n\u001b[0;32m--> 106\u001b[0m             [\n\u001b[1;32m    107\u001b[0m                 model\u001b[39m.\u001b[39mgrad(inpt, target)\n\u001b[1;32m    108\u001b[0m                 \u001b[39mfor\u001b[39;00m inpt, target \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(unsqueeze(x_test, \u001b[39m1\u001b[39m), y_test)\n\u001b[1;32m    109\u001b[0m             ]\n\u001b[1;32m    110\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/valuation/src/pydvl/influence/general.py:107\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtest_grads\u001b[39m() \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Generator[TensorType, \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m]:\n\u001b[1;32m    102\u001b[0m     \u001b[39mfor\u001b[39;00m x_test, y_test \u001b[39min\u001b[39;00m maybe_progress(\n\u001b[1;32m    103\u001b[0m         test_data, progress, desc\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBatch Test Gradients\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    104\u001b[0m     ):\n\u001b[1;32m    105\u001b[0m         \u001b[39myield\u001b[39;00m stack(\n\u001b[1;32m    106\u001b[0m             [\n\u001b[0;32m--> 107\u001b[0m                 model\u001b[39m.\u001b[39;49mgrad(inpt, target)\n\u001b[1;32m    108\u001b[0m                 \u001b[39mfor\u001b[39;00m inpt, target \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(unsqueeze(x_test, \u001b[39m1\u001b[39m), y_test)\n\u001b[1;32m    109\u001b[0m             ]\n\u001b[1;32m    110\u001b[0m         )\n",
      "File \u001b[0;32m~/Desktop/valuation/src/pydvl/influence/torch/torch_differentiable.py:130\u001b[0m, in \u001b[0;36mTorchTwiceDifferentiable.grad\u001b[0;34m(self, x, y, create_graph)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mif\u001b[39;00m create_graph \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m x\u001b[39m.\u001b[39mrequires_grad:\n\u001b[1;32m    128\u001b[0m     x \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mrequires_grad_(\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m--> 130\u001b[0m loss_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss(torch\u001b[39m.\u001b[39;49msqueeze(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x)), torch\u001b[39m.\u001b[39msqueeze(y))\n\u001b[1;32m    131\u001b[0m grad_f \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mgrad(\n\u001b[1;32m    132\u001b[0m     loss_value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparameters, create_graph\u001b[39m=\u001b[39mcreate_graph\n\u001b[1;32m    133\u001b[0m )\n\u001b[1;32m    134\u001b[0m \u001b[39mreturn\u001b[39;00m flatten_tensors_to_vector(grad_f)\n",
      "\u001b[0;31mTypeError\u001b[0m: squeeze(): argument 'input' (position 1) must be Tensor, not BaseModelOutputWithPastAndCrossAttentions"
     ]
    }
   ],
   "source": [
    "from pydvl.influence import compute_influences\n",
    "from pydvl.influence.torch import TorchTwiceDifferentiable\n",
    "\n",
    "model = PatchedGPT2LMHeadModel.from_pretrained(\"dpv/finetuned-gpt2-tiny\")\n",
    "\n",
    "for name, t in model.named_modules():\n",
    "    if \"mlp\" not in name:\n",
    "        t.requires_grad = False\n",
    "\n",
    "ekfac_train_influences = compute_influences(\n",
    "    TorchTwiceDifferentiable(model.transformer, torch.nn.functional.cross_entropy),\n",
    "    training_data=train_dataloader,\n",
    "    test_data=test_dataloader,\n",
    "    influence_type=\"up\",\n",
    "    inversion_method=\"ekfac\",\n",
    "    hessian_regularization=0.1,\n",
    "    progress=True,\n",
    ")\n",
    "mean_ekfac_train_influences = np.mean(ekfac_train_influences.numpy(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "PatchedGPT2LMHeadModel(\n",
      "  (transformer): GPT2Model(\n",
      "    (wte): Embedding(50257, 768)\n",
      "    (wpe): Embedding(1024, 768)\n",
      "    (drop): Dropout(p=0.1, inplace=False)\n",
      "    (h): ModuleList(\n",
      "      (0-11): 12 x GPT2Block(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (attn): GPT2Attention(\n",
      "          (c_attn): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (mlp): GPT2MLP(\n",
      "          (c_fc): Conv1D()\n",
      "          (c_proj): Conv1D()\n",
      "          (act): NewGELUActivation()\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (lm_head): Linear(in_features=768, out_features=50257, bias=False)\n",
      ")\n",
      "transformer\n",
      "GPT2Model(\n",
      "  (wte): Embedding(50257, 768)\n",
      "  (wpe): Embedding(1024, 768)\n",
      "  (drop): Dropout(p=0.1, inplace=False)\n",
      "  (h): ModuleList(\n",
      "    (0-11): 12 x GPT2Block(\n",
      "      (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (attn): GPT2Attention(\n",
      "        (c_attn): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "        (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (mlp): GPT2MLP(\n",
      "        (c_fc): Conv1D()\n",
      "        (c_proj): Conv1D()\n",
      "        (act): NewGELUActivation()\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      ")\n",
      "transformer.wte\n",
      "Embedding(50257, 768)\n",
      "transformer.wpe\n",
      "Embedding(1024, 768)\n",
      "transformer.drop\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h\n",
      "ModuleList(\n",
      "  (0-11): 12 x GPT2Block(\n",
      "    (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (attn): GPT2Attention(\n",
      "      (c_attn): Conv1D()\n",
      "      (c_proj): Conv1D()\n",
      "      (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "      (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "    (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "    (mlp): GPT2MLP(\n",
      "      (c_fc): Conv1D()\n",
      "      (c_proj): Conv1D()\n",
      "      (act): NewGELUActivation()\n",
      "      (dropout): Dropout(p=0.1, inplace=False)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "transformer.h.0\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.0.ln_1\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.0.attn\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.0.attn.c_attn\n",
      "Conv1D()\n",
      "transformer.h.0.attn.c_proj\n",
      "Conv1D()\n",
      "transformer.h.0.attn.attn_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.0.attn.resid_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.0.ln_2\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.0.mlp\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.0.mlp.c_fc\n",
      "Conv1D()\n",
      "transformer.h.0.mlp.c_proj\n",
      "Conv1D()\n",
      "transformer.h.0.mlp.act\n",
      "NewGELUActivation()\n",
      "transformer.h.0.mlp.dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.1\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.1.ln_1\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.1.attn\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.1.attn.c_attn\n",
      "Conv1D()\n",
      "transformer.h.1.attn.c_proj\n",
      "Conv1D()\n",
      "transformer.h.1.attn.attn_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.1.attn.resid_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.1.ln_2\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.1.mlp\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.1.mlp.c_fc\n",
      "Conv1D()\n",
      "transformer.h.1.mlp.c_proj\n",
      "Conv1D()\n",
      "transformer.h.1.mlp.act\n",
      "NewGELUActivation()\n",
      "transformer.h.1.mlp.dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.2\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.2.ln_1\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.2.attn\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.2.attn.c_attn\n",
      "Conv1D()\n",
      "transformer.h.2.attn.c_proj\n",
      "Conv1D()\n",
      "transformer.h.2.attn.attn_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.2.attn.resid_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.2.ln_2\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.2.mlp\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.2.mlp.c_fc\n",
      "Conv1D()\n",
      "transformer.h.2.mlp.c_proj\n",
      "Conv1D()\n",
      "transformer.h.2.mlp.act\n",
      "NewGELUActivation()\n",
      "transformer.h.2.mlp.dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.3\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.3.ln_1\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.3.attn\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.3.attn.c_attn\n",
      "Conv1D()\n",
      "transformer.h.3.attn.c_proj\n",
      "Conv1D()\n",
      "transformer.h.3.attn.attn_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.3.attn.resid_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.3.ln_2\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.3.mlp\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.3.mlp.c_fc\n",
      "Conv1D()\n",
      "transformer.h.3.mlp.c_proj\n",
      "Conv1D()\n",
      "transformer.h.3.mlp.act\n",
      "NewGELUActivation()\n",
      "transformer.h.3.mlp.dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.4\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.4.ln_1\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.4.attn\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.4.attn.c_attn\n",
      "Conv1D()\n",
      "transformer.h.4.attn.c_proj\n",
      "Conv1D()\n",
      "transformer.h.4.attn.attn_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.4.attn.resid_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.4.ln_2\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.4.mlp\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.4.mlp.c_fc\n",
      "Conv1D()\n",
      "transformer.h.4.mlp.c_proj\n",
      "Conv1D()\n",
      "transformer.h.4.mlp.act\n",
      "NewGELUActivation()\n",
      "transformer.h.4.mlp.dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.5\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.5.ln_1\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.5.attn\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.5.attn.c_attn\n",
      "Conv1D()\n",
      "transformer.h.5.attn.c_proj\n",
      "Conv1D()\n",
      "transformer.h.5.attn.attn_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.5.attn.resid_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.5.ln_2\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.5.mlp\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.5.mlp.c_fc\n",
      "Conv1D()\n",
      "transformer.h.5.mlp.c_proj\n",
      "Conv1D()\n",
      "transformer.h.5.mlp.act\n",
      "NewGELUActivation()\n",
      "transformer.h.5.mlp.dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.6\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.6.ln_1\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.6.attn\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.6.attn.c_attn\n",
      "Conv1D()\n",
      "transformer.h.6.attn.c_proj\n",
      "Conv1D()\n",
      "transformer.h.6.attn.attn_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.6.attn.resid_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.6.ln_2\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.6.mlp\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.6.mlp.c_fc\n",
      "Conv1D()\n",
      "transformer.h.6.mlp.c_proj\n",
      "Conv1D()\n",
      "transformer.h.6.mlp.act\n",
      "NewGELUActivation()\n",
      "transformer.h.6.mlp.dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.7\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.7.ln_1\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.7.attn\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.7.attn.c_attn\n",
      "Conv1D()\n",
      "transformer.h.7.attn.c_proj\n",
      "Conv1D()\n",
      "transformer.h.7.attn.attn_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.7.attn.resid_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.7.ln_2\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.7.mlp\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.7.mlp.c_fc\n",
      "Conv1D()\n",
      "transformer.h.7.mlp.c_proj\n",
      "Conv1D()\n",
      "transformer.h.7.mlp.act\n",
      "NewGELUActivation()\n",
      "transformer.h.7.mlp.dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.8\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.8.ln_1\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.8.attn\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.8.attn.c_attn\n",
      "Conv1D()\n",
      "transformer.h.8.attn.c_proj\n",
      "Conv1D()\n",
      "transformer.h.8.attn.attn_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.8.attn.resid_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.8.ln_2\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.8.mlp\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.8.mlp.c_fc\n",
      "Conv1D()\n",
      "transformer.h.8.mlp.c_proj\n",
      "Conv1D()\n",
      "transformer.h.8.mlp.act\n",
      "NewGELUActivation()\n",
      "transformer.h.8.mlp.dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.9\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.9.ln_1\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.9.attn\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.9.attn.c_attn\n",
      "Conv1D()\n",
      "transformer.h.9.attn.c_proj\n",
      "Conv1D()\n",
      "transformer.h.9.attn.attn_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.9.attn.resid_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.9.ln_2\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.9.mlp\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.9.mlp.c_fc\n",
      "Conv1D()\n",
      "transformer.h.9.mlp.c_proj\n",
      "Conv1D()\n",
      "transformer.h.9.mlp.act\n",
      "NewGELUActivation()\n",
      "transformer.h.9.mlp.dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.10\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.10.ln_1\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.10.attn\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.10.attn.c_attn\n",
      "Conv1D()\n",
      "transformer.h.10.attn.c_proj\n",
      "Conv1D()\n",
      "transformer.h.10.attn.attn_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.10.attn.resid_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.10.ln_2\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.10.mlp\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.10.mlp.c_fc\n",
      "Conv1D()\n",
      "transformer.h.10.mlp.c_proj\n",
      "Conv1D()\n",
      "transformer.h.10.mlp.act\n",
      "NewGELUActivation()\n",
      "transformer.h.10.mlp.dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.11\n",
      "GPT2Block(\n",
      "  (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (attn): GPT2Attention(\n",
      "    (c_attn): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "    (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (mlp): GPT2MLP(\n",
      "    (c_fc): Conv1D()\n",
      "    (c_proj): Conv1D()\n",
      "    (act): NewGELUActivation()\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      ")\n",
      "transformer.h.11.ln_1\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.11.attn\n",
      "GPT2Attention(\n",
      "  (c_attn): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (attn_dropout): Dropout(p=0.1, inplace=False)\n",
      "  (resid_dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.11.attn.c_attn\n",
      "Conv1D()\n",
      "transformer.h.11.attn.c_proj\n",
      "Conv1D()\n",
      "transformer.h.11.attn.attn_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.11.attn.resid_dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.h.11.ln_2\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "transformer.h.11.mlp\n",
      "GPT2MLP(\n",
      "  (c_fc): Conv1D()\n",
      "  (c_proj): Conv1D()\n",
      "  (act): NewGELUActivation()\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      ")\n",
      "transformer.h.11.mlp.c_fc\n",
      "Conv1D()\n",
      "transformer.h.11.mlp.c_proj\n",
      "Conv1D()\n",
      "transformer.h.11.mlp.act\n",
      "NewGELUActivation()\n",
      "transformer.h.11.mlp.dropout\n",
      "Dropout(p=0.1, inplace=False)\n",
      "transformer.ln_f\n",
      "LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "lm_head\n",
      "Linear(in_features=768, out_features=50257, bias=False)\n"
     ]
    }
   ],
   "source": [
    "for name, t in model.named_modules():\n",
    "    print(name)\n",
    "    print(t)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pydvl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

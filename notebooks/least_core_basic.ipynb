{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "995d4271",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Least Core for Data Valuation\n",
    "\n",
    "This notebook introduces Least Core methods for the computation of data values using pyDVL.\n",
    "\n",
    "Shapley values define a fair way of distributing the worth of the whole training set when every data point is part of it. But they do not consider the question of stability of subsets: Could some data points obtain a higher payoff if they formed smaller subsets? It is argued that this might be relevant if data providers are paid based on data value, since Shapley values can incentivise them not to contribute their data to the \"grand coalition\", but instead try to form smaller ones. Whether this is of actual practical relevance is debatable, but in any case, the least core is an alternative tool available for any task of Data Valuation\n",
    "\n",
    "The Core is another approach to compute data values originating in cooperative game theory that attempts to answer those questions. It is the set of feasible payoffs that cannot be improved upon by a coalition of the participants.\n",
    "\n",
    "Its use for Data Valuation was first described in the paper [*If You Like Shapley Then Youâ€™ll Love the Core*](https://ojs.aaai.org/index.php/AAAI/article/view/16721) by Tom Yan and Ariel D. Procaccia.\n",
    "\n",
    "The Least Core value $v$ of the $i$-th sample in dataset $D$ wrt. utility $u$ is computed\n",
    "by solving the following Linear Program:\n",
    "\n",
    "$$\n",
    "\\begin{array}{lll}\n",
    "\\text{minimize} & \\displaystyle{e} & \\\\\n",
    "\\text{subject to} & \\displaystyle\\sum_{x_i\\in D} v_u(x_i) = u(D) & \\\\\n",
    "& \\displaystyle\\sum_{x_i\\in S} v_u(x_i) + e \\geq u(S) &, \\forall S \\subset D, S \\neq \\emptyset \\\\\n",
    "\\end{array}\n",
    "$$\n",
    "\n",
    "To illustrate this method we will use a synthetic dataset. We will first use a subset of 10 data point to compute the exact values and use them to assess the Monte Carlo approximation. Afterwards, we will conduct the data removal experiments as described by Ghorbani and Zou in their paper [Data Shapley: Equitable Valuation of Data for Machine Learning](https://arxiv.org/abs/1904.02868v1): We compute the data valuation given different computation budgets and incrementally remove a percentage of the best, respectively worst, data points and observe how that affects the utility."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa21e5d1",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing the main libraries and setting some defaults.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "If you are reading this in the documentation, some boilerplate (including most plotting code) has been omitted for convenience.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ee61fd",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "plt.ioff()  # Prevent jupyter from automatically plotting\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 8)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"xtick.labelsize\"] = 12\n",
    "plt.rcParams[\"ytick.labelsize\"] = 10\n",
    "plt.rcParams[\"axes.facecolor\"] = (1, 1, 1, 0)\n",
    "plt.rcParams[\"figure.facecolor\"] = (1, 1, 1, 0)\n",
    "\n",
    "mean_colors = [\"dodgerblue\", \"indianred\", \"limegreen\", \"darkorange\", \"darkorchid\"]\n",
    "shade_colors = [\"lightskyblue\", \"firebrick\", \"seagreen\", \"gold\", \"plum\"]\n",
    "\n",
    "seed = 16\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "is_CI = os.environ.get(\"CI\")\n",
    "\n",
    "dataset_size = 200\n",
    "n_iterations = 5000\n",
    "train_mini_size = 12\n",
    "n_jobs = 12\n",
    "n_runs = 10\n",
    "\n",
    "if is_CI:\n",
    "    dataset_size = 20\n",
    "    n_iterations = 500\n",
    "    train_mini_size = 4\n",
    "    n_jobs = 1\n",
    "    n_runs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea11d1ff",
   "metadata": {},
   "source": [
    "We will be using the following functions and classes from pyDVL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3155c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydvl.reporting.plots import shaded_mean_std\n",
    "from pydvl.reporting.scores import compute_removal_score\n",
    "from pydvl.valuation import (\n",
    "    Dataset,\n",
    "    ExactLeastCoreValuation,\n",
    "    ModelUtility,\n",
    "    MonteCarloLeastCoreValuation,\n",
    "    SupervisedScorer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7d81aa",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "We generate a synthetic dataset using the [`make_classification`](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.make_classification.html) function from scikit-learn.\n",
    "\n",
    "We sample 200 data points from a 50-dimensional Gaussian distribution with 25 informative features and 25 non-informative features (generated as random linear combinations of the informative features).\n",
    "\n",
    "The 200 samples are uniformly distributed across 3 classes with a small percentage of noise added to the labels to make the task a bit more difficult."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e916a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(\n",
    "    n_samples=dataset_size,\n",
    "    n_features=50,\n",
    "    n_informative=25,\n",
    "    n_classes=3,\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "train, test = Dataset.from_arrays(X, y, stratify_by_target=True, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffce8661",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=500, solver=\"liblinear\")\n",
    "model.fit(train.data().x, train.data().y);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "270c1bf3",
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "train_acc = model.score(train.data().x, train.data().y)\n",
    "test_acc = model.score(test.data().x, test.data().y)\n",
    "print(f\"Training accuracy: {100 * train_acc:0.2f}%\")\n",
    "print(f\"Testing accuracy: {100 * test_acc:0.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b4a2d1",
   "metadata": {},
   "source": [
    "## Estimating Least Core Values\n",
    "\n",
    "In this first section we use a smaller subset of the dataset containing 12 samples in order to be able to compute exact values reasonably fast. Recall that, in order to assemble the problem, for every subset $S \\subset D$ we must compute the utility $u(S).$ We then have a linear problem with $2^{|D|}$ constraints to solve. After doing this, we use the Monte Carlo method with a limited budget (maximum number of constraints) to approximate the LC values on the same reduced dataset, and we repeat this several times to assess the stability of the approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c584b2fa6fbf9449",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mini = train[:train_mini_size]\n",
    "scorer = SupervisedScorer(\"accuracy\", test_data=test, default=0, range=(0, 1))\n",
    "utility = ModelUtility(model=model, scorer=scorer)\n",
    "valuation = ExactLeastCoreValuation(utility=utility)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa91a124",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from joblib import parallel_config\n",
    "\n",
    "with parallel_config(n_jobs=n_jobs):\n",
    "    valuation.fit(train_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b84bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "exact_result = valuation.result\n",
    "exact_df = exact_result.to_dataframe(column=\"exact\").T\n",
    "exact_df = exact_df[sorted(exact_df.columns)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a40f0c2761b2dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relative_error(x, estimate, norm):\n",
    "    return np.linalg.norm(x - estimate, ord=norm) / np.linalg.norm(x, ord=norm)\n",
    "\n",
    "\n",
    "budget_array = np.logspace(8, len(train_mini), base=2, num=8, endpoint=False, dtype=int)\n",
    "\n",
    "all_estimated_values_df = []\n",
    "all_errors = {budget: [] for budget in budget_array}\n",
    "\n",
    "with tqdm(total=len(budget_array) * n_runs) as pbar:\n",
    "    for budget in budget_array:\n",
    "        pbar.set_description(f\"Computing values with {budget} constraints\")\n",
    "        dfs = []\n",
    "        errors = []\n",
    "        column_name = f\"estimated_{budget}\"\n",
    "        valuation = MonteCarloLeastCoreValuation(\n",
    "            utility=utility, n_samples=budget, progress=False\n",
    "        )\n",
    "        for i in range(n_runs):\n",
    "            with parallel_config(n_jobs=n_jobs):\n",
    "                valuation.fit(train_mini)\n",
    "            df = (\n",
    "                valuation.result.to_dataframe(column=column_name)\n",
    "                .drop(columns=[f\"{column_name}_variances\", f\"{column_name}_counts\"])\n",
    "                .T\n",
    "            )\n",
    "            df = df[sorted(df.columns)]\n",
    "            error = relative_error(\n",
    "                exact_df.loc[\"exact\"].values, np.nan_to_num(df.values.ravel()), norm=1\n",
    "            )\n",
    "            all_errors[budget].append(error)\n",
    "            df[\"budget\"] = budget\n",
    "            dfs.append(df)\n",
    "            pbar.update(1)\n",
    "        estimated_values_df = pd.concat(dfs)\n",
    "        all_estimated_values_df.append(estimated_values_df)\n",
    "\n",
    "values_df = pd.concat(all_estimated_values_df)\n",
    "errors_df = pd.DataFrame(all_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e02c36",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "outputs": [],
   "source": [
    "_ = shaded_mean_std(\n",
    "    errors_df,\n",
    "    abscissa=errors_df.columns,\n",
    "    num_std=1,\n",
    "    xlabel=\"Number of constraints\",\n",
    "    ylabel=\"$l_2$ Error\",\n",
    "    label=\"Estimated values\",\n",
    "    title=\"$l_1$ approximation error of values as a function of the budget\",\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8488311",
   "metadata": {},
   "source": [
    "We can see that the approximation error decreases as the number of constraints increases, but that there are diminishing returns for increasing the budget beyond a certain point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bccf93",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "outputs": [],
   "source": [
    "mean_std_values_df = values_df.drop(columns=\"budget\").agg([\"mean\", \"std\"])\n",
    "df = pd.concat([exact_df, mean_std_values_df])\n",
    "df = df.sort_values(\"exact\", ascending=False, axis=1).T\n",
    "df.plot(\n",
    "    kind=\"bar\",\n",
    "    title=\"Comparison of Exact and Monte Carlo Methods\",\n",
    "    xlabel=\"Index\",\n",
    "    ylabel=\"Value\",\n",
    "    color=[\"dodgerblue\", \"indianred\"],\n",
    "    y=[\"exact\", \"mean\"],\n",
    "    yerr=[\n",
    "        np.sqrt(exact_df.loc[\"exact_variances\"] / n_runs),\n",
    "        mean_std_values_df.loc[\"std\"],\n",
    "    ],\n",
    ")\n",
    "plt.legend([\"Exact\", \"Monte Carlo\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "886ea343",
   "metadata": {},
   "source": [
    "## Data Removal\n",
    "\n",
    "In the final two experiments, we rank the training set according to the value estimates obtained with Monte Carlo Least Core. Then, we incrementally remove up to 40% of the most / least valuable training points, train the model on this subset and compute its accuracy on the previously held-out test set."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73e30a4",
   "metadata": {},
   "source": [
    "### Remove Best\n",
    "\n",
    "We start by removing the best data points and seeing how the model's accuracy evolves. We repeat the whole process (valuation and removal) several times to assess the stability of the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985c27e0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "from pydvl.valuation.methods.random import RandomValuation\n",
    "\n",
    "removal_percentages = np.arange(0, 0.41, 0.05)\n",
    "methods = [\n",
    "    RandomValuation(random_state=seed),\n",
    "    MonteCarloLeastCoreValuation(\n",
    "        utility=utility, n_samples=n_iterations, progress=False, seed=seed\n",
    "    ),\n",
    "]\n",
    "all_scores = []\n",
    "for i in trange(n_runs, position=0, desc=f\"Removing best points, {n_runs} times\"):\n",
    "    for method in methods:\n",
    "        with parallel_config(n_jobs=n_jobs):\n",
    "            valuation.fit(train)\n",
    "        result = valuation.result\n",
    "\n",
    "        scores = compute_removal_score(\n",
    "            utility,\n",
    "            result,\n",
    "            train,\n",
    "            removal_percentages,\n",
    "            remove_best=True,\n",
    "            progress=False,\n",
    "        )\n",
    "\n",
    "        scores[\"method_name\"] = method.__class__.__name__\n",
    "        all_scores.append(scores)\n",
    "\n",
    "scores_df = pd.DataFrame(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f95fb06",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    method_name = method.__class__.__name__\n",
    "    shaded_mean_std(\n",
    "        scores_df[scores_df[\"method_name\"] == method_name].drop(\n",
    "            columns=[\"method_name\"]\n",
    "        ),\n",
    "        abscissa=removal_percentages,\n",
    "        mean_color=mean_colors[i],\n",
    "        shade_color=shade_colors[i],\n",
    "        xlabel=\"Percentage Removal\",\n",
    "        ylabel=\"Accuracy\",\n",
    "        label=method_name,\n",
    "        title=\"Accuracy as a function of percentage of removed best data points\",\n",
    "        ax=ax,\n",
    "    )\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe590fa",
   "metadata": {},
   "source": [
    "We can clearly see that removing the most valuable data points, as given by the Least Core method, leads to, on average, a decrease in the model's performance and that the method outperforms random removal of data points."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f4f0ba7",
   "metadata": {},
   "source": [
    "### Remove Worst\n",
    "\n",
    "We then proceed to removing the worst data points and seeing how the model's accuracy evolves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f33b5bb",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "outputs": [],
   "source": [
    "all_scores = []\n",
    "for i in trange(n_runs, position=0, desc=f\"Removing best points, {n_runs} times\"):\n",
    "    for method in methods:\n",
    "        with parallel_config(n_jobs=n_jobs):\n",
    "            valuation.fit(train)\n",
    "        result = valuation.result\n",
    "\n",
    "        scores = compute_removal_score(\n",
    "            utility,\n",
    "            result,\n",
    "            train,\n",
    "            removal_percentages,\n",
    "            remove_best=False,\n",
    "            progress=False,\n",
    "        )\n",
    "\n",
    "        scores[\"method_name\"] = method.__class__.__name__\n",
    "        all_scores.append(scores)\n",
    "\n",
    "scores_df = pd.DataFrame(all_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d69593",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "for i, method in enumerate(methods):\n",
    "    method_name = method.__class__.__name__\n",
    "    shaded_mean_std(\n",
    "        scores_df[scores_df[\"method_name\"] == method_name].drop(\n",
    "            columns=[\"method_name\"]\n",
    "        ),\n",
    "        abscissa=removal_percentages,\n",
    "        mean_color=mean_colors[i],\n",
    "        shade_color=shade_colors[i],\n",
    "        xlabel=\"Percentage Removal\",\n",
    "        ylabel=\"Accuracy\",\n",
    "        label=method_name,\n",
    "        title=\"Accuracy as a function of percentage of removed worst data points\",\n",
    "        ax=ax,\n",
    "    )\n",
    "plt.legend()\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fc86c3",
   "metadata": {},
   "source": [
    "We can clearly see that removing the least valuable data points, as given by the Least Core method, leads to, on average, an increase in the model's performance and that the method outperforms the random removal of data points."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

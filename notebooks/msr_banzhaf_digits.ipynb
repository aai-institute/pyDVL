{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Banzhaf Semi-values for data valuation\n",
    "\n",
    "This notebook showcases [Data Banzhaf: A Robust Data Valuation Framework for Machine Learning](https://proceedings.mlr.press/v206/wang23e.html) by Wang, and Jia.\n",
    "\n",
    "Computing Banzhaf semi-values using pyDVL follows basically the same procedure as all other semi-value-based methods like Shapley values. However, Data-Banzhaf tends to be more robust to stochasticity in the training process than other semi-values. A property that we study here.\n",
    "\n",
    "Additionally, we compare two sampling techniques: the standard permutation-based Monte Carlo sampling, and the so-called MSR (Maximum Sample Reuse) principle.\n",
    "\n",
    "In order to highlight the strengths of Data-Banzhaf, we require a stochastic model. For this reason, we use a CNN to classify handwritten digits from the [scikit-learn toy datasets](https://scikit-learn.org/stable/datasets/toy_dataset.html#optical-recognition-of-handwritten-digits-dataset)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "If you are reading this in the documentation, some boilerplate (including most plotting code) has been omitted for convenience.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "%load_ext autoreload"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.ioff()  # Prevent jupyter from automatically plotting\n",
    "plt.rcParams[\"figure.figsize\"] = (20, 6)\n",
    "plt.rcParams[\"font.size\"] = 12\n",
    "plt.rcParams[\"xtick.labelsize\"] = 10\n",
    "plt.rcParams[\"ytick.labelsize\"] = 10\n",
    "plt.rcParams[\"axes.facecolor\"] = (1, 1, 1, 0)\n",
    "plt.rcParams[\"figure.facecolor\"] = (1, 1, 1, 0)\n",
    "\n",
    "is_CI = os.environ.get(\"CI\")\n",
    "random_state = 24\n",
    "n_jobs = 16\n",
    "random.seed(random_state)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be using the following functions from pyDVL. The main entry point is the function `compute_banzhaf_semivalues()`.\n",
    "In order to use it we need the classes [Dataset](../../api/pydvl/utils/dataset/#pydvl.utils.dataset.Dataset), [Utility](../../api/pydvl/utils/utility/#pydvl.utils.utility.Utility) and [Scorer](../../api/pydvl/utils/score/#pydvl.utils.score.Scorer)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%autoreload\n",
    "from pydvl.reporting.plots import plot_shapley\n",
    "from support.banzhaf import load_digits_dataset\n",
    "from pydvl.value import *"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset\n",
    "\n",
    "We use a support function, `load_digits_dataset()`, which downloads the data and prepares it for usage. It returns four arrays that we then use to construct a [Dataset](../../api/pydvl/utils/dataset/#pydvl.utils.dataset.Dataset). The data consists of grayscale images of shape 8x8 pixels with 16 shades of gray. These images contain handwritten digits from 0 to 9."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "training_data, _, test_data = load_digits_dataset(\n",
    "    test_size=0.3, random_state=random_state\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide"
    ]
   },
   "source": [
    "# In CI we only use a subset of the training set\n",
    "training_data = list(training_data)\n",
    "if is_CI:\n",
    "    training_data[0] = training_data[0][:10]\n",
    "    training_data[1] = training_data[1][:10]\n",
    "    max_checks = 1\n",
    "else:\n",
    "    training_data[0] = training_data[0][:200]\n",
    "    training_data[1] = training_data[1][:200]\n",
    "    max_checks = 1000"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Visualize some of the data\n",
    "fig, axes = plt.subplots(2, 2, figsize=(4, 4))\n",
    "for i in range(4):\n",
    "    ax = axes[i % 2, i // 2]\n",
    "    ax.imshow(np.reshape(training_data[0][i], (8, 8)), cmap=\"gray\")\n",
    "    ax.set_xlabel(f\"Label: {training_data[1][i]}\")\n",
    "plt.suptitle(\"Example images from the dataset\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and test data are then used to instantiate a [Dataset](../../api/pydvl/utils/dataset/#pydvl.utils.dataset.Dataset) object:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "dataset = Dataset(*training_data, *test_data)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the utility and computing Banzhaf semivalues\n",
    "\n",
    "Now we can calculate the contribution of each training sample to the model performance. First we need a model and a [Scorer](../../api/pydvl/utils/score/#pydvl.utils.score.Scorer).\n",
    "\n",
    "As a model, we use a simple CNN written torch, and wrapped into an object to convert numpy arrays into tensors (as of v0.9.0 valuation methods in pyDVL work only with numpy arrays). Note that any model that implements the protocol [pydvl.utils.types.SupervisedModel](../../api/pydvl/utils/types/#pydvl.utils.types.SupervisedModel), which is just the standard sklearn interface of `fit()`,`predict()` and `score()` can be used to construct the utility."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import torch\n",
    "from support.banzhaf import TorchCNNModel\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TorchCNNModel(lr=0.001, epochs=40, batch_size=32, device=device)\n",
    "model.fit(x=training_data[0], y=training_data[1])\n",
    "\n",
    "print(f\"Train Accuracy: {model.score(x=training_data[0], y=training_data[1]):.3f}\")\n",
    "print(f\"Test Accuracy: {model.score(x=test_data[0], y=test_data[1]):.3f}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "The final component is the scoring function. It can be anything like accuracy or $R^2$, and is set with a string from the [standard sklearn scoring methods](https://scikit-learn.org/stable/modules/model_evaluation.html). Please refer to that documentation on information on how to define your own scoring function.\n",
    "\n",
    "We group dataset, model and scoring function into an instance of [Utility](../../api/pydvl/utils/utility/#pydvl.utils.utility.Utility) and compute the Banzhaf semi-values. We take all defaults, and choose to stop computation using the [MaxChecks](../../api/pydvl/value/stopping/#pydvl.value.stopping.MaxChecks) stopping criterion, which terminates after a fixed number of calls to it. With the default `batch_size` of 1 this means that we will retrain the model.\n",
    "\n",
    "Note how we enable caching using memcached (assuming memcached runs with the default configuration for localhost). This is necessary in the current preliminary implementation of [permutation sampling](../../api/pydvl/value/sampler/#pydvl.value.sampler.PermutationSampler), which is the default for [compute_banzhaf_semivalues](../../api/pydvl/value/semivalues#pydvl.value.semivalues.compute_banzhaf_semivalues)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from pydvl.utils import MemcachedCacheBackend, MemcachedClientConfig\n",
    "\n",
    "# Compute regular Banzhaf semivalue\n",
    "utility = Utility(\n",
    "    model=model,\n",
    "    data=dataset,\n",
    "    scorer=Scorer(\"accuracy\", default=0.0, range=(0, 1)),\n",
    "    cache_backend=MemcachedCacheBackend(MemcachedClientConfig())\n",
    ")\n",
    "values = compute_banzhaf_semivalues(\n",
    "    utility, done=MaxChecks(max_checks), n_jobs=n_jobs, progress=True\n",
    ")\n",
    "values.sort(key=\"value\")\n",
    "df = values.to_dataframe(column=\"banzhaf_value\", use_names=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": ".The returned dataframe contains the mean and variance of the Monte Carlo estimates for the values:"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us plot the results. In the next cell we will take the 30 images with the lowest score and plot their values with 95% Normal confidence intervals. Keep in mind that Permutation Monte Carlo Banzhaf is typically very noisy, and it can take many steps to arrive at a clean estimate."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "source": [
    "low_dvl = df.iloc[:30].copy()\n",
    "low_dvl.index = low_dvl.index.map(str)\n",
    "plot_shapley(\n",
    "    low_dvl,\n",
    "    level=0.05,\n",
    "    title=\"Images with low values\",\n",
    "    xlabel=\"Image\",\n",
    "    ylabel=\"Banzhaf value\",\n",
    "    prefix=\"banzhaf_value\"\n",
    ")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on anomalous data\n",
    "\n",
    "An interesting use-case for data valuation is finding anomalous data. Maybe some of the data is really noisy or has been mislabeled. To simulate this, we will change some of the labels of our dataset and add noise to some others. Intuitively, these anomalous data points should then have a lower value.\n",
    "\n",
    "To evaluate this, let us first check the average value of the first 10 data points, as these will be the ones that we modify. Currently, these are the 10 data points with the highest values:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "source": [
    "high_dvl = df.iloc[-10:].copy()\n",
    "print(f\"Average value of first 10 data points: {high_dvl['banzhaf_value'].mean()}\")\n",
    "print(f\"Exact values:\\n{high_dvl['banzhaf_value']}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first 5 images, we will falsify their label, for images 6-10, we will add some noise."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "x_train_anomalous = training_data[0].copy()\n",
    "y_train_anomalous = training_data[1].copy()\n",
    "anomalous_indices = high_dvl.index.map(int).values[:10]\n",
    "\n",
    "# Set label of first 5 images to 0\n",
    "y_train_anomalous[high_dvl.index.map(int).values[:5]] = 0\n",
    "\n",
    "# Add noise to images 6-10\n",
    "indices = high_dvl.index.values[5:10].astype(int)\n",
    "current_images = x_train_anomalous[indices]\n",
    "noisy_images = current_images + 0.5 * np.random.randn(*current_images.shape)\n",
    "noisy_images[noisy_images < 0] = 0.0\n",
    "noisy_images[noisy_images > 1] = 1.0\n",
    "x_train_anomalous[indices] = noisy_images\n",
    "\n",
    "fig, axes = plt.subplots(2, 5, figsize=(9, 5))\n",
    "for i in range(5):\n",
    "    axes[0, i].imshow(np.reshape(current_images[i], (8, 8)), cmap=\"gray\")\n",
    "    axes[1, i].imshow(np.reshape(noisy_images[i], (8, 8)), cmap=\"gray\")\n",
    "    axes[0, i].set_xlabel(f\"Original: {training_data[1][indices[i]]}\")\n",
    "    axes[1, i].set_xlabel(f\"Noisy: {training_data[1][indices[i]]}\")\n",
    "plt.suptitle(\"Original and noisy versions of images 6-10\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "anomalous_dataset = Dataset(\n",
    "    x_train=x_train_anomalous,\n",
    "    y_train=y_train_anomalous,\n",
    "    x_test=test_data[0],\n",
    "    y_test=test_data[1],\n",
    ")\n",
    "\n",
    "anomalous_utility = Utility(\n",
    "    model=TorchCNNModel(),\n",
    "    data=anomalous_dataset,\n",
    "    scorer=Scorer(\"accuracy\", default=0.0, range=(0, 1)),\n",
    "    cache_backend=MemcachedCacheBackend(MemcachedClientConfig())\n",
    ")\n",
    "anomalous_values = compute_banzhaf_semivalues(\n",
    "    anomalous_utility, done=MaxChecks(max_checks), n_jobs=n_jobs, progress=True\n",
    ")\n",
    "anomalous_values.sort(key=\"value\")\n",
    "anomalous_df = anomalous_values.to_dataframe(column=\"banzhaf_value\", use_names=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now take a look at the low-value images and check how many of our anomalous images are part of it."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "\n",
    "plot_data = anomalous_df.loc[anomalous_indices].copy()\n",
    "plot_data[\"original_banzhaf_value\"] = df.loc[anomalous_indices][\"banzhaf_value\"]\n",
    "plot_data[\"original_banzhaf_value_stderr\"] = df.loc[anomalous_indices][\"banzhaf_value_stderr\"]\n",
    "plot_data.index = plot_data.index.map(str)\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(8, 4))\n",
    "yerr = norm.ppf(1 - 0.05 / 2) * plot_data[\"banzhaf_value_stderr\"]\n",
    "original_yerr = norm.ppf(1 - 0.05 / 2) * plot_data[\"original_banzhaf_value_stderr\"]\n",
    "ax.errorbar(\n",
    "    x=plot_data.index,\n",
    "    y=plot_data[\"banzhaf_value\"],\n",
    "    yerr=yerr,\n",
    "    fmt=\"o\",\n",
    "    capsize=6,\n",
    "    color=\"red\",\n",
    "    label=\"Anomalous\",\n",
    ")\n",
    "ax.errorbar(\n",
    "    x=plot_data.index,\n",
    "    y=plot_data[\"original_banzhaf_value\"],\n",
    "    yerr=original_yerr,\n",
    "    fmt=\"o\",\n",
    "    capsize=6,\n",
    "    color=\"green\",\n",
    "    label=\"Original\",\n",
    ")\n",
    "ax.set_xlabel(\"Image\")\n",
    "ax.set_ylabel(\"Banzhaf Value\")\n",
    "ax.set_title(\"Data valuation scores of anomalous images\")\n",
    "plt.legend()\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen in this figure, the valuation of the data points has decreased significantly by adding noise or falsifying their labels. This shows the potential of using Banzhaf values or other data valuation methods to detect mislabeled data points or noisy input data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "print(\n",
    "    f\"Average value of original data points: {plot_data['original_banzhaf_value'].mean()}\"\n",
    ")\n",
    "print(\n",
    "    f\"Average value of modified, anomalous data points: {plot_data['banzhaf_value'].mean()}\"\n",
    ")\n",
    "print(\n",
    "    \"For reference, these are the average data values of all data points used for training (anomalous):\"\n",
    ")\n",
    "print(anomalous_df.mean())\n",
    "print(\"These are the average data values of all points (original data):\")\n",
    "print(df.mean())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Maximum Sample Reuse Banzhaf\n",
    "\n",
    "Despite the previous results already being useful, we had to retrain the model a number of times and yet the variance of the value estimates was high. This has consequences for the stability of the top-k ranking of points, which decreases the applicability of the method. We now introduce a different sampling method called Maximum Sample Reuse (MSR) which reuses every sample for updating the Banzhaf values. The method was introduced by the authors of Data-Banzhaf and is much more sample-efficient, as we will show.\n",
    "\n",
    "We next construct a new utility. Note how this time we don't use a cache: the chance of hitting twice the same subset of the training set is low enough that one can dispense with it (nevertheless it can still be useful, e.g. when running many experiments)."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "utility = Utility(\n",
    "    model=TorchCNNModel(),\n",
    "    data=dataset,\n",
    "    scorer=Scorer(\"accuracy\", default=0.0, range=(0, 1)),\n",
    "    cache_backend=MemcachedCacheBackend(MemcachedClientConfig())\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Computing the values is the same, but we now use a better stopping criterion. Instead of fixing the number of utility evaluations with [MaxChecks](../../api/pydvl/value/stopping/#pydvl.value.stopping.MaxChecks), we use [RankStability](../../api/pydvl/value/stopping/#pydvl.value.stopping.RankStability) to stop when the change in Spearman correlation between the ranking of two successive iterations is below a threshold. "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "values = compute_msr_banzhaf_semivalues(\n",
    "    utility,\n",
    "    done=RankStability(0.0001),\n",
    "    n_jobs=n_jobs,\n",
    "    progress=True,\n",
    ")\n",
    "values.sort(key=\"value\")\n",
    "msr_df = values.to_dataframe(column=\"banzhaf_value\", use_names=True)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Inspection of the values reveals (generally) much lower variances. Notice the number of updates to each value as well."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "msr_df.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "high_dvl = df.iloc[-30:]\n",
    "high_dvl.index = high_dvl.index.map(str)\n",
    "ax = plot_shapley(\n",
    "    high_dvl,\n",
    "    title=\"Images with high values\",\n",
    "    xlabel=\"Image\",\n",
    "    ylabel=\"Banzhaf Value\",\n",
    "    prefix=\"banzhaf_value\"\n",
    ")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "low_dvl = df.iloc[:30]\n",
    "low_dvl.index = low_dvl.index.map(str)\n",
    "ax = plot_shapley(\n",
    "    low_dvl,\n",
    "    title=\"Images with low values\",\n",
    "    xlabel=\"Image\",\n",
    "    ylabel=\"Banzhaf value\",\n",
    "    prefix=\"banzhaf_value\"\n",
    ")\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare convergence speed of Banzhaf and MSR Banzhaf Values\n",
    "\n",
    "Conventional margin-based samplers produce require evaluating the utility twice to do one update of the value, and permutation samplers do instead $n+1$ evaluations for $n$ updates. Maximum Sample Reuse (MSR) updates instead all indices in every sample that the utility evaluates. We compare the convergence rates of these methods.\n",
    "\n",
    "In order to do so, we will compute the semi-values using different samplers and use a high number of iterations to make sure that the values have converged."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "if is_CI:\n",
    "    max_checks = 1\n",
    "    moving_avg = 1\n",
    "else:\n",
    "    max_checks = 10000\n",
    "    moving_avg = 200"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "if is_CI:\n",
    "    utility = Utility(\n",
    "        model=SGDClassifier(max_iter=2),\n",
    "        data=dataset,\n",
    "        scorer=Scorer(\"accuracy\", default=0.0, range=(0, 1)),\n",
    "    )\n",
    "else:\n",
    "    utility = Utility(\n",
    "        model=TorchCNNModel(),\n",
    "        data=dataset,\n",
    "        scorer=Scorer(\"accuracy\", default=0.0, range=(0, 1)),\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def get_semivalues_and_history(\n",
    "    sampler_t, max_checks=max_checks, n_jobs=n_jobs, progress=True\n",
    "):\n",
    "    _history = HistoryDeviation(n_steps=max_checks, rtol=1e-9)\n",
    "    _values = compute_msr_banzhaf_semivalues(\n",
    "        utility,\n",
    "        sampler_t=sampler_t,\n",
    "        done=MaxChecks(max_checks + 2) | _history,\n",
    "        n_jobs=n_jobs,\n",
    "        progress=progress,\n",
    "    )\n",
    "    return _history, _values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Monte Carlo Permutation Sampling Banzhaf semivalues\n",
    "history_permutation, permutation_values = get_semivalues_and_history(PermutationSampler)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# MSR Banzhaf values\n",
    "history_msr, msr_values = get_semivalues_and_history(MSRSampler)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# UniformSampler\n",
    "history_uniform, uniform_values = get_semivalues_and_history(UniformSampler)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# AntitheticSampler\n",
    "history_antithetic, antithetic_values = get_semivalues_and_history(AntitheticSampler)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# RandomHierarchicalSampler\n",
    "history_random, random_values = get_semivalues_and_history(RandomHierarchicalSampler)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Compare convergence speed of both methods\n",
    "names = [\"Permutation\", \"MSR\", \"Uniform\", \"Antithetic\", \"RandomHierarchical\"]\n",
    "all_values = [\n",
    "    history_permutation._memory,\n",
    "    history_msr._memory,\n",
    "    history_uniform._memory,\n",
    "    history_antithetic._memory,\n",
    "    history_random._memory,\n",
    "]\n",
    "distances = [[] for _ in names]\n",
    "moving_avgs = []\n",
    "\n",
    "for sampler_id, name in enumerate(names):\n",
    "    for iteration in range(max_checks):\n",
    "        abs_dist = np.abs(\n",
    "            all_values[sampler_id][:, iteration]\n",
    "            - all_values[sampler_id][:, iteration + 1]\n",
    "        )\n",
    "        if abs_dist.max() == 0.0:\n",
    "            distances[sampler_id].append(0.0)\n",
    "        else:\n",
    "            distances[sampler_id].append(np.mean(abs_dist[abs_dist > 0]))\n",
    "    moving_avgs.append(\n",
    "        np.convolve(\n",
    "            distances[sampler_id], np.ones(moving_avg) / moving_avg, mode=\"same\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(10, 5))\n",
    "for sampler_id, name in enumerate(names):\n",
    "    ax.plot(list(range(max_checks)), moving_avgs[sampler_id], label=name)\n",
    "ax.set_xlabel(\"Iteration\")\n",
    "ax.set_ylabel(\"Mean semivalue change between iterations\")\n",
    "ax.set_title(\"Convergence speed of different samplers\")\n",
    "plt.yscale(\"log\")\n",
    "plt.ylim(1e-5, 1)\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above visualizes the convergence speed of different samplers used for Banzhaf semivalue calculation. /It shows the average magnitude of how much the semivalues are updated in every step of the algorithm. \n",
    "\n",
    "As you can see, **MSR Banzhaf** stabilizes much faster. After 1000 iterations (subsets sampled and evaluated with the utility), Permutation Monte Carlo Banzhaf has evaluated the marginal function about 5 times per data point (we are using 200 data points). For MSR, the semivalue of each data point was updated 1000 times. Due to this, the values converge much faster wrt. the number of utility evaluations, which is the key advantage of MSR sampling. \n",
    "\n",
    "MSR sampling does come at a cost, however, which is that the updates to the semivalues are more noisy than in other methods.  We will analyze the impact of this tradeoff in the next sections. First, let us look at how similar all the computed semivalues are. They are all Banzhaf values, so in a perfect world, all samplers should result in the exact same semivalues. However, due to randomness in the utility (recall that we use a neural network) and randomness in the samplers, the resulting values are likely never exactly the same. Another quality measure is that a good sampler would lead to very consistent values, a bad one to less consistent values. Let us first examine how similar the results are, then we'll look at consistency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity of the semivalues computed using different samplers"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "names = [\"Permutation\", \"MSR\", \"Uniform\", \"Antithetic\", \"RandomHierarchical\"]\n",
    "values = [\n",
    "    permutation_values,\n",
    "    msr_values,\n",
    "    uniform_values,\n",
    "    antithetic_values,\n",
    "    random_values,\n",
    "]\n",
    "top_consistency = np.zeros((len(names), len(names)))\n",
    "low_consistency = np.zeros((len(names), len(names)))\n",
    "twenty_percent = training_data[0].shape[0] // 5\n",
    "\n",
    "for sampler1_id, sampler1_values in enumerate(values):\n",
    "    for sampler2_id, sampler2_values in enumerate(values):\n",
    "        sampler1_values.sort(key=\"value\")\n",
    "        sampler2_values.sort(key=\"value\")\n",
    "        top_20_1 = set(sampler1_values.indices[-twenty_percent:].tolist())\n",
    "        lower_20_1 = set(sampler1_values.indices[:twenty_percent].tolist())\n",
    "        top_20_2 = set(sampler2_values.indices[-twenty_percent:].tolist())\n",
    "        lower_20_2 = set(sampler2_values.indices[:twenty_percent].tolist())\n",
    "        top_consistency[sampler1_id, sampler2_id] = len(top_20_1.intersection(top_20_2))\n",
    "        low_consistency[sampler1_id, sampler2_id] = len(\n",
    "            lower_20_1.intersection(lower_20_2)\n",
    "        )"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fix, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "axes[0].matshow(top_consistency, vmin=0, vmax=twenty_percent)\n",
    "mat2 = axes[1].matshow(low_consistency, vmin=0, vmax=twenty_percent)\n",
    "axes[0].set_xticks(np.arange(len(names)), names, rotation=90)\n",
    "axes[1].set_xticks(np.arange(len(names)), names, rotation=90)\n",
    "for (i, j), z in np.ndenumerate(top_consistency):\n",
    "    axes[0].text(j, i, f\"{int(z)}\", ha=\"center\", va=\"center\", c=\"white\")\n",
    "for (i, j), z in np.ndenumerate(low_consistency):\n",
    "    axes[1].text(j, i, f\"{int(z)}\", ha=\"center\", va=\"center\", c=\"white\")\n",
    "\n",
    "axes[0].set_yticks(np.arange(len(names)), names)\n",
    "axes[1].set_yticks(np.arange(len(names)), names)\n",
    "axes[0].set_title(\"Top 20% of points\")\n",
    "axes[1].set_title(\"Low 20% of points\")\n",
    "fig.colorbar(mat2)\n",
    "plt.suptitle(\"Overlapping high and low value points between samplers\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows that the samplers lead to quite different Banzhaf semivalues, however, all of them have some points in common.  \n",
    "The MSR Sampler does not seem to be significantly worse than any others. \n",
    "\n",
    "In an ideal setting without randomness, the overlap of points would be higher, however, the stochastic nature of the CNN model that we use together with the\n",
    "fact that we use only 200 data points for training, might overshadow these results.  "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "all_in_common = set(permutation_values.indices.tolist())\n",
    "for sampler_id, sampler_values in enumerate(values):\n",
    "    sampler_values.sort(key=\"value\")\n",
    "    top_20 = set(sampler_values.indices[-twenty_percent:].tolist())\n",
    "    all_in_common = all_in_common.intersection(top_20)\n",
    "print(\n",
    "    f\"Total number of top 20 points that all samplers have in common: {len(all_in_common)}\"\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Consistency of the semivalues\n",
    "\n",
    "In this part, we want to analyze how consistent the semivalues returned by the different samplers are.  \n",
    "To evaluate this, we will compute semivalues multiple times and check how many of the data points in the top and lowest 20% of valuation of the data overlap."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "max_checks = [1000, 2000, 3000] if not is_CI else [1]\n",
    "num_retries = 3 if not is_CI else 1\n",
    "num_samplers = 5\n",
    "twenty_percent = training_data[0].shape[0] // 5"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Run all experiments\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "results = [[[] for i in range(num_samplers)] for _ in max_checks]\n",
    "pbar = tqdm(total=len(max_checks) * num_retries * 5)\n",
    "for sampler_index, sampler in enumerate(\n",
    "    [\n",
    "        PermutationSampler,\n",
    "        MSRSampler,\n",
    "        UniformSampler,\n",
    "        AntitheticSampler,\n",
    "        RandomHierarchicalSampler,\n",
    "    ]\n",
    "):\n",
    "    for check_index, max_check in enumerate(max_checks):\n",
    "        for retry in range(num_retries):\n",
    "            _, vals = get_semivalues_and_history(\n",
    "                sampler, max_checks=max_check, progress=False\n",
    "            )\n",
    "            results[check_index][sampler_index].append(vals)\n",
    "            pbar.n = (\n",
    "                sampler_index * (len(max_checks) * num_retries)\n",
    "                + check_index * num_retries\n",
    "                + retry\n",
    "                + 1\n",
    "            )\n",
    "            pbar.refresh()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Extract results from experiments\n",
    "\n",
    "plot_results_top = [[] for _ in range(num_samplers)]\n",
    "plot_results_low = [[] for _ in range(num_samplers)]\n",
    "for check_index, _ in enumerate(max_checks):\n",
    "    for sampler_index, sampler in enumerate(\n",
    "        [\n",
    "            PermutationSampler,\n",
    "            MSRSampler,\n",
    "            UniformSampler,\n",
    "            AntitheticSampler,\n",
    "            RandomHierarchicalSampler,\n",
    "        ]\n",
    "    ):\n",
    "        value_list = results[check_index][sampler_index]\n",
    "        top_20 = None\n",
    "        lower_20 = None\n",
    "        for vals in value_list:\n",
    "            vals.sort(key=\"value\")\n",
    "            if top_20 is None:\n",
    "                top_20 = set(vals.indices[-twenty_percent:].tolist())\n",
    "                lower_20 = set(vals.indices[:twenty_percent].tolist())\n",
    "            else:\n",
    "                top_20 = top_20.intersection(\n",
    "                    set(vals.indices[-twenty_percent:].tolist())\n",
    "                )\n",
    "                lower_20 = lower_20.intersection(\n",
    "                    set(vals.indices[:twenty_percent].tolist())\n",
    "                )\n",
    "        plot_results_top[sampler_index].append(len(top_20))\n",
    "        plot_results_low[sampler_index].append(len(lower_20))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Plot results\n",
    "\n",
    "fig, axes = plt.subplots(2, 1, figsize=(8, 8))\n",
    "for sampler_index, name in enumerate(names):\n",
    "    axes[0].plot(max_checks, plot_results_top[sampler_index], label=name)\n",
    "    axes[1].plot(max_checks, plot_results_low[sampler_index], label=name)\n",
    "axes[0].legend()\n",
    "axes[1].legend()\n",
    "axes[0].set_xlabel(\"Number of iterations\")\n",
    "axes[1].set_xlabel(\"Number of iterations\")\n",
    "axes[0].set_ylabel(f\"Number of common points \\nin top 20% in {num_retries} runs\")\n",
    "axes[1].set_ylabel(f\"Number of common points \\nin lower 20% in {num_retries} runs\")\n",
    "fig.suptitle(f\"Evaluation of consistency of samplers (Max value: {twenty_percent})\")\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Conclusion:**\n",
    "MSR sampling updates the semivalue estimates a lot more frequently than any other sampler available, which leads to a lot **faster convergence**.  \n",
    "Additionally, the sampler is more consistent with its value estimates than the other samplers, which might be caused by the higher number of value updates.  \n",
    "\n",
    "In general, the recommendation is to try different samplers when computing semivalues and test, which one is best suited for your use case. The MSR sampler\n",
    "seems like a more efficient sampler which may bring fast results and is well-suited for stochastic models."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e000971326892723e7f31ded70802f690c31c3620f59a0f99e594aaee3047ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

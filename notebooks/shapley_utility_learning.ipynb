{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Utility Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces **Data Utility Learning**, a method of approximating Data Shapley values by learning to estimate the utility function.\n",
    "\n",
    "The idea is to employ a model to learn the performance of the learning algorithm of interest on unseen data combinations (i.e. subsets of the dataset). The method was originally described in *Wang, Tianhao, Yu Yang, and Ruoxi Jia. [Improving Cooperative Game Theory-Based Data Valuation via Data Utility Learning](https://doi.org/10.48550/arXiv.2107.06336). arXiv, 2022*.\n",
    "\n",
    "<div class=\"alert alert-warning\">\n",
    "    <p><b>Warning:</b> Work on Data Utility Learning is preliminary. It remains to be seen when or whether it can be put effectively into application. For this further testing and benchmarking are required.</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall the definition of Shapley value $v_u(i)$ for data point $i$:\n",
    "\n",
    "\\begin{equation}\n",
    "v_u(i) = \\frac{1}{n} \\sum_{S \\subseteq N \\setminus \\{i\\}} \\binom{n-1}{|S|}^{-1} [u(S \\cup \\{i\\}) âˆ’ u(S)] ,\n",
    "\\tag{1}\n",
    "\\label{eq:shapley-def}\n",
    "\\end{equation}\n",
    "\n",
    "where $N$ is the set of all indices in the training set and $u$ is the utility.\n",
    "\n",
    "In Data Utility Learning, to avoid the exponential cost of computing this sum, one learns a surrogate model for $u$. We start by sampling so-called **utility samples** to form a training set $S_\\mathrm{train}$ for our utility model. Each utility sample is a tuple consisting of a subset of indices $S_j$ in the dataset and its utility $u(S_j)$:\n",
    "\n",
    "$$\\mathcal{S}_\\mathrm{train} = \\{(S_j, u(S_j): j = 1 , ..., m_\\mathrm{train}\\}$$\n",
    "\n",
    "where $m_\\mathrm{train}$ denotes the *training budget* for the learned utility function.\n",
    "\n",
    "The subsets are then transformed into boolean vectors $\\phi$ in which a $1$ at index $k$ means that the $k$-th sample of the dataset is present in the subset:\n",
    "\n",
    "$$S_j \\mapsto \\phi_j \\in \\{ 0, 1 \\}^{N}$$\n",
    "\n",
    "We fit a regression model $\\tilde{u}$, called **data utility model**, on the transformed utility samples $\\phi (\\mathcal{S}_\\mathrm{train}) := \\{(\\phi(S_j), u(S_j): j = 1 , ..., m_\\mathrm{train}\\}$ and use it to predict instead of computing the utility for any $S_j \\notin \\mathcal{S}_\\mathrm{train}$. We abuse notation and identify $\\tilde{u}$ with the composition $\\tilde{u} \\circ \\phi : N \\rightarrow \\mathbb{R}$.\n",
    "\n",
    "The main assumption is that it is much faster to fit and use $\\tilde{u}$ than it is to compute $u$ and that for most $i$, $v_\\tilde{u}(i) \\approx v_u(i)$ in some sense."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing the main libraries and setting some defaults.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "If you are reading this in the documentation, some boilerplate (including most plotting code) has been omitted for convenience.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide"
    ]
   },
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from pydvl.reporting.plots import shaded_mean_std\n",
    "\n",
    "plt.ioff()  # Prevent jupyter from automatically plotting\n",
    "plt.rcParams[\"figure.figsize\"] = (16, 10)\n",
    "plt.rcParams[\"font.size\"] = 15\n",
    "plt.rcParams[\"xtick.labelsize\"] = 15\n",
    "plt.rcParams[\"ytick.labelsize\"] = 15\n",
    "plt.rcParams[\"axes.facecolor\"] = (1, 1, 1, 0)\n",
    "plt.rcParams[\"figure.facecolor\"] = (1, 1, 1, 0)\n",
    "\n",
    "random_state = 42\n",
    "\n",
    "train_size = 15\n",
    "batch_size = 32\n",
    "training_budget_values = np.ceil(np.logspace(2, np.log10(4000), num=8, base=10)).astype(\n",
    "    int\n",
    ")\n",
    "n_runs = 10\n",
    "n_jobs = 16\n",
    "\n",
    "is_CI = os.environ.get(\"CI\")\n",
    "\n",
    "if is_CI:\n",
    "    train_size = 4\n",
    "    batch_size = 1\n",
    "    training_budget_values = [2, 4, 6]\n",
    "    n_runs = 1\n",
    "    n_jobs = 1\n",
    "\n",
    "random.seed(random_state)\n",
    "np.random.seed(random_state)\n",
    "\n",
    "# raised by joblib after cancelling running tasks\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "computation_times = defaultdict(list)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data utility learning can be applied to any valuation method that uses a Utility, in particular any [SemivalueValuation][pydvl.valuation.methods.semivalue.SemivalueValuation]. For this example we will use Shapley values with the subclass [ShapleyValuation][pydvl.valuation.methods.shapley.ShapleyValuation]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "Closely following the paper, we take `train_size=15` samples (10%) from the [Iris dataset](https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html) and compute their Data Shapley values by using all the remaining samples as test set for computing the utility, which in this case is accuracy."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "from pydvl.valuation.dataset import Dataset\n",
    "\n",
    "train, test = Dataset.from_sklearn(\n",
    "    load_iris(),\n",
    "    train_size=train_size,\n",
    "    random_state=random_state,\n",
    "    stratify_by_target=True,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We verify that, as in the paper, if we fit a Support-Vector Classifier to the training data, we obtain a high accuracy. In our case around 94%:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "model = LinearSVC()\n",
    "model.fit(*train.data());"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "print(f\"Mean accuracy: {100 * model.score(*test.data()):0.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Shapley\n",
    "\n",
    "We start by defining the utility using the main model of interest and computing the exact Data Shapley values by definition $\\ref{eq:shapley-def}$.\n",
    "\n",
    "We require a scoring function (accuracy), and a sampler. In order to compute exact values we must use either [DeterministicUniformSampler][pydvl.valuation.samplers.powerset.DeterministicUniformSampler] which yields all possible subsets of the data or [DeterministicPermutationSampler][pydvl.valuation.samplers.permutation.DeterministicPermutationSampler] which yields all possible permutations of the data, but the latter is prohibitively expensive.\n",
    "\n",
    "Finally, we must pick a stopping criterion. Since the sampler is finite, we could use [NoStopping][pydvl.valuation.stopping.NoStopping] to run until completion, but we use [MinUpdates(1)][pydvl.valuation.stopping.MinUpdates] since it allows for progress display (completion being the number of indices having been updates at least once)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "from pydvl.valuation import (\n",
    "    DeterministicUniformSampler,\n",
    "    MinUpdates,\n",
    "    ModelUtility,\n",
    "    ShapleyValuation,\n",
    "    SupervisedScorer,\n",
    ")\n",
    "\n",
    "scorer = SupervisedScorer(\"accuracy\", test_data=test, default=0, range=(0, 1))\n",
    "utility = ModelUtility(model=model, scorer=scorer, show_warnings=False)\n",
    "sampler = DeterministicUniformSampler(batch_size=32)\n",
    "# A DeterministicUniformSampler updates each index exactly once.\n",
    "# This stopping criterion is therefore only here to keep track of progress:\n",
    "stopping = MinUpdates(1)\n",
    "\n",
    "valuation = ShapleyValuation(\n",
    "    utility=utility, sampler=sampler, is_done=stopping, progress=True\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With everything set up, we fit the valuation in parallel and obtain the exact Data Shapley values:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from joblib import parallel_config\n",
    "\n",
    "from pydvl.utils.functional import timed\n",
    "\n",
    "timed_fit = timed()(valuation.fit)  # A decorator to time the fitting process\n",
    "with parallel_config(n_jobs=n_jobs):\n",
    "    timed_fit(train)\n",
    "computation_times[\"exact\"] = timed_fit.execution_time\n",
    "\n",
    "result = valuation.values()\n",
    "df = result.to_dataframe(column=\"exact\")[\"exact\"]  # We only need the values"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now estimate the Data Shapley values with [DataUtilityLearning][pydvl.valuation.utility.learning.DataUtilityLearning]. This class learns a model of the `Utility` by wrapping it and delegating calls to it, up until a given budget. Every call yields a _utility sample_ which is saved under the hood for training of the given utility model. Once the budget is exhausted, `DataUtilityLearning` fits the model to the utility samples and all subsequent calls use the learned model to predict the wrapped utility. Because each evaluation of the original utility is assumed to take a long time, this results in a speedup.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Note how we use a Monte Carlo approximation instead of sampling all subsets as above. This is not only for speed reasons, but because [DeterministicUniformSampler][pydvl.valuation.samplers.powerset.DeterministicUniformSampler] yields subsets in a fixed order, from the lowest size to the largest. Because the training budget for the model to learn the utility is around 1/4th of the total number of subsets, this would mean that we would never see utility samples for the larger sizes and the model would be biased (try it!)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the parameters for the model used to learn the utility. We follow the paper and use a fully connected neural network whose inputs are indicator vectors of the sets. For a set $S = \\{i_1, ..., i_m\\}$, the encoding is a binary vector $x$ such that $x_i = 1$ if $i \\in S$ or $0$ otherwise. The process of encoding the data and fitting the neural network is encapsulated inside a [IndicatorUtilityModel][pydvl.valuation.utility.learning.IndicatorUtilityModel]. Other choices inherit from the ABC [UtilityModel][pydvl.valuation.utility.learning.UtilityModel]."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "mlp_params = dict(\n",
    "    hidden_layer_sizes=(20, 10),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    learning_rate_init=0.001,\n",
    "    batch_size=batch_size,\n",
    "    max_iter=800,\n",
    "    shuffle=False,\n",
    "    random_state=random_state\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "deepset_params = dict(\n",
    "    data=train,\n",
    "    phi_hidden_dim=20,\n",
    "    phi_output_dim=10,\n",
    "    rho_hidden_dim=20,\n",
    "    lr=0.001,\n",
    "    lr_step_size=40,\n",
    "    lr_gamma=0.8,\n",
    "    batch_size=64,\n",
    "    num_epochs=800,\n",
    "    device=\"cuda\",\n",
    "    progress={\"position\": 0}\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the training we use an increasing number of `training_budget` utility samples, spaced on a log scale from 100 to 4000. We repeat each training procedure 10 times in order to compute confidence intervals.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "source": [
    "from pydvl.valuation.samplers import PermutationSampler, RelativeTruncation\n",
    "from pydvl.valuation.stopping import HistoryDeviation, MaxUpdates\n",
    "from pydvl.valuation.utility import DataUtilityLearning\n",
    "from pydvl.utils.functional import timed\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from pydvl.valuation.utility.learning import IndicatorUtilityModel\n",
    "from pydvl.valuation.utility.deepset import DeepSetUtilityModel\n",
    "\n",
    "pbar = tqdm(\n",
    "    product(range(n_runs), training_budget_values),\n",
    "    total=n_runs * len(training_budget_values),\n",
    "    position=0,\n",
    ")\n",
    "for idx, budget in pbar:\n",
    "    pbar.set_postfix_str(f\"Run {idx+1} for training budget: {budget}\")\n",
    "    utility_model = IndicatorUtilityModel(MLPRegressor(**mlp_params), n_data=len(train))\n",
    "    # utility_model = DeepSetUtilityModel(**depset_params)\n",
    "    # utility_model.predictor.reset_parameters()\n",
    "    dul_utility = DataUtilityLearning(\n",
    "        utility=utility, training_budget=budget, model=utility_model\n",
    "    )\n",
    "\n",
    "    sampler = PermutationSampler(truncation=RelativeTruncation(rtol=0.05))\n",
    "\n",
    "    stopping = HistoryDeviation(n_steps=100, rtol=0.01) | MaxUpdates(400)\n",
    "    # DUL will kick in after training_budget calls to utility\n",
    "    valuation = ShapleyValuation(dul_utility, sampler, is_done=stopping, progress=False)\n",
    "\n",
    "    # Note that DUL does not support parallel fitting (yet?)\n",
    "    timed_fit = timed()(valuation.fit)\n",
    "    timed_fit(train)\n",
    "    computation_times[budget].append(timed_fit.execution_time)\n",
    "\n",
    "    result = valuation.values()\n",
    "    dul_df = result.to_dataframe(column=f\"{budget}_{idx}\")[f\"{budget}_{idx}\"]\n",
    "    df = pd.concat([df, dul_df], axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice how we have changed the stopping criterion to be a combination of [HistoryDeviation][pydvl.valuation.stopping.HistoryDeviation] and [MaxUpdates][pydvl.valuation.stopping.MaxUpdates]. The former stops the valuation when the relative deviation of the values is below a certain threshold for a given number of steps, and the latter stops the valuation after a given number of updates (to ensure that the valuation does not run indefinitely). `HistoryDeviation` is the criterion used in the paper introducing Truncated Monte Carlo Shapley.\n",
    "Next we compute the $l_2$ error for the different training budgets across all runs and plot mean and standard deviation. We obtain results analogous to Figure 1 of the paper, verifying that the method indeed works for estimating the Data Shapley values (at least in this context).\n",
    "\n",
    "In the plot we also display the mean and standard deviation of the computation time taken for each training budget."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "max_len = max(len(v) for v in computation_times.values() if isinstance(v, list))\n",
    "for k,v in computation_times.items():\n",
    "    computation_times[k] = v + [v[-1]] if isinstance(v, list) and len(v) < max_len else v"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide"
    ]
   },
   "source": [
    "from pydvl.utils import top_k_value_accuracy\n",
    "\n",
    "computation_times_df = pd.DataFrame(computation_times)\n",
    "errors = np.zeros((len(training_budget_values), n_runs), dtype=float)\n",
    "accuracies = np.zeros((len(training_budget_values), n_runs), dtype=float)\n",
    "\n",
    "top_k = 3\n",
    "\n",
    "for i, budget in enumerate(training_budget_values):\n",
    "    for j in range(n_runs):\n",
    "        y_true = df[\"exact\"].values\n",
    "        y_estimated = df[f\"{budget}_{j}\"].values\n",
    "        errors[i, j] = np.linalg.norm(y_true - y_estimated, ord=2)\n",
    "        accuracies[i, j] = top_k_value_accuracy(y_true, y_estimated, k=top_k)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "source": [
    "fig, ax = plt.subplots()\n",
    "shaded_mean_std(\n",
    "    errors.transpose(),\n",
    "    abscissa=training_budget_values,\n",
    "    num_std=1,\n",
    "    xlabel=\"$m_\\\\operatorname{train}$\",\n",
    "    ylabel=\"$l_2$ Error\",\n",
    "    label=\"Estimated values\",\n",
    "    mean_color=\"dodgerblue\",\n",
    "    shade_color=\"lightblue\",\n",
    "    ax=ax,\n",
    ")\n",
    "ax.set_ylabel(\"$l_2$ Error\", color=\"dodgerblue\")\n",
    "ax.tick_params(axis=\"y\", labelcolor=\"dodgerblue\")\n",
    "\n",
    "ax2 = ax.twinx()\n",
    "shaded_mean_std(\n",
    "    computation_times_df.drop(columns=\"exact\"),\n",
    "    abscissa=training_budget_values,\n",
    "    num_std=1,\n",
    "    xlabel=\"$m_\\\\operatorname{train}$\",\n",
    "    ylabel=\"Time\",\n",
    "    label=\"Estimated values\",\n",
    "    mean_color=\"indianred\",\n",
    "    shade_color=\"firebrick\",\n",
    "    ax=ax2,\n",
    ")\n",
    "ax2.set_ylabel(\"Computation Time\", color=\"indianred\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=\"indianred\")\n",
    "ax.set_title(\"$l_2$ Error and computation time with respect to $m_{train}$\")\n",
    "fig.tight_layout()\n",
    "plt.show();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us next look at how well the ranking of values resulting from using the surrogate $\\tilde{u}$ matches the ranking by the exact values. For this we fix $k=3$ and consider the $k$ samples with the highest value according to $\\tilde{u}$ and $u$:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "source": [
    "shaded_mean_std(\n",
    "    accuracies.transpose(),\n",
    "    abscissa=training_budget_values,\n",
    "    mean_color=\"dodgerblue\",\n",
    "    shade_color=\"lightblue\",\n",
    "    xlabel=\"$m_\\\\operatorname{train}$\",\n",
    "    ylabel=f\"Average Top-{top_k} Accuracy\",\n",
    ")\n",
    "plt.show();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, for each sample, we look at the distance of the estimates to the exact value across runs. Boxes are centered at the 50th percentile with wiskers at the 25th and 75th. We plot relative distances, as a percentage."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "source": [
    "warnings.simplefilter(\"ignore\", RuntimeWarning)  # numpy complains about stuff\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18, 12))\n",
    "distances = 100 * df.loc[:, df.columns != \"exact\"].sub(df.exact, axis=\"index\").div(\n",
    "    df.exact, axis=\"index\"\n",
    ")\n",
    "distances.transpose().boxplot(column=distances.index.values.tolist(), ax=ax)\n",
    "ax.hlines(0.0, 0, distances.index.max() + 2, \"indianred\")\n",
    "ax.set_xlim((0, distances.index.max() + 2))\n",
    "# Display 96% of the data:\n",
    "ax.set_ylim(\n",
    "    (\n",
    "        distances.transpose().quantile(0.02).min(),\n",
    "        distances.transpose().quantile(0.98).max(),\n",
    "    )\n",
    ")\n",
    "\n",
    "ax.set_xlabel(\"Index\")\n",
    "ax.set_ylabel(\"% deviation from the exact value\")\n",
    "ax.set_title(\"Relative deviation of estimated from exact values across runs\")\n",
    "ax.grid(False)\n",
    "plt.show();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "bins = 20\n",
    "\n",
    "# Compute a global range for all histograms.\n",
    "global_min = df.min().min()\n",
    "global_max = df.max().max()\n",
    "\n",
    "# Use fixed bin edges for consistency.\n",
    "bin_edges = np.linspace(global_min, global_max, bins + 1)\n",
    "bin_centers = (bin_edges[:-1] + bin_edges[1:]) / 2\n",
    "\n",
    "# Compute the global maximum density to use the same y-axis across plots.\n",
    "global_max_density = 0\n",
    "for col in df.columns:\n",
    "    data = df[col].dropna()\n",
    "    hist, _ = np.histogram(data, bins=bin_edges, density=True)\n",
    "    global_max_density = max(global_max_density, hist.max())\n",
    "\n",
    "# Compute density for the first column (used as the reference overlay).\n",
    "data_first = df.iloc[:, 0].dropna()\n",
    "hist_first, _ = np.histogram(data_first, bins=bin_edges, density=True)\n",
    "\n",
    "fig, axes = plt.subplots(9, 9, figsize=(18, 18))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, ax in enumerate(axes):\n",
    "    data = df.iloc[:, i].dropna()\n",
    "    ax.hist(data, bins=bin_edges, density=True, color='lightblue', alpha=0.7)\n",
    "    \n",
    "    # Overlay the first column's density curve on all plots except the first one.\n",
    "    if i != 0:\n",
    "        ax.plot(bin_centers, hist_first, color='lightgray', linestyle='--', linewidth=2)\n",
    "    \n",
    "    ax.set_ylim(0, global_max_density * 0.6)\n",
    "\n",
    "    if i > 0:\n",
    "        budget, run = df.columns[i].split(\"_\")\n",
    "        title = f\"Run {run}, budget {budget}\"\n",
    "    else:\n",
    "        title = \"Exact values\"\n",
    "        \n",
    "    ax.set_title(title, fontsize=9)\n",
    "\n",
    "    ax.tick_params(axis='both', labelsize=6)\n",
    "    \n",
    "    if i % 9 != 0:\n",
    "        ax.set_yticklabels([])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation on anomalous data\n",
    "\n",
    "One interesting way to assess the Data Utility Learning approach is to corrupt some data and monitor how the value changes. To do this, we will take the sample with the highest score and change its label."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "highest_value_index = df.index[df[\"exact\"].argmax()]\n",
    "y_corrupted = train.data().y.copy()\n",
    "y_corrupted[highest_value_index] = (y_corrupted[highest_value_index] + 1) % 3\n",
    "\n",
    "corrupted_dataset = Dataset(\n",
    "    train.data().x.copy(),\n",
    "    y_corrupted,\n",
    "    feature_names=train.feature_names,\n",
    "    target_names=train.target_names,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "print(f\"The corrupted sample has index {highest_value_index}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We retrain the model on the new dataset and verify that the accuracy decreases:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "model = LinearSVC()\n",
    "model.fit(*corrupted_dataset.data());"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "print(f\"Mean accuracy over test set, with corrupted training data: {100 * model.score(*test.data()):0.2f}%\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Finally, we recompute the values of all samples using the exact method and the best training budget previously obtained and then plot the resulting scores."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "source": [
    "sampler = DeterministicUniformSampler(batch_size=32)\n",
    "stopping = MinUpdates(1)\n",
    "valuation = ShapleyValuation(\n",
    "    utility=utility, sampler=sampler, is_done=stopping, progress=True\n",
    ")\n",
    "\n",
    "with parallel_config(n_jobs=n_jobs):\n",
    "    valuation.fit(corrupted_dataset)\n",
    "result = valuation.values()\n",
    "\n",
    "df_corrupted = result.to_dataframe(column=\"exact\")[\"exact\"]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input"
    ]
   },
   "source": [
    "best_budget = training_budget_values[errors.mean(axis=1).argmin()]\n",
    "print(f\"Best training budget was: {best_budget}\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-output"
    ]
   },
   "source": [
    "scorer = SupervisedScorer(\"accuracy\", test_data=test, default=0, range=(0, 1))\n",
    "utility = ModelUtility(model=model, scorer=scorer, show_warnings=False)\n",
    "utility_model = DeepSetUtilityModel(\n",
    "    data=train,\n",
    "    phi_hidden_dim=16,\n",
    "    phi_output_dim=8,\n",
    "    rho_hidden_dim=8,\n",
    "    lr=0.001,\n",
    "    batch_size=128,\n",
    "    num_epochs=30,\n",
    "    device=\"cuda\",\n",
    "    progress={\"position\": 0})\n",
    "dul_utility = DataUtilityLearning(\n",
    "    utility=utility, training_budget=best_budget, model=utility_model\n",
    ")\n",
    "\n",
    "valuation = ShapleyValuation(\n",
    "    utility=dul_utility,\n",
    "    sampler=PermutationSampler(),\n",
    "    is_done=MaxUpdates(400),\n",
    "    progress=True\n",
    ")\n",
    "valuation.fit(train)\n",
    "result = valuation.values()\n",
    "\n",
    "dul_df = result.to_dataframe(column=\"estimated\")[\"estimated\"]\n",
    "df_corrupted = pd.concat([df_corrupted, dul_df], axis=1)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "len(dul_utility._utility_samples), sampler.n_samples"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "We can see in the figure that both methods assign the lowest value to the sample with the corrupted label."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "source": [
    "fig, ax = plt.subplots()\n",
    "df_corrupted.sort_values(by=\"exact\", ascending=False, axis=0).plot(\n",
    "    y=[\"exact\", \"estimated\"], kind=\"bar\", ax=ax, color=[\"dodgerblue\", \"indianred\"]\n",
    ")\n",
    "ax.set_xlabel(\"Index\")\n",
    "ax.set_ylabel(\"Data Shapley value\")\n",
    "plt.legend([\"Exact\", \"Estimated\"])\n",
    "plt.show();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "As mentioned above, despite the previous results, this work is preliminary and the usefulness of Data Utility Learning remains to be tested in practice.\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

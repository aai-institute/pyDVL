{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bagging for data valuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook introduces the Data-OOB method, from Kwon and Zou \"[Data-OOB: Out-of-bag Estimate as a Simple and Efficient Data Value](https://proceedings.mlr.press/v202/kwon23e.html)\" (ICML 2023), using pyDVL.\n",
    "\n",
    "The objective of this paper is mainly to overcome the computational bottleneck of Shapley-based data valuation methods that require fitting a significant number of models to accurately estimate marginal contributions.\n",
    "Instead, Data-OOB computes data values from out-of-bag (OOB) error estimates of a bagging model. Originally, the method is therefore only designed for bagging models, but it can be adapted to other models as well.\n",
    "\n",
    "For a bagging model with $B$ estimators $\\hat{f}_b, b \\in [B]$, we define $w_{bj}$ as the number of times that the $j$-th sample is in the training set of the $b$-th estimator. For a **fixed** choice of bootstrapped training sets, the Data-OOB value of sample $(x_i, y_i)$ is defined as:\n",
    " \n",
    "$$\n",
    "\\psi(x_i,y_i) := \\frac{\\sum_{b=1}^{B}\\mathbb{1}(w_{bi}=0)T(y_i, \\hat{f}_b(x_i))}{\\sum_{b=1}^{B}\n",
    "\\mathbb{1} (w_{bi}=0)}.\n",
    "$$\n",
    "\n",
    "It can therefore be interpreted as a per-sample partition of the standard OOB error estimate for a bagging model, which is: $\\frac{1}{n} \\sum_{i=1}^n \\psi(x_i,y_i)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "We begin by importing the main libraries and setting some defaults.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "If you are reading this in the documentation, some boilerplate (including most plotting code) has been omitted for convenience.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide"
    ]
   },
   "source": [
    "%load_ext autoreload\n",
    "\n",
    "import os\n",
    "import random\n",
    "from typing import Literal\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from pydvl.reporting.plots import plot_ci_array, plot_ci_values\n",
    "from pydvl.reporting.scores import compute_removal_score\n",
    "from support.common import load_adult_data\n",
    "\n",
    "matplotlib.rcParams[\"axes.facecolor\"] = (1, 1, 1, 0)\n",
    "plt.rcParams[\"axes.facecolor\"] = (1, 1, 1, 0)\n",
    "plt.rcParams[\"figure.facecolor\"] = (1, 1, 1, 0)\n",
    "\n",
    "is_CI = os.environ.get(\"CI\")\n",
    "random_state = 24\n",
    "random.seed(random_state);"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "%autoreload\n",
    "from pydvl.valuation import (\n",
    "    ValuationResult,\n",
    "    DataOOBValuation,\n",
    "    Dataset,\n",
    "    KNNClassifierUtility,\n",
    "    )\n",
    "from pydvl.utils import Seed, ensure_seed_sequence"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with the [adult classification dataset](https://archive.ics.uci.edu/dataset/2/adult) from the UCI repository. The objective is to predict whether a person earns more than 50k a year based on a set of features such as age, education, occupation, etc.\n",
    "\n",
    "With a helper function we download the data and obtain the following pandas dataframe, where the categorical features have been removed:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "hide-output"
    ]
   },
   "source": [
    "data_adult = load_adult_data()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "tags": [
     "hide"
    ]
   },
   "source": [
    "if is_CI:\n",
    "    data_adult = data_adult.sample(100, random_state=random_state)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": "data_adult.head()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the OOB values\n",
    "\n",
    "The main idea of Data-OOB is to use the out-of-bag error estimates of a bagging model to compute data values. In pyDVL, we provide a class [DataOOBValuation][pydvl.valuation.DataOOBValuation] that allows extending this idea to any classifier. The class is designed to take an existing classifier or regression model and compute a per-sample out-of-bag performance estimate via bagging.\n",
    "\n",
    "For this example, we use a simple KNN classifier with $k=5$ neighbours on the data and compute the data-oob values with two choices for the number of estimators in the bagging.\n",
    "\n",
    "We then use the [fit][pydvl.valuation.DataOOBValuation.fit] method to compute the values and store them in a [ValuationResult][pydvl.value.result.ValuationResult] object."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "data = Dataset(\n",
    "        data_adult.drop(columns=[\"income\"]).values,\n",
    "        data_adult.loc[:, \"income\"].cat.codes.values,\n",
    "        )\n",
    "model = KNeighborsClassifier(n_neighbors=5)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "n_estimators = [100, 500]\n",
    "oob_values = []\n",
    "for n_est in n_estimators:\n",
    "    valuation = DataOOBValuation(\n",
    "            model, n_estimators=n_est, max_samples=0.95, seed=random_state\n",
    "            )\n",
    "    valuation.fit(data)\n",
    "    oob_values.append(valuation.values())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "The two results are stored in an array of [ValuationResult][pydvl.value.result.ValuationResult] objects. Here's their distribution. The left-hand side depicts value as it increases with rank and a 99% t-confidence interval. The right-hand side shows the histogram of values.\n",
    "\n",
    "Observe how adding estimators reduces the variance of the values, but doesn't change their distribution much. "
   ]
  },
  {
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "cell_type": "code",
   "source": [
    "mean_colors = [\"dodgerblue\", \"indianred\", \"limegreen\", \"darkorange\",\n",
    "               \"darkorchid\"]\n",
    "shade_colors = [\"lightskyblue\", \"firebrick\", \"seagreen\", \"gold\", \"plum\"]\n",
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=[15, 5])\n",
    "\n",
    "for (n_est, values, mean_color, shade_color) in zip(\n",
    "        n_estimators, oob_values, mean_colors, shade_colors\n",
    "        ):\n",
    "    values.sort(key=\"value\")\n",
    "    plot_ci_values(\n",
    "            values,\n",
    "            level=0.01,\n",
    "            mean_color=mean_color,\n",
    "            shade_color=shade_color,\n",
    "            ax=ax1,\n",
    "            label=f\"{n_est} estimators\",\n",
    "            )\n",
    "\n",
    "    ax2.hist(values, bins=50, color=mean_color, alpha=0.5,\n",
    "             label=f\"{n_est} estimators\")\n",
    "ax1.set_title(\"Point rank\")\n",
    "ax1.set_xlabel(\"Value\")\n",
    "ax1.set_ylabel(\"Data-OOB values\")\n",
    "ax1.set_xticks(ax1.get_xticks()[::150])\n",
    "ax1.legend()\n",
    "ax2.set_title(\"Histogram of Data-OOB values\")\n",
    "ax2.legend()\n",
    "plt.plot();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "cell_type": "markdown",
   "source": [
    "## Point removal experiments\n",
    "\n",
    "The standard procedure for the evaluation of data valuation schemes is the point removal experiment. The objective is to measure the evolution of performance when the best/worst points are iteratively removed from the training set. This can be done with the function [compute_removal_score][pydvl.reporting.scores.compute_removal_score], which takes precomputed values and evaluates the performance of the model as points are removed from the training set.\n",
    "\n",
    "We repeat the whole task of computing the values and the point removal experiment multiple times, including the splitting of the dataset into training and valuation sets. It is important to remember to pass random state adequately for full reproducibility."
   ]
  },
  {
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide"
    ]
   },
   "cell_type": "code",
   "source": [
    "def removal_job(\n",
    "        method: Literal[\"random\", \"data_oob\"],\n",
    "        seed: Seed,\n",
    "        n_est: int = 500,\n",
    "        max_samples: float = 0.95,\n",
    "        ):\n",
    "    \"\"\"This is not very efficient, but it's just an example.\"\"\"\n",
    "    data = Dataset(\n",
    "            data_adult.drop(columns=[\"income\"]).values,\n",
    "            data_adult.loc[:, \"income\"].cat.codes.values,\n",
    "            )\n",
    "    model = KNeighborsClassifier(n_neighbors=5)\n",
    "\n",
    "    if method == \"random\":\n",
    "        values = ValuationResult.from_random(size=len(data), seed=seed)\n",
    "    else:\n",
    "        valuation = DataOOBValuation(\n",
    "                model, n_estimators=n_est, max_samples=max_samples, seed=seed\n",
    "                )\n",
    "        valuation.fit(data)\n",
    "        values = valuation.values()\n",
    "\n",
    "    best_scores = compute_removal_score(\n",
    "            KNNClassifierUtility(model, data),\n",
    "            values,\n",
    "            data,\n",
    "            percentages=removal_percentages,\n",
    "            remove_best=True,\n",
    "            )\n",
    "    best_scores[\"method_name\"] = method\n",
    "\n",
    "    worst_scores = compute_removal_score(\n",
    "            KNNClassifierUtility(model, data),\n",
    "            values,\n",
    "            data,\n",
    "            percentages=removal_percentages,\n",
    "            remove_best=False,\n",
    "            )\n",
    "    worst_scores[\"method_name\"] = method\n",
    "\n",
    "    return best_scores, worst_scores"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide"
    ]
   },
   "cell_type": "code",
   "source": [
    "from joblib import parallel_config, Parallel, delayed\n",
    "\n",
    "n_runs = 20\n",
    "n_jobs = 20\n",
    "n_est = 500\n",
    "max_samples = 0.95\n",
    "seed = random_state\n",
    "\n",
    "all_best_scores = []\n",
    "all_worst_scores = []\n",
    "removal_percentages = np.arange(0, 0.99, 0.01)\n",
    "\n",
    "pending = set()\n",
    "\n",
    "with parallel_config(n_jobs=n_jobs):\n",
    "    seed_seq = ensure_seed_sequence(seed)\n",
    "    job = delayed(removal_job)\n",
    "    args = zip([\"random\", \"data_oob\"] * n_runs,\n",
    "               seed_seq.spawn(2 * n_runs),\n",
    "               [n_est] * 2 * n_runs,\n",
    "               [max_samples] * 2 * n_runs)\n",
    "    with Parallel(return_as=\"generator_unordered\") as parallel:\n",
    "        delayed_evals = parallel(\n",
    "                job(method=m, seed=s, n_est=n, max_samples=ms) for m, s, n, ms\n",
    "                in args)\n",
    "        for result in tqdm(delayed_evals, unit=\"%\", total=2 * n_runs):\n",
    "            best_scores, worst_scores = result\n",
    "            all_best_scores.append(best_scores)\n",
    "            all_worst_scores.append(worst_scores)\n",
    "\n",
    "best_scores_df = pd.DataFrame(all_best_scores)\n",
    "worst_scores_df = pd.DataFrame(all_worst_scores)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "hide-input",
     "invertible-output"
    ]
   },
   "source": [
    "fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=[15, 5])\n",
    "\n",
    "for i, method_name in enumerate([\"random\", \"data_oob\"]):\n",
    "    plot_ci_array(\n",
    "            data=worst_scores_df[worst_scores_df[\"method_name\"] == method_name]\n",
    "            .drop(columns=[\"method_name\"])\n",
    "            .values,\n",
    "            level=0.05,\n",
    "            abscissa=removal_percentages,\n",
    "            mean_color=mean_colors[i],\n",
    "            shade_color=shade_colors[i],\n",
    "            label=method_name,\n",
    "            ax=ax1,\n",
    "            )\n",
    "    plot_ci_array(\n",
    "            best_scores_df[best_scores_df[\"method_name\"] == method_name]\n",
    "            .drop(columns=[\"method_name\"])\n",
    "            .values,\n",
    "            level=0.05,\n",
    "            abscissa=removal_percentages,\n",
    "            mean_color=mean_colors[i],\n",
    "            shade_color=shade_colors[i],\n",
    "            label=method_name,\n",
    "            ax=ax2,\n",
    "            )\n",
    "metric_name = \"Accuracy\"\n",
    "ax1.set_title(\"Worst point removal, 95% CI\")\n",
    "ax1.set_xlabel(\"Fraction of data removed\")\n",
    "ax1.set_ylabel(metric_name)\n",
    "ax1.set_xticks(ax1.get_xticks()[::10])\n",
    "ax1.legend()\n",
    "ax2.set_title(\"Best point removal, 95% CI\")\n",
    "ax2.set_xlabel(\"Fraction of data removed\")\n",
    "ax2.set_xticks(ax2.get_xticks()[::10])\n",
    "ax2.set_ylabel(metric_name)\n",
    "ax2.legend()\n",
    "\n",
    "plt.show();"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "celltoolbar": "Edit Metadata",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "4e000971326892723e7f31ded70802f690c31c3620f59a0f99e594aaee3047ef"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

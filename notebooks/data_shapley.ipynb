{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "$$ \\phi_i = C \\sum_{S \\subset D \\backslash \\{i\\}} \\frac{1}{{n-1} \\choose {|S|}} [V(S \\cup \\{i\\})-V(S)]$$\n",
    "\n",
    "$$ \\phi_i = \\mathbb{E}_{\\pi \\sim \\Pi} [V(S^i_{\\pi} \\cup {\\{i\\}})-V(S^i_{\\pi})]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "1. n = number of training samples\n",
    "1. values = -np.inf * np.ones(n)\n",
    "1. scores = [[] for _ in range(n)]\n",
    "1. For i in (1,n):\n",
    "    1. iteration = 0\n",
    "    1. while iteration < max_iterations:\n",
    "        1. Draw an n-permutation\n",
    "        1. model.fit(samples(permutation(:index(i))))\n",
    "        1. score_without = model.predict(test set)\n",
    "        1. model.fit(samples(permutation(:index(i)+1)))\n",
    "        1. score_with = model.predict(test set)\n",
    "        1. old_moving_average = mean(scores(i))\n",
    "        1. scores(i).push(score_with - score_without)\n",
    "        1. new_moving_average = mean(scores(i))\n",
    "        1. if abs(new_moving_average - old_moving_average) < eps then break\n",
    "        1. old_moving_average = new_moving_average \n",
    "        1. iteration += 1\n",
    "    1. values(i) = mean(scores(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from valuation.utils import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data = Dataset.from_sklearn(datasets.load_boston())\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(data.x_train, data.y_train)\n",
    "predictions = model.predict(data.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "plt.scatter(data.y_test, predictions)\n",
    "plt.plot([0, 50], [0, 50], '--k')\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from valuation.shapley import permutation_exact_shapley, truncated_montecarlo_shapley\n",
    "from valuation.utils import map_reduce, Utility\n",
    "from valuation.reporting.scores import compute_fb_scores\n",
    "from valuation.reporting.plots import shapley_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Shapley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to examine how the shapley values change with train and test data. In particular, we want to examine how robust data shapley values are to out of distribution input data. To do so, we will progressively add more and more outliers to our train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polynomial(coefficients, x):\n",
    "    powers = np.arange(len(coefficients))\n",
    "    return np.power(x, np.tile(powers, (len(x), 1)).T).T @ coefficients\n",
    "\n",
    "def polynomial_dataset(coefficients: np.ndarray):\n",
    "    \"\"\"Coefficients must be for monomials of increasing degree\"\"\"\n",
    "    from sklearn.utils import Bunch\n",
    "\n",
    "    x = np.arange(-1, 1, 0.2)\n",
    "    locs = polynomial(coefficients, x)\n",
    "    y = np.random.normal(loc=locs, scale=0.3)\n",
    "    db = Bunch()\n",
    "    db.data, db.target = x.reshape(-1, 1), y\n",
    "    poly = [f\"{c} x^{i}\" for i, c in enumerate(coefficients)]\n",
    "    poly = \" + \".join(poly)\n",
    "    db.DESCR = f\"$y \\\\sim N({poly}, 1)$\"\n",
    "    db.feature_names = [\"x\"]\n",
    "    db.target_names = [\"y\"]\n",
    "    return Dataset.from_sklearn(data=db, train_size=0.5), coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "d, coeffs = polynomial_dataset(np.random.randint(-3, 3, size=3))  \n",
    "model = make_pipeline(PolynomialFeatures(len(coeffs)-1), LinearRegression())\n",
    "\n",
    "n = len(d)\n",
    "model.fit(d.x_train, d.y_train)\n",
    "predicted = [model.predict(d.x_test)]\n",
    "\n",
    "x_cont = d.x_train.reshape(-1,) + np.random.uniform(-0.05, 0.05, size=len(d))\n",
    "x_cont = x_cont[::2]\n",
    "y_cont = polynomial(np.random.normal(loc=coeffs, scale=0.3), x_cont)\n",
    "xtrain = np.concatenate([d.x_train, x_cont.reshape(-1, 1)], axis=0)\n",
    "ytrain = np.concatenate([d.y_train, y_cont.reshape(-1,)], axis=0)\n",
    "for i in range(len(d), len(xtrain)):\n",
    "    model.fit(xtrain[:i+1], ytrain[:i+1])\n",
    "    ypred = model.predict(d.x_test)\n",
    "    predicted.append(ypred)\n",
    "\n",
    "test_indices = np.argsort(d.x_test, axis=0).reshape(-1, )\n",
    "xx = np.arange(-1, 1, 0.1)\n",
    "yy = polynomial(coeffs, xx)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "for i, ypred in enumerate(predicted):\n",
    "    plt.figure(dpi=300)\n",
    "    plt.scatter(d.x_train[:n], d.y_train[:n], label=\"Training (in-dist)\")\n",
    "    plt.scatter(d.x_test, d.y_test, label=\"Test\")\n",
    "\n",
    "    if i > 0:\n",
    "        plt.scatter(x_cont[:i], y_cont[:i], label=\"Training (out of dist)\")\n",
    "    plt.plot(xx, yy, label=\"True\")\n",
    "    plt.plot(d.x_test[test_indices], ypred[test_indices], label=\"Predicted\")\n",
    "    plt.ylim(min(d.y_train[:n].min(), y_cont.min()) - 1,\n",
    "                max(d.y_train[:n].max(), y_cont.max()) + 1)\n",
    "    plt.legend()\n",
    "    plt.title(d.description)\n",
    "    plt.show()\n",
    "\n",
    "d.x_train = xtrain\n",
    "d.y_train = ytrain\n",
    "\n",
    "from valuation.shapley import combinatorial_exact_shapley\n",
    "from valuation.utils import Utility\n",
    "u = Utility(model, d, \"neg_median_absolute_error\")\n",
    "values = combinatorial_exact_shapley(u, progress=False)\n",
    "\n",
    "print(\"******\")\n",
    "print(values)\n",
    "print(\"******\")\n",
    "high_to_low = list(reversed(values))\n",
    "print(high_to_low)\n",
    "print(\"******\")\n",
    "print(list(np.round(d.x_train[high_to_low].reshape(-1,), 2)))\n",
    "print(list(np.round(d.y_train[high_to_low], 2)))\n",
    "\n",
    "take = 5\n",
    "plt.figure(dpi=300)\n",
    "plt.scatter(d.x_train[:n], d.y_train[:n], label=\"Training (in-dist)\")\n",
    "plt.scatter(d.x_test, d.y_test, label=\"Test\")\n",
    "plt.scatter(d.x_train[high_to_low][:take], d.y_train[high_to_low][:take],\n",
    "            marker='x', label='High value')\n",
    "plt.scatter(x_cont, y_cont, label=\"Training (out of dist)\")\n",
    "plt.plot(xx, yy, label=\"True\")\n",
    "plt.plot(d.x_test[test_indices], predicted[-1][test_indices], label=\"Predicted\")\n",
    "\n",
    "model.fit(d.x_train[high_to_low][:take], d.y_train[high_to_low][:take])\n",
    "ypred = model.predict(d.x_test)\n",
    "plt.plot(d.x_test, ypred, label='High: prediction')\n",
    "plt.title(d.description)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# MCShapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "max_iterations = 200\n",
    "utility = Utility(\n",
    "    model,\n",
    "    data,\n",
    "    scoring=None,\n",
    "    enable_cache=False,\n",
    ")\n",
    "fun = partial(permutation_exact_shapley, utility=utility, progress=True)\n",
    "values_nmcs, hist_nmcs = map_reduce(fun, num_runs=10, num_jobs=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores_nmcs = compute_fb_scores(model=model, data=data, values=values_nmcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores_nmcs.update({'max_iterations': max_iterations, 'score_name': \"$R^2$\"})\n",
    "shapley_results(scores_nmcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated MC Shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "params = {'bootstrap_iterations': 200,\n",
    "          'min_scores': 10,\n",
    "          'score_tolerance': 0.1,\n",
    "          'min_values': 10,\n",
    "          'value_tolerance': 1e-2,\n",
    "          'max_iterations': 0.5*len(data)}\n",
    "fun = partial(truncated_montecarlo_shapley, \n",
    "              model, data, num_workers=160, worker_progress=False, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "values_mcs, hist_mcs = map_reduce(fun, data=data, num_runs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores_mcs = compute_fb_scores(model=model, data=data, values=values_mcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "scores_mcs.update({'max_iterations': params['max_iterations'], 'score_name': \"$R^2$\"})\n",
    "shapley_results(scores_mcs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

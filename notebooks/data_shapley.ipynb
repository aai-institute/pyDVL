{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\phi_i = C \\sum_{S \\subset D \\backslash \\{i\\}} \\frac{1}{{n-1} \\choose {|S|}} [V(S \\cup \\{i\\})-V(S)]$$\n",
    "\n",
    "$$ \\phi_i = \\mathbb{E}_{\\pi \\sim \\Pi} [V(S^i_{\\pi} \\cup {\\{i\\}})-V(S^i_{\\pi})]$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. n = number of training samples\n",
    "1. values = -np.inf * np.ones(n)\n",
    "1. scores = [[] for _ in range(n)]\n",
    "1. For i in (1,n):\n",
    "    1. iteration = 0\n",
    "    1. while iteration < max_iterations:\n",
    "        1. Draw an n-permutation\n",
    "        1. model.fit(samples(permutation(:index(i))))\n",
    "        1. score_without = model.predict(test set)\n",
    "        1. model.fit(samples(permutation(:index(i)+1)))\n",
    "        1. score_with = model.predict(test set)\n",
    "        1. old_moving_average = mean(scores(i))\n",
    "        1. scores(i).push(score_with - score_without)\n",
    "        1. new_moving_average = mean(scores(i))\n",
    "        1. if abs(new_moving_average - old_moving_average) < eps then break\n",
    "        1. old_moving_average = new_moving_average \n",
    "        1. iteration += 1\n",
    "    1. values(i) = mean(scores(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from functools import partial\n",
    "from sklearn import datasets\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from valuation.utils import Dataset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_sklearn(datasets.load_boston())\n",
    "model = GradientBoostingRegressor()\n",
    "model.fit(data.x_train, data.y_train)\n",
    "predictions = model.predict(data.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(9, 6))\n",
    "plt.scatter(data.y_test, predictions)\n",
    "plt.plot([0, 50], [0, 50], '--k')\n",
    "plt.xlabel('True')\n",
    "plt.ylabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from valuation.shapley import permutation_exact_shapley, truncated_montecarlo_shapley\n",
    "from valuation.utils import map_reduce, Utility\n",
    "from valuation.reporting.scores import compute_fb_scores\n",
    "from valuation.reporting.plots import shapley_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Shapley"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to examine how the shapley values change with train and test data. In particular, we want to examine how robust data shapley values are to out of distribution input data. To do so, we will progressively add more and more outliers to our train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from valuation.utils.dataset import polynomial_dataset, polynomial\n",
    "\n",
    "d, coeffs = polynomial_dataset(np.random.randint(-3, 3, size=3))  \n",
    "model = make_pipeline(PolynomialFeatures(len(coeffs)-1), LinearRegression())\n",
    "\n",
    "n = len(d)\n",
    "model.fit(d.x_train, d.y_train)\n",
    "predicted = [model.predict(d.x_test)]\n",
    "\n",
    "x_cont = d.x_train.reshape(-1,) + np.random.uniform(-0.05, 0.05, size=len(d))\n",
    "x_cont = x_cont[::2]\n",
    "y_cont = polynomial(np.random.normal(loc=coeffs, scale=0.3), x_cont)\n",
    "xtrain = np.concatenate([d.x_train, x_cont.reshape(-1, 1)], axis=0)\n",
    "ytrain = np.concatenate([d.y_train, y_cont.reshape(-1,)], axis=0)\n",
    "for i in range(len(d), len(xtrain)):\n",
    "    model.fit(xtrain[:i+1], ytrain[:i+1])\n",
    "    ypred = model.predict(d.x_test)\n",
    "    predicted.append(ypred)\n",
    "\n",
    "test_indices = np.argsort(d.x_test, axis=0).reshape(-1, )\n",
    "xx = np.arange(-1, 1, 0.1)\n",
    "yy = polynomial(coeffs, xx)\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "for i, ypred in enumerate(predicted):\n",
    "    plt.figure(dpi=300)\n",
    "    plt.scatter(d.x_train[:n], d.y_train[:n], label=\"Training (in-dist)\")\n",
    "    plt.scatter(d.x_test, d.y_test, label=\"Test\")\n",
    "\n",
    "    if i > 0:\n",
    "        plt.scatter(x_cont[:i], y_cont[:i], label=\"Training (out of dist)\")\n",
    "    plt.plot(xx, yy, label=\"True\")\n",
    "    plt.plot(d.x_test[test_indices], ypred[test_indices], label=\"Predicted\")\n",
    "    plt.ylim(min(d.y_train[:n].min(), y_cont.min()) - 1,\n",
    "                max(d.y_train[:n].max(), y_cont.max()) + 1)\n",
    "    plt.legend()\n",
    "    plt.title(d.description)\n",
    "    plt.show()\n",
    "\n",
    "d.x_train = xtrain\n",
    "d.y_train = ytrain\n",
    "\n",
    "from valuation.shapley import combinatorial_exact_shapley\n",
    "from valuation.utils import Utility\n",
    "u = Utility(model, d, \"neg_median_absolute_error\")\n",
    "values = combinatorial_exact_shapley(u, progress=False)\n",
    "high_to_low = list(reversed(values))\n",
    "\n",
    "take = 5\n",
    "plt.figure(dpi=300)\n",
    "plt.scatter(d.x_train[:n], d.y_train[:n], label=\"Training (in-dist)\")\n",
    "plt.scatter(d.x_test, d.y_test, label=\"Test\")\n",
    "plt.scatter(d.x_train[high_to_low][:take], d.y_train[high_to_low][:take],\n",
    "            marker='x', label='High value')\n",
    "plt.scatter(x_cont, y_cont, label=\"Training (out of dist)\")\n",
    "plt.plot(xx, yy, label=\"True\")\n",
    "plt.plot(d.x_test[test_indices], predicted[-1][test_indices], label=\"Predicted\")\n",
    "\n",
    "model.fit(d.x_train[high_to_low][:take], d.y_train[high_to_low][:take])\n",
    "ypred = model.predict(d.x_test)\n",
    "plt.plot(d.x_test, ypred, label='High: prediction')\n",
    "plt.title(d.description)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MCShapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iterations = 200\n",
    "utility = Utility(\n",
    "    model,\n",
    "    data,\n",
    "    scoring=None,\n",
    "    enable_cache=False,\n",
    ")\n",
    "fun = partial(permutation_exact_shapley, utility=utility, progress=True)\n",
    "values_nmcs, hist_nmcs = map_reduce(fun, num_runs=10, num_jobs=160)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nmcs = compute_fb_scores(model=model, data=data, values=values_nmcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_nmcs.update({'max_iterations': max_iterations, 'score_name': \"$R^2$\"})\n",
    "shapley_results(scores_nmcs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Truncated MC Shapley"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'bootstrap_iterations': 200,\n",
    "          'min_scores': 10,\n",
    "          'score_tolerance': 0.1,\n",
    "          'min_values': 10,\n",
    "          'value_tolerance': 1e-2,\n",
    "          'max_iterations': 0.5*len(data)}\n",
    "fun = partial(truncated_montecarlo_shapley, \n",
    "              model, data, num_workers=160, worker_progress=False, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "values_mcs, hist_mcs = map_reduce(fun, data=data, num_runs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mcs = compute_fb_scores(model=model, data=data, values=values_mcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_mcs.update({'max_iterations': params['max_iterations'], 'score_name': \"$R^2$\"})\n",
    "shapley_results(scores_mcs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dval_env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b3369ace3ad477f5e763d9fa7767e0177027059e92a8b1ded9e92b707c0b1513"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Data Utility Learning &mdash; pyDVL 0.1.1.dev1 documentation</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/design-tabs.js"></script>
        <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
        <script>window.MathJax = {"tex": {"inlineMath": [["\\(", "\\)"]], "processEscapes": true, "displayMath": [["\\[", "\\]"]]}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
        <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Influence functions for data mislabeling" href="influence_synthetic.html" />
    <link rel="prev" title="KNN Shapley" href="knn_shapley_flowers.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../index.html">
            <img src="../_static/logo.svg" class="logo" alt="Logo"/>
          </a>
              <div class="version">
                0.1
              </div>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Table of Contents</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../10-getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20-install.html">Installing pyDVL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../30-data-valuation.html">Computing data values</a></li>
<li class="toctree-l1"><a class="reference internal" href="../40-influence.html">Computing influence values</a></li>
<li class="toctree-l1 current"><a class="reference internal" href="index.html">Examples</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="shapley_spotify.html">Shapley for data valuation</a></li>
<li class="toctree-l2"><a class="reference internal" href="knn_shapley_flowers.html">KNN Shapley</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Data Utility Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="influence_synthetic.html">Influence functions for data mislabeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="influence_wine.html">Influence functions and neural networks</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Data Utility Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="influence_synthetic.html">Influence functions for data mislabeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="influence_wine.html">Influence functions and neural networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="knn_shapley_flowers.html">KNN Shapley</a></li>
<li class="toctree-l2"><a class="reference internal" href="shapley_spotify.html">Shapley for data valuation</a></li>
<li class="toctree-l2"><a class="reference internal" href="tests-valuation.html">Some tests, do not commit</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../pydvl/index.html">API Reference</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">pyDVL</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content style-external-links">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home"></a> &raquo;</li>
          <li><a href="index.html">Examples</a> &raquo;</li>
      <li>Data Utility Learning</li>
      <li class="wy-breadcrumbs-aside">
            <a href="../_sources/examples/data_utility_learning.ipynb.txt" rel="nofollow"> View page source</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput.container div.prompt *,
div.nboutput.container div.prompt *,
div.nbinput.container div.input_area pre,
div.nboutput.container div.output_area pre,
div.nbinput.container div.input_area .highlight,
div.nboutput.container div.output_area .highlight {
    border: none;
    padding: 0;
    margin: 0;
    box-shadow: none;
}

div.nbinput.container > div[class*=highlight],
div.nboutput.container > div[class*=highlight] {
    margin: 0;
}

div.nbinput.container div.prompt *,
div.nboutput.container div.prompt * {
    background: none;
}

div.nboutput.container div.output_area .highlight,
div.nboutput.container div.output_area pre {
    background: unset;
}

div.nboutput.container div.output_area div.highlight {
    color: unset;  /* override Pygments text color */
}

/* avoid gaps between output lines */
div.nboutput.container div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput.container,
div.nboutput.container {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput.container,
    div.nboutput.container {
        flex-direction: column;
    }
}

/* input container */
div.nbinput.container {
    padding-top: 5px;
}

/* last container */
div.nblast.container {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput.container div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput.container div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput.container div.prompt,
div.nboutput.container div.prompt {
    width: 4.5ex;
    padding-top: 5px;
    position: relative;
    user-select: none;
}

div.nbinput.container div.prompt > div,
div.nboutput.container div.prompt > div {
    position: absolute;
    right: 0;
    margin-right: 0.3ex;
}

@media (max-width: 540px) {
    div.nbinput.container div.prompt,
    div.nboutput.container div.prompt {
        width: unset;
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput.container div.prompt.empty {
        padding: 0;
    }

    div.nbinput.container div.prompt > div,
    div.nboutput.container div.prompt > div {
        position: unset;
    }
}

/* disable scrollbars on prompts */
div.nbinput.container div.prompt pre,
div.nboutput.container div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput.container div.input_area,
div.nboutput.container div.output_area {
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput.container div.input_area,
    div.nboutput.container div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput.container div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    /*background: #f5f5f5;*/
}

/* override MathJax center alignment in output cells */
div.nboutput.container div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput.container div.math p {
    text-align: left;
}

/* standard error */
div.nboutput.container div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }


div.nbinput.container div.input_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight] > pre,
div.nboutput.container div.output_area div[class*=highlight].math,
div.nboutput.container div.output_area.rendered_html,
div.nboutput.container div.output_area > div.output_javascript,
div.nboutput.container div.output_area:not(.rendered_html) > img{
    padding: 5px;
    margin: 0;
}

/* fix copybtn overflow problem in chromium (needed for 'sphinx_copybutton') */
div.nbinput.container div.input_area > div[class^='highlight'],
div.nboutput.container div.output_area > div[class^='highlight']{
    overflow-y: hidden;
}

/* hide copybtn icon on prompts (needed for 'sphinx_copybutton') */
.prompt .copybtn {
    display: none;
}

/* Some additional styling taken form the Jupyter notebook CSS */
.jp-RenderedHTMLCommon table,
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
.jp-RenderedHTMLCommon thead,
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
.jp-RenderedHTMLCommon tr,
.jp-RenderedHTMLCommon th,
.jp-RenderedHTMLCommon td,
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
.jp-RenderedHTMLCommon th,
div.rendered_html th {
  font-weight: bold;
}
.jp-RenderedHTMLCommon tbody tr:nth-child(odd),
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
.jp-RenderedHTMLCommon tbody tr:hover,
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast.container,
.nboutput.nblast.container {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast.container + .nbinput.container {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="admonition note">
    This page was generated from
    <a class="reference external" href="https://github.com/appliedAI-Initiative/pyDVL/blob/develop/notebooks/data_utility_learning.ipynb">notebooks/data_utility_learning.ipynb</a>
    <br>
    Interactive online version:
    <span style="white-space: nowrap;">
        <a href="https://mybinder.org/v2/gh/appliedAI-Initiative/pyDVL/develop?filepath=notebooks/data_utility_learning.ipynb">
            <img alt="Binder badge" src="https://mybinder.org/badge_logo.svg" style="vertical-align:text-bottom">
        </a>
    </span>
</div>

<style>
    .nbinput .prompt,
    .nboutput .prompt {
        display: none;
    }
</style><section id="Data-Utility-Learning">
<h1>Data Utility Learning<a class="headerlink" href="#Data-Utility-Learning" title="Permalink to this heading"></a></h1>
<p>This notebook introduces <strong>Data Utility Learning</strong>, a method of approximating Data Shapley values by learning to estimate the utility function.</p>
<p>The idea is to employ a model to learn the performance of the learning algorithm of interest on unseen data combinations (i.e. subsets of the dataset). The method was originally described in <em>Wang, Tianhao, Yu Yang, and Ruoxi Jia.</em><a class="reference external" href="https://doi.org/10.48550/arXiv.2107.06336">Improving Cooperative Game Theory-Based Data Valuation via Data Utility Learning</a><em>. arXiv, 2022</em>.</p>
<div class="admonition warning">
<p><strong>Warning:</strong> Work on Data Utility Learning is preliminary. It remains to be seen when or whether it can be put effectively into application. For this further testing and benchmarking are required.</p>
</div>
<p>Recall the definition of Shapley value <span class="math notranslate nohighlight">\(v_u(i)\)</span> for data point <span class="math notranslate nohighlight">\(i\)</span>:</p>
<p><span class="math">\begin{equation}
v_u(i) = \frac{1}{n} \sum_{S \subseteq N \setminus \{i\}} \binom{n-1}{|S|}^{-1} [u(S \cup \{i\}) − u(S)] ,
\tag{1}
\label{eq:shapley-def}
\end{equation}</span></p>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the set of all indices in the training set and <span class="math notranslate nohighlight">\(u\)</span> is the utility. To avoid the exponential cost of computing this sum, we set to learn a surrogate model for <span class="math notranslate nohighlight">\(u\)</span>.</p>
<p>In Data Utility Learning, we start by sampling so-called <strong>utility samples</strong> to form a training set <span class="math notranslate nohighlight">\(S_\text{train}\)</span> for our utility model. Each utility sample is a tuple consisting of a subset of indices <span class="math notranslate nohighlight">\(S_j\)</span> in the dataset and its utility <span class="math notranslate nohighlight">\(u(S_j)\)</span>:</p>
<div class="math notranslate nohighlight">
\[\mathcal{S}_\text{train} = \{(S_j, v(S_j): j = 1 , ..., m_\text{train}\}\]</div>
<p>where <span class="math notranslate nohighlight">\(m_\text{train}\)</span> denotes the <em>training budget</em> for the learned utility function.</p>
<p>The subsets are then transformed into boolean vectors <span class="math notranslate nohighlight">\(\phi\)</span> in which a <span class="math notranslate nohighlight">\(1\)</span> at index <span class="math notranslate nohighlight">\(k\)</span> means that the <span class="math notranslate nohighlight">\(k\)</span>-th sample of the dataset is present in the subset:</p>
<div class="math notranslate nohighlight">
\[S_j \mapsto \phi_j \in \{ 0, 1 \}^{N}\]</div>
<p>We fit a regression model <span class="math notranslate nohighlight">\(\tilde{u}\)</span>, called <strong>data utility model</strong>, on <span class="math notranslate nohighlight">\(\mathcal{S}_\text{train}\)</span> and use it to avoid computing the utility for any <span class="math notranslate nohighlight">\(S_j \notin \mathcal{S}_\text{train}\)</span>:</p>
<div class="math notranslate nohighlight">
\[\tilde{u} : \{ 0, 1 \}^{N} \rightarrow \mathbb{R}.\]</div>
<p>The main assumption is that it is much faster to fit and use <span class="math notranslate nohighlight">\(\tilde{u}\)</span> than it is to compute <span class="math notranslate nohighlight">\(u\)</span> and that for most <span class="math notranslate nohighlight">\(i\)</span>, <span class="math notranslate nohighlight">\(v_\tilde{u}(i) \approx v_u(i)\)</span> in some sense.</p>
<section id="Imports">
<h2>Imports<a class="headerlink" href="#Imports" title="Permalink to this heading"></a></h2>
<p>We begin by importing the main libraries and setting some defaults.</p>
<div class="admonition note">
<p><strong>Note:</strong> If you are reading this in the documentation, some boilerplate is left out for your convenience.</p>
</div>
<p>As is the case with all other Shapley methods, the main entry point is the function <a class="reference internal" href="../pydvl/shapley.html#pydvl.shapley.compute_shapley_values"><span class="std std-ref">compute_shapley_values()</span></a>, which provides a facade to all algorithms in this family. We use it with the usual classes <a class="reference internal" href="../pydvl/utils/dataset.html#pydvl.utils.dataset.Dataset"><span class="std std-ref">Dataset</span></a> and <a class="reference internal" href="../pydvl/utils/utility.html#pydvl.utils.utility.Utility"><span class="std std-ref">Utility</span></a>. In addition, we must import the core class for learning a utility,
<a class="reference internal" href="../pydvl/utils/utility.html#pydvl.utils.utility.DataUtilityLearning"><span class="std std-ref">DataUtilityLearning</span></a>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pydvl.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">Dataset</span><span class="p">,</span>
    <span class="n">Utility</span><span class="p">,</span>
    <span class="n">DataUtilityLearning</span><span class="p">,</span>
    <span class="n">top_k_value_accuracy</span><span class="p">,</span>
    <span class="n">available_cpus</span><span class="p">,</span>
<span class="p">)</span>
<span class="kn">from</span> <span class="nn">pydvl.shapley</span> <span class="kn">import</span> <span class="n">compute_shapley_values</span>
</pre></div>
</div>
</div>
</section>
<section id="Dataset">
<h2>Dataset<a class="headerlink" href="#Dataset" title="Permalink to this heading"></a></h2>
<p>Following the paper, we take 15 samples (10%) from the <a class="reference external" href="https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html">Iris dataset</a> and compute their Data Shapley values by using all the remaining samples as test set for computing the utility, which in this case is accuracy.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="o">.</span><span class="n">from_sklearn</span><span class="p">(</span>
    <span class="n">load_iris</span><span class="p">(),</span> <span class="n">train_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span> <span class="n">random_state</span><span class="o">=</span><span class="n">random_state</span><span class="p">,</span> <span class="n">stratify</span><span class="o">=</span><span class="kc">True</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>We verify that, as in the paper, if we fit a Support-Vector Classifier to the training data, we obtain an accuracy of around 92%:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">x_train</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">y_train</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean accuracy: </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">x_test</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Mean accuracy: 92.59%
</pre></div></div>
</div>
</section>
<section id="Data-Shapley">
<h2>Data Shapley<a class="headerlink" href="#Data-Shapley" title="Permalink to this heading"></a></h2>
<p>We start by defining the utility using the model and computing the exact Data Shapley values by definition <span class="math notranslate nohighlight">\(\ref{eq:shapley-def}\)</span>.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">utility</span> <span class="o">=</span> <span class="n">Utility</span><span class="p">(</span><span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">dataset</span><span class="p">,</span> <span class="n">enable_cache</span><span class="o">=</span><span class="n">enable_cache</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">compute_shapley_values</span><span class="p">(</span>
    <span class="n">u</span><span class="o">=</span><span class="n">utility</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;combinatorial_exact&quot;</span><span class="p">,</span>
    <span class="n">n_jobs</span><span class="o">=</span><span class="n">available_cpus</span><span class="p">(),</span>
    <span class="n">progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;data_value&quot;</span><span class="p">:</span> <span class="s2">&quot;exact&quot;</span><span class="p">})</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
1
</pre></div></div>
</div>
<p>We now estimate the Data Shapley values using the <a class="reference internal" href="../pydvl/utils/utility.html#pydvl.utils.utility.DataUtilityLearning"><span class="std std-ref">DataUtilityLearning</span></a> wrapper. For the utility model we do as in the paper and use a fully connected neural network. To train it we use a total of <code class="docutils literal notranslate"><span class="pre">training_budget</span></code> of utility samples. We repeat this for each training budget.</p>
<p><strong>FIXME:</strong> repeat this multiple times in order to better estimate errors.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">training_budget</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">training_budget_values</span><span class="p">):</span>
    <span class="n">dul_utility</span> <span class="o">=</span> <span class="n">DataUtilityLearning</span><span class="p">(</span>
        <span class="n">u</span><span class="o">=</span><span class="n">utility</span><span class="p">,</span> <span class="n">training_budget</span><span class="o">=</span><span class="n">training_budget</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">MLPRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">mlp_kwargs</span><span class="p">)</span>
    <span class="p">)</span>

    <span class="n">dul_df</span> <span class="o">=</span> <span class="n">compute_shapley_values</span><span class="p">(</span>
        <span class="n">u</span><span class="o">=</span><span class="n">dul_utility</span><span class="p">,</span>
        <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;combinatorial_exact&quot;</span><span class="p">,</span>
        <span class="n">n_jobs</span><span class="o">=</span><span class="n">available_cpus</span><span class="p">(),</span>
        <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
    <span class="p">)</span>
    <span class="n">dul_df</span> <span class="o">=</span> <span class="n">dul_df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;data_value&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">training_budget</span><span class="si">}</span><span class="s2">_</span><span class="si">{</span><span class="n">idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">})</span>
    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df</span><span class="p">,</span> <span class="n">dul_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "a7f55d9c09e0440289f80f919e981587", "version_major": 2, "version_minor": 0}</script></div>
</div>
<p>Next we compute the mean, minimum and maximum absolute error for the different training budget values and look at the results. The plot matches the one in the paper and shows that the method works for estimating the Data Shapley values.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_data_utility_learning_20_0.png" src="../_images/examples_data_utility_learning_20_0.png" />
</div>
</div>
<p>Let us next look at how well the ranking of values resulting from using the surrogate <span class="math notranslate nohighlight">\(\tilde{u}\)</span> matches the true ranking. For this we fix <span class="math notranslate nohighlight">\(k=3\)</span> and consider the <span class="math notranslate nohighlight">\(k\)</span> samples with the highest value according to <span class="math notranslate nohighlight">\(\tilde{u}\)</span> and <span class="math notranslate nohighlight">\(u\)</span></p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_data_utility_learning_23_0.png" src="../_images/examples_data_utility_learning_23_0.png" />
</div>
</div>
<p>Finally, we compare the best approximate values obtained and their distance to the true ones (<strong>FIXME:</strong> use boxplot or similar here)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_data_utility_learning_26_0.png" src="../_images/examples_data_utility_learning_26_0.png" />
</div>
</div>
</section>
<section id="Evaluation-on-anomalous-data">
<h2>Evaluation on anomalous data<a class="headerlink" href="#Evaluation-on-anomalous-data" title="Permalink to this heading"></a></h2>
<p>One interesting way to assess the Data Utility Learning approach is to corrupt some of the data and monitor how the valuation score changes. To do this, we will take the sample with the highest score and change its label.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">highest_value_index</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;exact&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">argmax</span><span class="p">()]</span>
<span class="n">y_train_corrupted</span> <span class="o">=</span> <span class="n">dataset</span><span class="o">.</span><span class="n">y_train</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">y_train_corrupted</span><span class="p">[</span><span class="n">highest_value_index</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span>
    <span class="n">y_train_corrupted</span><span class="p">[</span><span class="n">highest_value_index</span><span class="p">]</span> <span class="o">+</span> <span class="mi">1</span>
<span class="p">)</span> <span class="o">%</span> <span class="mi">3</span>

<span class="n">corrupted_dataset</span> <span class="o">=</span> <span class="n">Dataset</span><span class="p">(</span>
    <span class="n">x_train</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">x_train</span><span class="p">,</span>
    <span class="n">y_train</span><span class="o">=</span><span class="n">y_train_corrupted</span><span class="p">,</span>
    <span class="n">x_test</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">x_test</span><span class="p">,</span>
    <span class="n">y_test</span><span class="o">=</span><span class="n">dataset</span><span class="o">.</span><span class="n">y_test</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<p>We retrain the model on the new dataset and verify that the accuracy decreases:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">LinearSVC</span><span class="p">()</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train_corrupted</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Mean accuracy: </span><span class="si">{</span><span class="mi">100</span> <span class="o">*</span> <span class="n">model</span><span class="o">.</span><span class="n">score</span><span class="p">(</span><span class="n">dataset</span><span class="o">.</span><span class="n">x_test</span><span class="p">,</span> <span class="n">dataset</span><span class="o">.</span><span class="n">y_test</span><span class="p">)</span><span class="si">:</span><span class="s2">0.2f</span><span class="si">}</span><span class="s2">%&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
0.8296296296296296
</pre></div></div>
</div>
<p>Finally, we recompute the scores of all samples using the exact method and the best training budget previously obtained and then plot the resulting scores. We can see in the figure that both methods assign the lowest value to the sample with the corrupted label.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">utility</span> <span class="o">=</span> <span class="n">Utility</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">LinearSVC</span><span class="p">(),</span>
    <span class="n">data</span><span class="o">=</span><span class="n">corrupted_dataset</span><span class="p">,</span>
    <span class="n">enable_cache</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">df_corrupted</span> <span class="o">=</span> <span class="n">compute_shapley_values</span><span class="p">(</span>
    <span class="n">u</span><span class="o">=</span><span class="n">utility</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;combinatorial_exact&quot;</span><span class="p">,</span>
    <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">df_corrupted</span> <span class="o">=</span> <span class="n">df_corrupted</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;data_value&quot;</span><span class="p">:</span> <span class="s2">&quot;exact&quot;</span><span class="p">})</span>

<span class="n">dul_utility</span> <span class="o">=</span> <span class="n">DataUtilityLearning</span><span class="p">(</span>
    <span class="n">u</span><span class="o">=</span><span class="n">utility</span><span class="p">,</span> <span class="n">training_budget</span><span class="o">=</span><span class="n">best_training_budget</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">MLPRegressor</span><span class="p">(</span><span class="o">**</span><span class="n">mlp_kwargs</span><span class="p">)</span>
<span class="p">)</span>

<span class="n">dul_df</span> <span class="o">=</span> <span class="n">compute_shapley_values</span><span class="p">(</span>
    <span class="n">u</span><span class="o">=</span><span class="n">dul_utility</span><span class="p">,</span>
    <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;combinatorial_exact&quot;</span><span class="p">,</span>
    <span class="n">progress</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">dul_df</span> <span class="o">=</span> <span class="n">dul_df</span><span class="o">.</span><span class="n">rename</span><span class="p">(</span><span class="n">columns</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;data_value&quot;</span><span class="p">:</span> <span class="s2">&quot;estimated&quot;</span><span class="p">})</span>
<span class="n">df_corrupted</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">concat</span><span class="p">([</span><span class="n">df_corrupted</span><span class="p">,</span> <span class="n">dul_df</span><span class="p">],</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>
<span class="n">df_corrupted</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span>
    <span class="n">y</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;exact&quot;</span><span class="p">,</span> <span class="s2">&quot;estimated&quot;</span><span class="p">],</span> <span class="n">kind</span><span class="o">=</span><span class="s2">&quot;bar&quot;</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;dodgerblue&quot;</span><span class="p">,</span> <span class="s2">&quot;indianred&quot;</span><span class="p">]</span>
<span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Index&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Data Shapley value&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">([</span><span class="s2">&quot;Exact&quot;</span><span class="p">,</span> <span class="s2">&quot;Estimated&quot;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_data_utility_learning_33_0.png" src="../_images/examples_data_utility_learning_33_0.png" />
</div>
</div>
<div class="admonition warning">
<p>As mentioned above, despite the previous results, this work is preliminary and the usefulness of Data Utility Learning remains to be tested in practice.</p>
</div>
<p>For one, as can be seen in the first figure, the error of the estimated utility doesn’t go below the error of true utility mean. This can either be due to the fact that for this dataset all the utility values are close to each other and that’s why the mean is a better predictor, or due to the method not learning anything useful apart from the mean.</p>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="knn_shapley_flowers.html" class="btn btn-neutral float-left" title="KNN Shapley" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="influence_synthetic.html" class="btn btn-neutral float-right" title="Influence functions for data mislabeling" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022 AppliedAI Institute gGmbH.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>
<!doctype html>
<html class="no-js" lang="en">
  <head><meta charset="utf-8"/>
    <meta name="viewport" content="width=device-width,initial-scale=1"/>
    <meta name="color-scheme" content="light dark"><meta name="generator" content="Docutils 0.19: https://docutils.sourceforge.io/" />
<link rel="index" title="Index" href="../genindex.html" /><link rel="search" title="Search" href="../search.html" /><link rel="next" title="Influence functions for data mislabeling" href="influence_synthetic.html" /><link rel="prev" title="Least Core for Data Valuation" href="least_core_basic.html" />

    <!-- Generated with Sphinx 5.3.0 and Furo 2023.03.27 -->
        <title>Influence functions for neural networks - pyDVL 0.6.1.dev0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo.css?digest=fad236701ea90a88636c2a8c73b44ae642ed2a53" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster.bundle.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-shadow.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-punk.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-noir.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-light.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/tooltipster-sideTip-borderless.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/css/micromodal.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
    <link rel="stylesheet" type="text/css" href="../_static/nbsphinx-code-cells.css" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/furo-extensions.css?digest=30d1aed668e5c3a91c3e3bf6a60b675221979f0e" />
    
    


<style>
  body {
    --color-code-background: #eeffcc;
  --color-code-foreground: black;
  
  }
  @media not print {
    body[data-theme="dark"] {
      --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
    }
    @media (prefers-color-scheme: dark) {
      body:not([data-theme="light"]) {
        --color-code-background: #202020;
  --color-code-foreground: #d0d0d0;
  
      }
    }
  }
</style></head>
  <body>
    
    <script>
      document.body.dataset.theme = localStorage.getItem("theme") || "auto";
    </script>
    

<svg xmlns="http://www.w3.org/2000/svg" style="display: none;">
  <symbol id="svg-toc" viewBox="0 0 24 24">
    <title>Contents</title>
    <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024">
      <path d="M408 442h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8zm-8 204c0 4.4 3.6 8 8 8h480c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8H408c-4.4 0-8 3.6-8 8v56zm504-486H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zm0 632H120c-4.4 0-8 3.6-8 8v56c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-56c0-4.4-3.6-8-8-8zM115.4 518.9L271.7 642c5.8 4.6 14.4.5 14.4-6.9V388.9c0-7.4-8.5-11.5-14.4-6.9L115.4 505.1a8.74 8.74 0 0 0 0 13.8z"/>
    </svg>
  </symbol>
  <symbol id="svg-menu" viewBox="0 0 24 24">
    <title>Menu</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-menu">
      <line x1="3" y1="12" x2="21" y2="12"></line>
      <line x1="3" y1="6" x2="21" y2="6"></line>
      <line x1="3" y1="18" x2="21" y2="18"></line>
    </svg>
  </symbol>
  <symbol id="svg-arrow-right" viewBox="0 0 24 24">
    <title>Expand</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather-chevron-right">
      <polyline points="9 18 15 12 9 6"></polyline>
    </svg>
  </symbol>
  <symbol id="svg-sun" viewBox="0 0 24 24">
    <title>Light mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="feather-sun">
      <circle cx="12" cy="12" r="5"></circle>
      <line x1="12" y1="1" x2="12" y2="3"></line>
      <line x1="12" y1="21" x2="12" y2="23"></line>
      <line x1="4.22" y1="4.22" x2="5.64" y2="5.64"></line>
      <line x1="18.36" y1="18.36" x2="19.78" y2="19.78"></line>
      <line x1="1" y1="12" x2="3" y2="12"></line>
      <line x1="21" y1="12" x2="23" y2="12"></line>
      <line x1="4.22" y1="19.78" x2="5.64" y2="18.36"></line>
      <line x1="18.36" y1="5.64" x2="19.78" y2="4.22"></line>
    </svg>
  </symbol>
  <symbol id="svg-moon" viewBox="0 0 24 24">
    <title>Dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-moon">
      <path stroke="none" d="M0 0h24v24H0z" fill="none" />
      <path d="M12 3c.132 0 .263 0 .393 0a7.5 7.5 0 0 0 7.92 12.446a9 9 0 1 1 -8.313 -12.454z" />
    </svg>
  </symbol>
  <symbol id="svg-sun-half" viewBox="0 0 24 24">
    <title>Auto light/dark mode</title>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" fill="none" stroke="currentColor"
      stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round" class="icon-tabler-shadow">
      <path stroke="none" d="M0 0h24v24H0z" fill="none"/>
      <circle cx="12" cy="12" r="9" />
      <path d="M13 12h5" />
      <path d="M13 15h4" />
      <path d="M13 18h1" />
      <path d="M13 9h4" />
      <path d="M13 6h1" />
    </svg>
  </symbol>
</svg>

<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation">
<input type="checkbox" class="sidebar-toggle" name="__toc" id="__toc">
<label class="overlay sidebar-overlay" for="__navigation">
  <div class="visually-hidden">Hide navigation sidebar</div>
</label>
<label class="overlay toc-overlay" for="__toc">
  <div class="visually-hidden">Hide table of contents sidebar</div>
</label>

<div class="announcement">
  <aside class="announcement-content">
     pyDVL is in an early stage of development. Expect changes to functionality and the API until version 1.0.0. 
  </aside>
</div>

<div class="page">
  <header class="mobile-header">
    <div class="header-left">
      <label class="nav-overlay-icon" for="__navigation">
        <div class="visually-hidden">Toggle site navigation sidebar</div>
        <i class="icon"><svg><use href="#svg-menu"></use></svg></i>
      </label>
    </div>
    <div class="header-center">
      <a href="../index.html"><div class="brand">pyDVL 0.6.1.dev0 documentation</div></a>
    </div>
    <div class="header-right">
      <div class="theme-toggle-container theme-toggle-header">
        <button class="theme-toggle">
          <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
          <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
          <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
          <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
        </button>
      </div>
      <label class="toc-overlay-icon toc-header-icon" for="__toc">
        <div class="visually-hidden">Toggle table of contents sidebar</div>
        <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
      </label>
    </div>
  </header>
  <aside class="sidebar-drawer">
    <div class="sidebar-container">
      
      <div class="sidebar-sticky"><a class="sidebar-brand centered" href="../index.html">
  
  <div class="sidebar-logo-container">
    <img class="sidebar-logo" src="../_static/logo.svg" alt="Logo"/>
  </div>
  
  
</a><form class="sidebar-search-container" method="get" action="../search.html" role="search">
  <input class="sidebar-search" placeholder="Search" name="q" aria-label="Search">
  <input type="hidden" name="check_keywords" value="yes">
  <input type="hidden" name="area" value="default">
</form>
<div id="searchbox"></div><div class="sidebar-scroll"><div class="sidebar-tree">
  <ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../10-getting-started.html">Getting started</a></li>
<li class="toctree-l1"><a class="reference internal" href="../20-install.html">Installing pyDVL</a></li>
<li class="toctree-l1"><a class="reference internal" href="../30-data-valuation.html">Computing data values</a></li>
<li class="toctree-l1"><a class="reference internal" href="../40-influence.html">Computing influence values</a></li>
<li class="toctree-l1 current has-children"><a class="reference internal" href="index.html">Examples</a><input checked="" class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" role="switch" type="checkbox"/><label for="toctree-checkbox-1"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="shapley_basic_spotify.html">Shapley for data valuation</a></li>
<li class="toctree-l2"><a class="reference internal" href="shapley_knn_flowers.html">KNN Shapley</a></li>
<li class="toctree-l2"><a class="reference internal" href="shapley_utility_learning.html">Data Utility Learning</a></li>
<li class="toctree-l2"><a class="reference internal" href="least_core_basic.html">Least Core for Data Valuation</a></li>
<li class="toctree-l2 current current-page"><a class="current reference internal" href="#">Influence functions for neural networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Theory-of-influence-functions-for-neural-networks">Theory of influence functions for neural networks</a></li>
<li class="toctree-l2"><a class="reference internal" href="influence_synthetic.html">Influence functions for data mislabeling</a></li>
<li class="toctree-l2"><a class="reference internal" href="influence_wine.html">Influence functions and neural networks</a></li>
</ul>
</li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1 has-children"><a class="reference internal" href="../pydvl/index.html">API Reference</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" role="switch" type="checkbox"/><label for="toctree-checkbox-2"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../pydvl/influence.html">influence</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" role="switch" type="checkbox"/><label for="toctree-checkbox-3"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/influence/conjugate_gradient.html">conjugate_gradient</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../pydvl/influence/frameworks.html">frameworks</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" role="switch" type="checkbox"/><label for="toctree-checkbox-4"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/influence/frameworks/torch_differentiable.html">torch_differentiable</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/influence/general.html">general</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/influence/linear.html">linear</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../pydvl/influence/model_wrappers.html">model_wrappers</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" role="switch" type="checkbox"/><label for="toctree-checkbox-5"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/influence/model_wrappers/torch_wrappers.html">torch_wrappers</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/influence/types.html">types</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../pydvl/reporting.html">reporting</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" role="switch" type="checkbox"/><label for="toctree-checkbox-6"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/reporting/plots.html">plots</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/reporting/scores.html">scores</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../pydvl/utils.html">utils</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" role="switch" type="checkbox"/><label for="toctree-checkbox-7"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/utils/caching.html">caching</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/utils/config.html">config</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/utils/dataset.html">dataset</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/utils/numeric.html">numeric</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../pydvl/utils/parallel.html">parallel</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" role="switch" type="checkbox"/><label for="toctree-checkbox-8"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/utils/parallel/actor.html">actor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/utils/parallel/backend.html">backend</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/utils/parallel/map_reduce.html">map_reduce</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/utils/progress.html">progress</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/utils/score.html">score</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/utils/status.html">status</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/utils/types.html">types</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/utils/utility.html">utility</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../pydvl/value.html">value</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" role="switch" type="checkbox"/><label for="toctree-checkbox-9"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l3 has-children"><a class="reference internal" href="../pydvl/value/least_core.html">least_core</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" role="switch" type="checkbox"/><label for="toctree-checkbox-10"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/least_core/common.html">common</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/least_core/montecarlo.html">montecarlo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/least_core/naive.html">naive</a></li>
</ul>
</li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../pydvl/value/loo.html">loo</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" role="switch" type="checkbox"/><label for="toctree-checkbox-11"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/loo/naive.html">naive</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/value/result.html">result</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/value/sampler.html">sampler</a></li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/value/semivalues.html">semivalues</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../pydvl/value/shapley.html">shapley</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" role="switch" type="checkbox"/><label for="toctree-checkbox-12"><div class="visually-hidden">Toggle child pages in navigation</div><i class="icon"><svg><use href="#svg-arrow-right"></use></svg></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/shapley/actor.html">actor</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/shapley/common.html">common</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/shapley/gt.html">gt</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/shapley/knn.html">knn</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/shapley/montecarlo.html">montecarlo</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/shapley/naive.html">naive</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/shapley/owen.html">owen</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/shapley/truncated.html">truncated</a></li>
<li class="toctree-l4"><a class="reference internal" href="../pydvl/value/shapley/types.html">types</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../pydvl/value/stopping.html">stopping</a></li>
</ul>
</li>
</ul>
</li>
</ul>

</div>
</div>

      </div>
      
    </div>
  </aside>
  <div class="main">
    <div class="content">
      <div class="article-container">
        <a href="#" class="back-to-top muted-link">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24">
            <path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8v12z"></path>
          </svg>
          <span>Back to top</span>
        </a>
        <div class="content-icon-container">
          
<div class="theme-toggle-container theme-toggle-content">
            <button class="theme-toggle">
              <div class="visually-hidden">Toggle Light / Dark / Auto color theme</div>
              <svg class="theme-icon-when-auto"><use href="#svg-sun-half"></use></svg>
              <svg class="theme-icon-when-dark"><use href="#svg-moon"></use></svg>
              <svg class="theme-icon-when-light"><use href="#svg-sun"></use></svg>
            </button>
          </div>
          <label class="toc-overlay-icon toc-content-icon" for="__toc">
            <div class="visually-hidden">Toggle table of contents sidebar</div>
            <i class="icon"><svg><use href="#svg-toc"></use></svg></i>
          </label>
        </div>
        <article role="main">
          <div class="admonition note">
    This page was generated from
    <a class="reference external" href="https://github.com/appliedAI-Initiative/pyDVL/blob/develop/notebooks/influence_imagenet.ipynb">notebooks/influence_imagenet.ipynb</a>
    <br>
    Interactive online version:
    <span style="white-space: nowrap;">
        <a href="https://mybinder.org/v2/gh/appliedAI-Initiative/pyDVL/develop?filepath=notebooks/influence_imagenet.ipynb">
            <img alt="Binder badge" src="https://mybinder.org/badge_logo.svg" style="vertical-align:text-bottom">
        </a>
    </span>
</div>

<style>
    .nbinput .prompt,
    .nboutput .prompt {
        display: none;
    }
    @media not print {
        [data-theme='dark'] .output_area img {
            filter: invert(0.9);
        }
        @media (prefers-color-scheme: dark) {
            :root:not([data-theme="light"]) .output_area img {
                filter: invert(0.9);
            }
        }
    }
</style><section id="Influence-functions-for-neural-networks">
<h1>Influence functions for neural networks<a class="headerlink" href="#Influence-functions-for-neural-networks" title="Permalink to this heading">#</a></h1>
<p>This notebook explores the use of influence functions for convolutional neural networks. In <a class="reference external" href="#analysing-influences">the first part</a> we will investigate the usefulness, or lack thereof, of influence functions for the interpretation of a classifier’s outputs.</p>
<p>For our study we choose a pre-trained ResNet18, fine-tuned on the <a class="reference external" href="https://huggingface.co/datasets/Maysee/tiny-imagenet">tiny-imagenet dataset</a>. This dataset was created for a Stanford course on <a class="reference external" href="http://cs231n.stanford.edu/">Deep Learning for Computer Vision</a>, and is a subset of the <a class="reference external" href="https://image-net.org/challenges/LSVRC/2012/index">famous ImageNet</a> with 200 classes instead of 1000, and images down-sampled to a lower resolution of 64x64 pixels.</p>
<p>After tuning the last layers of the network, we will use <strong>pyDVL</strong> to find the most and the least influential training images for the test set. This can sometimes be used to explain inference errors, or to direct efforts during data collection, although we will face inconclusive results with our model and data. This illustrates well-known issues of influence functions for neural networks.</p>
<p>However, in the <a class="reference external" href="#detecting-corrupted-data">final part of the notebook</a> we will see that influence functions are an effective tool for finding anomalous or corrupted data points.</p>
<p>We conclude with an <a class="reference external" href="#theory-of-influence-functions-for-neural-networks">appendix</a> with some basic theoretical concepts used.</p>
<div class="admonition note">
<p>If you are reading this in the documentation, some boilerplate has been omitted for convenience.</p>
</div>
<section id="Imports-and-setup">
<h2>Imports and setup<a class="headerlink" href="#Imports-and-setup" title="Permalink to this heading">#</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pydvl.influence.general</span> <span class="kn">import</span> <span class="n">compute_influences</span>
<span class="kn">from</span> <span class="nn">pydvl.reporting.plots</span> <span class="kn">import</span> <span class="n">plot_influence_distribution_by_label</span>
<span class="kn">from</span> <span class="nn">sklearn.metrics</span> <span class="kn">import</span> <span class="n">confusion_matrix</span><span class="p">,</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">,</span> <span class="n">f1_score</span>
</pre></div>
</div>
</div>
</section>
<section id="Loading-and-preprocessing-the-dataset">
<h2>Loading and preprocessing the dataset<a class="headerlink" href="#Loading-and-preprocessing-the-dataset" title="Permalink to this heading">#</a></h2>
<p>We pick two classes arbitrarily to work with: 90 and 100, corresponding respectively to dining tables, and boats in Venice (you can of course select any other two classes, or more of them, although that would imply longer training times and some modifications in the notebook below). The dataset is loaded with <code class="docutils literal notranslate"><span class="pre">load_preprocess_imagenet()</span></code>, which returns three pandas <code class="docutils literal notranslate"><span class="pre">DataFrames</span></code> with training, validation and test sets respectively. Each dataframe has three columns: normalized images, labels
and the original images. Note that you can load a subset of the data decreasing downsampling_ratio.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label_names</span> <span class="o">=</span> <span class="p">{</span><span class="mi">90</span><span class="p">:</span> <span class="s2">&quot;tables&quot;</span><span class="p">,</span> <span class="mi">100</span><span class="p">:</span> <span class="s2">&quot;boats&quot;</span><span class="p">}</span>
<span class="n">train_ds</span><span class="p">,</span> <span class="n">val_ds</span><span class="p">,</span> <span class="n">test_ds</span> <span class="o">=</span> <span class="n">load_preprocess_imagenet</span><span class="p">(</span>
    <span class="n">train_size</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
    <span class="n">test_size</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">keep_labels</span><span class="o">=</span><span class="n">label_names</span><span class="p">,</span>
    <span class="n">downsampling_ratio</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Normalised image dtype:&quot;</span><span class="p">,</span> <span class="n">train_ds</span><span class="p">[</span><span class="s2">&quot;normalized_images&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Label type:&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Image type:&quot;</span><span class="p">,</span> <span class="nb">type</span><span class="p">(</span><span class="n">train_ds</span><span class="p">[</span><span class="s2">&quot;images&quot;</span><span class="p">][</span><span class="mi">0</span><span class="p">]))</span>
<span class="n">train_ds</span><span class="o">.</span><span class="n">info</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Normalised image dtype: torch.float32
Label type: &lt;class &#39;str&#39;&gt;
Image type: &lt;class &#39;PIL.JpegImagePlugin.JpegImageFile&#39;&gt;
&lt;class &#39;pandas.core.frame.DataFrame&#39;&gt;
RangeIndex: 707 entries, 0 to 706
Data columns (total 3 columns):
 #   Column             Non-Null Count  Dtype
---  ------             --------------  -----
 0   normalized_images  707 non-null    object
 1   labels             707 non-null    object
 2   images             707 non-null    object
dtypes: object(3)
memory usage: 16.7+ KB
</pre></div></div>
</div>
<p>Let’s take a closer look at a few image samples</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_sample_images</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">n_images_per_class</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_influence_imagenet_9_0.png" src="../_images/examples_influence_imagenet_9_0.png" />
</div>
</div>
<p>Let’s now further pre-process the data and prepare for model training. The helper function <code class="docutils literal notranslate"><span class="pre">process_io</span></code> converts the normalized images into tensors and the labels to the indices 0 and 1 to train the classifier.</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Tuple</span>


<span class="k">def</span> <span class="nf">process_io</span><span class="p">(</span><span class="n">df</span><span class="p">:</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">,</span> <span class="n">labels</span><span class="p">:</span> <span class="nb">dict</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;normalized_images&quot;</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span>
    <span class="n">ds_label_to_model_label</span> <span class="o">=</span> <span class="p">{</span>
        <span class="n">ds_label</span><span class="p">:</span> <span class="n">idx</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">ds_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">labels</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
    <span class="p">}</span>
    <span class="n">x_nn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">tolist</span><span class="p">())</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="n">y_nn</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="n">ds_label_to_model_label</span><span class="p">[</span><span class="n">yi</span><span class="p">]</span> <span class="k">for</span> <span class="n">yi</span> <span class="ow">in</span> <span class="n">y</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">DEVICE</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x_nn</span><span class="p">,</span> <span class="n">y_nn</span>


<span class="n">train_x</span><span class="p">,</span> <span class="n">train_y</span> <span class="o">=</span> <span class="n">process_io</span><span class="p">(</span><span class="n">train_ds</span><span class="p">,</span> <span class="n">label_names</span><span class="p">)</span>
<span class="n">val_x</span><span class="p">,</span> <span class="n">val_y</span> <span class="o">=</span> <span class="n">process_io</span><span class="p">(</span><span class="n">val_ds</span><span class="p">,</span> <span class="n">label_names</span><span class="p">)</span>
<span class="n">test_x</span><span class="p">,</span> <span class="n">test_y</span> <span class="o">=</span> <span class="n">process_io</span><span class="p">(</span><span class="n">test_ds</span><span class="p">,</span> <span class="n">label_names</span><span class="p">)</span>
</pre></div>
</div>
</div>
</section>
<section id="Model-definition-and-training">
<h2>Model definition and training<a class="headerlink" href="#Model-definition-and-training" title="Permalink to this heading">#</a></h2>
<p>We use a ResNet18 from <code class="docutils literal notranslate"><span class="pre">torchvision</span></code> with final layers modified for binary classification.</p>
<p>Training for influence computation is facilitated by <code class="docutils literal notranslate"><span class="pre">:class:~pydvl.influence.model_wrappers.torch_wrappers.TorchModel</span></code>, a convenience wrapper around torch models which is part of pyDVL. We wrap this with a simple class <code class="docutils literal notranslate"><span class="pre">TrainingManager</span></code> which transparently handles persistence after training. The latter is not part of the main pyDVL package but just a way to reduce clutter in this notebook.</p>
<p>We train the model for 50 epochs and save the results. Then we plot the train and validation loss curves.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">model_ft</span> <span class="o">=</span> <span class="n">new_resnet_model</span><span class="p">(</span><span class="n">output_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">label_names</span><span class="p">))</span>
<span class="n">mgr</span> <span class="o">=</span> <span class="n">TrainingManager</span><span class="p">(</span>
    <span class="s2">&quot;model_ft&quot;</span><span class="p">,</span>
    <span class="n">model_ft</span><span class="p">,</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(),</span>
    <span class="n">train_x</span><span class="p">,</span>
    <span class="n">train_y</span><span class="p">,</span>
    <span class="n">val_x</span><span class="p">,</span>
    <span class="n">val_y</span><span class="p">,</span>
    <span class="n">MODEL_PATH</span><span class="p">,</span>
<span class="p">)</span>
<span class="c1"># Set use_cache=False to retrain the model</span>
<span class="n">train_loss</span><span class="p">,</span> <span class="n">val_loss</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Cached model found, loading...
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[8]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_losses</span><span class="p">(</span><span class="n">train_loss</span><span class="p">,</span> <span class="n">val_loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_influence_imagenet_14_0.png" src="../_images/examples_influence_imagenet_14_0.png" />
</div>
</div>
<p>The confusion matrix and <span class="math notranslate nohighlight">\(F_1\)</span> score look good, especially considering the low resolution of the images and their complexity (they contain different objects)</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred_y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model_ft</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_score</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">test_y</span><span class="p">,</span> <span class="n">pred_y_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>

<span class="n">cm</span> <span class="o">=</span> <span class="n">confusion_matrix</span><span class="p">(</span><span class="n">test_y</span><span class="p">,</span> <span class="n">pred_y_test</span><span class="p">)</span>
<span class="n">disp</span> <span class="o">=</span> <span class="n">ConfusionMatrixDisplay</span><span class="p">(</span><span class="n">confusion_matrix</span><span class="o">=</span><span class="n">cm</span><span class="p">,</span> <span class="n">display_labels</span><span class="o">=</span><span class="n">label_names</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;f1_score of model:&quot;</span><span class="p">,</span> <span class="n">model_score</span><span class="p">)</span>
<span class="n">disp</span><span class="o">.</span><span class="n">plot</span><span class="p">();</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
f1_score of model: 0.8468272032336833
</pre></div></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_influence_imagenet_16_1.png" src="../_images/examples_influence_imagenet_16_1.png" />
</div>
</div>
</section>
<section id="Influence-computation">
<h2>Influence computation<a class="headerlink" href="#Influence-computation" title="Permalink to this heading">#</a></h2>
<p>Let’s now calculate influences! The main method is <code class="docutils literal notranslate"><span class="pre">:func:~pydvl.influence.general.compute_influences</span></code>, which takes a trained <code class="docutils literal notranslate"><span class="pre">nn.Model</span></code>, the training loss, some input dataset with labels (which typically is the training data, or a subset of it) and some test data.</p>
<p>Other important parameters are the Hessian regularization term, which should be chosen as small as possible for the computation to converge (further details on why this is important can be found in the <a class="reference external" href="#appendix">Appendix</a>).</p>
<p>Since Resnet18 is quite big, we pick conjugate gradient (<code class="docutils literal notranslate"><span class="pre">cg</span></code>) as the method for inversion of the Hessian. A naive computation would require a lot of memory. Finally, the influence type will be <code class="docutils literal notranslate"><span class="pre">up</span></code>. The other option, <code class="docutils literal notranslate"><span class="pre">perturbation</span></code>, is beyond the scope of this notebook, but more info can be found in the notebook <a class="reference internal" href="influence_wine.html"><span class="doc">using the Wine dataset</span></a> or in the documentation for pyDVL.</p>
<p>The output of <code class="docutils literal notranslate"><span class="pre">calculate_influences</span></code> is a matrix of size <code class="docutils literal notranslate"><span class="pre">test_set_length</span></code> x <code class="docutils literal notranslate"><span class="pre">training_set_length</span></code>. Each row represents a test data point, and each column a training data point, so that entry <span class="math notranslate nohighlight">\((i,j)\)</span> represents the influence of training point <span class="math notranslate nohighlight">\(j\)</span> on test point <span class="math notranslate nohighlight">\(i\)</span>.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[10]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">influences</span> <span class="o">=</span> <span class="n">compute_influences</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">mgr</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">mgr</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="n">train_x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">train_y</span><span class="p">,</span>
    <span class="n">x_test</span><span class="o">=</span><span class="n">test_x</span><span class="p">,</span>
    <span class="n">y_test</span><span class="o">=</span><span class="n">test_y</span><span class="p">,</span>
    <span class="n">hessian_regularization</span><span class="o">=</span><span class="n">hessian_reg</span><span class="p">,</span>
    <span class="n">inversion_method</span><span class="o">=</span><span class="s2">&quot;cg&quot;</span><span class="p">,</span>
    <span class="n">influence_type</span><span class="o">=</span><span class="s2">&quot;up&quot;</span><span class="p">,</span>
    <span class="n">progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "eb973044c7634b2eb8ca3a1bc0b1a79f", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "a56ca4bccb724034a58eb32c2dd08859", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "ddb9905c50c54ff7b8beab0d52e0e4da", "version_major": 2, "version_minor": 0}</script></div>
</div>
</section>
<section id="Analysing-influences">
<h2>Analysing influences<a class="headerlink" href="#Analysing-influences" title="Permalink to this heading">#</a></h2>
<p>With the computed influences we can study single images or all of them together:</p>
<section id="Influence-on-a-single-test-image">
<h3>Influence on a single test image<a class="headerlink" href="#Influence-on-a-single-test-image" title="Permalink to this heading">#</a></h3>
<p>Let’s take any image in the test set:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[11]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">test_image_idx</span> <span class="o">=</span> <span class="mi">42</span>

<span class="n">model_label_to_ds_label</span> <span class="o">=</span> <span class="p">{</span>
    <span class="n">idx</span><span class="p">:</span> <span class="n">ds_label</span> <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="n">ds_label</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">label_names</span><span class="o">.</span><span class="n">values</span><span class="p">())</span>
<span class="p">}</span>
<span class="n">predicted_label</span> <span class="o">=</span> <span class="n">model_label_to_ds_label</span><span class="p">[</span>
    <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">model_ft</span><span class="p">(</span><span class="n">test_x</span><span class="p">[</span><span class="n">test_image_idx</span><span class="p">]</span><span class="o">.</span><span class="n">unsqueeze</span><span class="p">(</span><span class="mi">0</span><span class="p">))</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
<span class="p">]</span>
<span class="n">true_label</span> <span class="o">=</span> <span class="n">test_ds</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">][</span><span class="n">test_image_idx</span><span class="p">]</span>

<span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">3</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">test_ds</span><span class="p">[</span><span class="s2">&quot;images&quot;</span><span class="p">][</span><span class="n">test_image_idx</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">axis</span><span class="p">(</span><span class="s2">&quot;off&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Predicted: </span><span class="si">{</span><span class="n">predicted_label</span><span class="si">}</span><span class="s2"> - True: </span><span class="si">{</span><span class="n">true_label</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_influence_imagenet_20_0.png" src="../_images/examples_influence_imagenet_20_0.png" />
</div>
</div>
<p>Now we plot the histogram of the influence that all training images have on the image selected above, separated by their label.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[12]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plt</span><span class="o">.</span><span class="n">rcParams</span><span class="p">[</span><span class="s2">&quot;figure.figsize&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="n">default_figsize</span>
<span class="n">plot_influence_distribution_by_label</span><span class="p">(</span>
    <span class="n">influences</span><span class="p">[</span><span class="n">test_image_idx</span><span class="p">],</span>
    <span class="n">train_ds</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span>
    <span class="n">title_extra</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;over index </span><span class="si">{</span><span class="n">test_image_idx</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_influence_imagenet_22_0.png" src="../_images/examples_influence_imagenet_22_0.png" />
</div>
</div>
<p>Rather unsurprisingly, the training samples that have the same label as the test image have, on average, a higher influence on the classifier’s output for it. Let’s then take them and visualize those with the highest and lowest influence:</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[13]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">images_with_same_label</span> <span class="o">=</span> <span class="n">train_ds</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">test_ds</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">][</span><span class="n">test_image_idx</span><span class="p">]</span>
<span class="n">influence_values_with_same_label</span> <span class="o">=</span> <span class="n">influences</span><span class="p">[</span><span class="n">test_image_idx</span><span class="p">][</span><span class="n">images_with_same_label</span><span class="p">]</span>
<span class="n">images_same_label</span> <span class="o">=</span> <span class="n">train_ds</span><span class="p">[</span><span class="s2">&quot;images&quot;</span><span class="p">][</span><span class="n">images_with_same_label</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">plot_lowest_highest_influence_images</span><span class="p">(</span>
    <span class="n">influence_values_with_same_label</span><span class="p">,</span> <span class="n">subset_images</span><span class="o">=</span><span class="n">images_same_label</span><span class="p">,</span> <span class="n">num_to_plot</span><span class="o">=</span><span class="mi">3</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_influence_imagenet_24_0.png" src="../_images/examples_influence_imagenet_24_0.png" />
</div>
</div>
<p>Looking at the images, it is difficult to explain why those on the right are more influential than those on the left. At first sight, the choice seems to be random (or at the very least noisy). Let’s dig in a bit more by looking at average influences:</p>
</section>
<section id="Analysing-the-average-influence-on-test-samples">
<h3>Analysing the average influence on test samples<a class="headerlink" href="#Analysing-the-average-influence-on-test-samples" title="Permalink to this heading">#</a></h3>
<p>By averaging across the rows of the influence matrix, we obtain the average influence of each training sample on the whole test set:</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">avg_influences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">influences</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>Once again, let’s plot the histogram of influence values by label.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[15]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_influence_distribution_by_label</span><span class="p">(</span>
    <span class="n">avg_influences</span><span class="p">,</span> <span class="n">train_ds</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span><span class="o">.</span><span class="n">values</span><span class="p">,</span> <span class="s2">&quot;over all test samples&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_influence_imagenet_29_0.png" src="../_images/examples_influence_imagenet_29_0.png" />
</div>
</div>
<p>Next, for each class (you can change value by changing label key) we can have a look at the top and bottom images by average influence, i.e. we can show the images that have the highest and lowest average influence over all test images.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[16]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;tables&quot;</span>
<span class="n">img_with_selected_label</span> <span class="o">=</span> <span class="n">train_ds</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">label</span>
<span class="n">if_selected_label</span> <span class="o">=</span> <span class="n">avg_influences</span><span class="p">[</span><span class="n">img_with_selected_label</span><span class="p">]</span>
<span class="n">imges_same_label</span> <span class="o">=</span> <span class="n">train_ds</span><span class="p">[</span><span class="s2">&quot;images&quot;</span><span class="p">][</span><span class="n">img_with_selected_label</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">plot_lowest_highest_influence_images</span><span class="p">(</span><span class="n">if_selected_label</span><span class="p">,</span> <span class="n">imges_same_label</span><span class="p">,</span> <span class="n">num_to_plot</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_influence_imagenet_31_0.png" src="../_images/examples_influence_imagenet_31_0.png" />
</div>
</div>
<p>Once again, it is not easy to explain why the images on the left have a lower influence than the ones on the right. One could argue that in order to predict that there is a dining table in the image it is beneficial to clearly see both the chairs and the table itself, a feature missing in some samples on the left. Also, color seems to be a discriminant: houses with a blue painting could get confused with the water around a boat. Of course, this is debatable and different people could come up
with other explanations <em>a posteriori</em>.</p>
</section>
</section>
<section id="Detecting-corrupted-data">
<h2>Detecting corrupted data<a class="headerlink" href="#Detecting-corrupted-data" title="Permalink to this heading">#</a></h2>
<p>After facing the shortcomings of influence functions for explaining decisions, we move to an application with clear-cut results. Influences can be successfully used to detect corrupted or mislabeled samples, making them an effective tool to “debug” training data.</p>
<p>We begin by training a new model (with the same architecture as before) on a dataset with some corrupted labels. The method <code class="docutils literal notranslate"><span class="pre">get_corrupted_imagenet</span></code> will take the training dataset and corrupt a certain fraction of the labels by flipping them. We use the same number of epochs and optimizer as before.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[17]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">corrupted_model</span> <span class="o">=</span> <span class="n">new_resnet_model</span><span class="p">(</span><span class="n">output_size</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">label_names</span><span class="p">))</span>
<span class="n">corrupted_dataset</span><span class="p">,</span> <span class="n">corrupted_indices</span> <span class="o">=</span> <span class="n">corrupt_imagenet</span><span class="p">(</span>
    <span class="n">dataset</span><span class="o">=</span><span class="n">train_ds</span><span class="p">,</span>
    <span class="n">fraction_to_corrupt</span><span class="o">=</span><span class="mf">0.1</span><span class="p">,</span>
    <span class="n">avg_influences</span><span class="o">=</span><span class="n">avg_influences</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">corrupted_train_x</span><span class="p">,</span> <span class="n">corrupted_train_y</span> <span class="o">=</span> <span class="n">process_io</span><span class="p">(</span><span class="n">corrupted_dataset</span><span class="p">,</span> <span class="n">label_names</span><span class="p">)</span>

<span class="n">mgr</span> <span class="o">=</span> <span class="n">TrainingManager</span><span class="p">(</span>
    <span class="s2">&quot;corrupted_model&quot;</span><span class="p">,</span>
    <span class="n">corrupted_model</span><span class="p">,</span>
    <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">(),</span>
    <span class="n">corrupted_train_x</span><span class="p">,</span>
    <span class="n">corrupted_train_y</span><span class="p">,</span>
    <span class="n">val_x</span><span class="p">,</span>
    <span class="n">val_y</span><span class="p">,</span>
    <span class="n">MODEL_PATH</span><span class="p">,</span>
<span class="p">)</span>
<span class="n">training_loss</span><span class="p">,</span> <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">mgr</span><span class="o">.</span><span class="n">train</span><span class="p">(</span><span class="n">n_epochs</span><span class="o">=</span><span class="mi">50</span><span class="p">,</span> <span class="n">use_cache</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
Cached model found, loading...
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[18]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_losses</span><span class="p">(</span><span class="n">training_loss</span><span class="p">,</span> <span class="n">validation_loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_influence_imagenet_35_0.png" src="../_images/examples_influence_imagenet_35_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[19]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">pred_y_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">corrupted_model</span><span class="p">(</span><span class="n">test_x</span><span class="p">)</span><span class="o">.</span><span class="n">detach</span><span class="p">(),</span> <span class="n">axis</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
<span class="n">model_score</span> <span class="o">=</span> <span class="n">f1_score</span><span class="p">(</span><span class="n">test_y</span><span class="p">,</span> <span class="n">pred_y_test</span><span class="p">,</span> <span class="n">average</span><span class="o">=</span><span class="s2">&quot;weighted&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;F1 score of model with corrupted data:&quot;</span><span class="p">,</span> <span class="n">model_score</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<div class="highlight"><pre>
F1 score of model with corrupted data: 0.8164795918367347
</pre></div></div>
</div>
<p>Interestingly, despite being trained on a corrupted dataset, the model has a fairly high <span class="math notranslate nohighlight">\(F_1\)</span> score. Let’s now calculate the influence of the corrupted training data points over the test data points.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[20]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">influences</span> <span class="o">=</span> <span class="n">compute_influences</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">mgr</span><span class="o">.</span><span class="n">model</span><span class="p">,</span>
    <span class="n">loss</span><span class="o">=</span><span class="n">mgr</span><span class="o">.</span><span class="n">loss</span><span class="p">,</span>
    <span class="n">x</span><span class="o">=</span><span class="n">corrupted_train_x</span><span class="p">,</span>
    <span class="n">y</span><span class="o">=</span><span class="n">corrupted_train_y</span><span class="p">,</span>
    <span class="n">x_test</span><span class="o">=</span><span class="n">test_x</span><span class="p">,</span>
    <span class="n">y_test</span><span class="o">=</span><span class="n">test_y</span><span class="p">,</span>
    <span class="n">hessian_regularization</span><span class="o">=</span><span class="n">hessian_reg</span><span class="p">,</span>
    <span class="n">inversion_method</span><span class="o">=</span><span class="s2">&quot;cg&quot;</span><span class="p">,</span>
    <span class="n">influence_type</span><span class="o">=</span><span class="s2">&quot;up&quot;</span><span class="p">,</span>
    <span class="n">progress</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "06237dca13474cc1afcc66220191cf33", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "1660a4cbe6d6453f8ad8a051431c7778", "version_major": 2, "version_minor": 0}</script></div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<script type="application/vnd.jupyter.widget-view+json">{"model_id": "7c268d8c428c4317b4a8faf2dafa84a3", "version_major": 2, "version_minor": 0}</script></div>
</div>
<p>As before, since we are interested in the average influence on the test dataset, we take the average of influences across rows, and then plot the highest and lowest influences for a chosen label</p>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[21]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">avg_corrupted_influences</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">influences</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[22]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">label</span> <span class="o">=</span> <span class="s2">&quot;boats&quot;</span>
<span class="n">img_with_selected_label</span> <span class="o">=</span> <span class="n">corrupted_dataset</span><span class="p">[</span><span class="s2">&quot;labels&quot;</span><span class="p">]</span> <span class="o">==</span> <span class="n">label</span>
<span class="n">if_selected_label</span> <span class="o">=</span> <span class="n">avg_corrupted_influences</span><span class="p">[</span><span class="n">img_with_selected_label</span><span class="p">]</span>
<span class="n">imges_same_label</span> <span class="o">=</span> <span class="n">corrupted_dataset</span><span class="p">[</span><span class="s2">&quot;images&quot;</span><span class="p">][</span><span class="n">img_with_selected_label</span><span class="p">]</span><span class="o">.</span><span class="n">values</span>
<span class="n">plot_lowest_highest_influence_images</span><span class="p">(</span><span class="n">if_selected_label</span><span class="p">,</span> <span class="n">imges_same_label</span><span class="p">,</span> <span class="n">num_to_plot</span><span class="o">=</span><span class="mi">3</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_influence_imagenet_41_0.png" src="../_images/examples_influence_imagenet_41_0.png" />
</div>
</div>
<p>As expected, the samples with lowest (negative) influence for the label “boats” are those that have been corrupted: all the images on the left are tables! We can compare the average influence of corrupted data with non-corrupted ones</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[23]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">plot_corrupted_influences_distribution</span><span class="p">(</span>
    <span class="n">corrupted_dataset</span><span class="p">,</span> <span class="n">corrupted_indices</span><span class="p">,</span> <span class="n">avg_corrupted_influences</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../_images/examples_influence_imagenet_43_0.png" src="../_images/examples_influence_imagenet_43_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">compute_mean_corrupted_influences</span><span class="p">(</span>
    <span class="n">corrupted_dataset</span><span class="p">,</span> <span class="n">corrupted_indices</span><span class="p">,</span> <span class="n">avg_corrupted_influences</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[24]:
</pre></div>
</div>
<div class="output_area rendered_html docutils container">
<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>label</th>
      <th>avg_non_corrupted_infl</th>
      <th>avg_corrupted_infl</th>
      <th>score_diff</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>boats</td>
      <td>0.945390</td>
      <td>-0.890972</td>
      <td>1.836362</td>
    </tr>
    <tr>
      <th>1</th>
      <td>tables</td>
      <td>-1.092637</td>
      <td>-2.757206</td>
      <td>1.664569</td>
    </tr>
  </tbody>
</table>
</div></div>
</div>
<p>And indeed corrupted data have a more negative influence on average than clean ones!</p>
<p>Despite this being a useful property, influence functions are known to be unreliable for tasks of data valuation, especially in deep learning where the fundamental assumption of the theory (convexity) is grossly violated. A lot of factors (e.g. the size of the network, the training process or the Hessian regularization term) can interfere with the computation, to the point that often the results that we obtain cannot be trusted. This has been extensively studied in the recent paper:</p>
<p><em>Basu, S., P. Pope, and S. Feizi.</em><a class="reference external" href="https://par.nsf.gov/servlets/purl/10315557">Influence Functions in Deep Learning Are Fragile.</a><em>International Conference on Learning Representations (ICLR). 2021</em>.</p>
<p>Nevertheless, influence functions offer a relatively quick and mathematically rigorous way to evaluate (at first order) the importance of a training point for a model’s prediction.</p>
</section>
</section>
<section id="Theory-of-influence-functions-for-neural-networks">
<h1>Theory of influence functions for neural networks<a class="headerlink" href="#Theory-of-influence-functions-for-neural-networks" title="Permalink to this heading">#</a></h1>
<p>In this appendix we will briefly go through the basic ideas of influence functions adapted for neural networks as introduced in <em>Koh, Pang Wei, and Percy Liang.</em><a class="reference external" href="https://arxiv.org/pdf/1703.04730.pdf">“Understanding Black-box Predictions via Influence Functions”</a><em>International conference on machine learning. PMLR, 2017.</em></p>
<p>Note however that this paper departs from the standard and established theory and notation for influence functions. For a rigorous introduction to the topic we recommend classical texts like <em>Hampel, Frank R., Elvezio M. Ronchetti, Peter J. Rousseeuw, and Werner A. Stahel. Robust Statistics: The Approach Based on Influence Functions. 1st edition. Wiley Series in Probability and Statistics. New York: Wiley-Interscience, 2005. https://doi.org/10.1002/9781118186435.</em></p>
<section id="Upweighting-points">
<h2>Upweighting points<a class="headerlink" href="#Upweighting-points" title="Permalink to this heading">#</a></h2>
<p>Let’s start by considering some input space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> to a model (e.g. images) and an output space <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> (e.g. labels). Let’s take <span class="math notranslate nohighlight">\(z_i = (x_i, y_i)\)</span> to be the <span class="math notranslate nohighlight">\(i\)</span>-th training point, and <span class="math notranslate nohighlight">\(\theta\)</span> to be the (potentially highly) multi-dimensional parameters of the neural network (i.e. <span class="math notranslate nohighlight">\(\theta\)</span> is a big array with very many parameters). We will indicate with <span class="math notranslate nohighlight">\(L(z, \theta)\)</span> the loss of the model for point <span class="math notranslate nohighlight">\(z\)</span> and parameters <span class="math notranslate nohighlight">\(\theta\)</span>.
When training the model we minimize the loss over all points, i.e. the optimal parameters are calculated through gradient descent on the following formula:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\hat{\theta} = \arg \min_\theta \frac{1}{n}\sum_{i=1}^n L(z_i, \theta)\]</div>
</div>
<p>where <span class="math notranslate nohighlight">\(n\)</span> is the total number of training data points.</p>
<p>For notational convenience, let’s define</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\hat{\theta}_{-z} = \arg \min_\theta \frac{1}{n}\sum_{z_i \ne z} L(z_i, \theta) \ ,\]</div>
</div>
<p>i.e. <span class="math notranslate nohighlight">\(\hat{\theta}_{-z}\)</span> are the model parameters that minimize the total loss when <span class="math notranslate nohighlight">\(z\)</span> is not in the training dataset.</p>
<p>In order to check the impact of each training point on the model, we would need to calculate <span class="math notranslate nohighlight">\(\hat{\theta}_{-z}\)</span> for each <span class="math notranslate nohighlight">\(z\)</span> in the training dataset, thus re-training the model at least ~<span class="math notranslate nohighlight">\(n\)</span> times (more if model training is noisy). This is computationally very expensive, especially for big neural networks. To circumvent this problem, we can just calculate a first order approximation of <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>. This can be done through single backpropagation and without
re-training the full model.</p>
<p>Let’s define</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\hat{\theta}_{\epsilon, z} = \arg \min_\theta \frac{1}{n}\sum_{i=1}^n L(z_i, \theta) + \epsilon L(z, \theta) \ ,\]</div>
</div>
<p>which is the optimal <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> if we were to up-weigh <span class="math notranslate nohighlight">\(z\)</span> by an amount <span class="math notranslate nohighlight">\(\epsilon\)</span>.</p>
<p>From a classical result (a simple derivation is available in Appendix A of Koh and Liang’s paper), we know that:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\frac{d \ \hat{\theta}_{\epsilon, z}}{d \epsilon} \Big|_{\epsilon=0} = -H_{\hat{\theta}}^{-1} \nabla_\theta L(z, \hat{\theta})\]</div>
</div>
<p>where <span class="math notranslate nohighlight">\(H_{\hat{\theta}} = \frac{1}{n} \sum_{i=1}^n \nabla_\theta^2 L(z_i, \hat{\theta})\)</span> is the Hessian of <span class="math notranslate nohighlight">\(L\)</span>. Importantly, notice that this expression is only valid when <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is a minimum of <span class="math notranslate nohighlight">\(L\)</span>, or otherwise <span class="math notranslate nohighlight">\(H_{\hat{\theta}}\)</span> cannot be inverted!</p>
</section>
<section id="Approximating-the-influence-of-a-point">
<h2>Approximating the influence of a point<a class="headerlink" href="#Approximating-the-influence-of-a-point" title="Permalink to this heading">#</a></h2>
<p>We will define the influence of training point <span class="math notranslate nohighlight">\(z\)</span> on test point <span class="math notranslate nohighlight">\(z_{\text{test}}\)</span> as <span class="math notranslate nohighlight">\(\mathcal{I}(z, z_{\text{test}}) = L(z_{\text{test}}, \hat{\theta}_{-z}) - L(z_{\text{test}}, \hat{\theta})\)</span> (notice that it is higher for points <span class="math notranslate nohighlight">\(z\)</span> which positively impact the model score, since if they are excluded, the loss is higher). In practice, however, we will always use the infinitesimal approximation <span class="math notranslate nohighlight">\(\mathcal{I}_{up}(z, z_{\text{test}})\)</span>, defined as</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\mathcal{I}_{up}(z, z_{\text{test}}) = - \frac{d L(z_{\text{test}}, \hat{\theta}_{\epsilon, z})}{d \epsilon} \Big|_{\epsilon=0}\]</div>
</div>
<p>Using the chain rule and the results calculated above, we thus have:</p>
<div class="math-wrapper docutils container">
<div class="math notranslate nohighlight">
\[\mathcal{I}_{up}(z, z_{\text{test}}) = - \nabla_\theta L(z_{\text{test}}, \hat{\theta})^\top \ \frac{d \hat{\theta}_{\epsilon, z}}{d \epsilon} \Big|_{\epsilon=0} = \nabla_\theta L(z_{\text{test}}, \hat{\theta})^\top \ H_{\hat{\theta}}^{-1} \ \nabla_\theta L(z, \hat{\theta})\]</div>
</div>
<p>In order to calculate this expression we need the gradient and the Hessian of the loss wrt. the model parameters <span class="math notranslate nohighlight">\(\hat{\theta}\)</span>. This can be easily done through a single backpropagation pass.</p>
</section>
<section id="Regularizing-the-Hessian">
<h2>Regularizing the Hessian<a class="headerlink" href="#Regularizing-the-Hessian" title="Permalink to this heading">#</a></h2>
<p>One very important assumption that we make when approximating influence is that <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> is at least a local minimum of the loss. However, we clearly cannot guarantee this except for convex models, and despite good apparent convergence, <span class="math notranslate nohighlight">\(\hat{\theta}\)</span> might be located in a region with flat curvature or close to a saddle point. In particular, the Hessian might have vanishing eigenvalues making its direct inversion impossible.</p>
<p>To circumvent this problem, instead of inverting the true Hessian <span class="math notranslate nohighlight">\(H_{\hat{\theta}}\)</span>, one can invert a small perturbation thereof: <span class="math notranslate nohighlight">\(H_{\hat{\theta}} + \lambda \mathbb{I}\)</span>, with <span class="math notranslate nohighlight">\(\mathbb{I}\)</span> being the identity matrix. This standard trick ensures that the eigenvalues of <span class="math notranslate nohighlight">\(H_{\hat{\theta}}\)</span> are bounded away from zero and therefore the matrix is invertible. In order for this regularization not to corrupt the outcome too much, the parameter <span class="math notranslate nohighlight">\(\lambda\)</span> should be as small as
possible while still allowing a reliable inversion of <span class="math notranslate nohighlight">\(H_{\hat{\theta}} + \lambda \mathbb{I}\)</span>.</p>
</section>
</section>

        </article>
      </div>
      <footer>
        
        <div class="related-pages">
          <a class="next-page" href="influence_synthetic.html">
              <div class="page-info">
                <div class="context">
                  <span>Next</span>
                </div>
                <div class="title">Influence functions for data mislabeling</div>
              </div>
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
            </a>
          <a class="prev-page" href="least_core_basic.html">
              <svg class="furo-related-icon"><use href="#svg-arrow-right"></use></svg>
              <div class="page-info">
                <div class="context">
                  <span>Previous</span>
                </div>
                
                <div class="title">Least Core for Data Valuation</div>
                
              </div>
            </a>
        </div>
        <div class="bottom-of-page">
          <div class="left-details">
            <div class="copyright">
                Copyright &#169; AppliedAI Institute gGmbH
            </div>
            Made with <a href="https://www.sphinx-doc.org/">Sphinx</a> and <a class="muted-link" href="https://pradyunsg.me">@pradyunsg</a>'s
            
            <a href="https://github.com/pradyunsg/furo">Furo</a>
            
          </div>
          <div class="right-details">
            <div class="icons">
              <a class="muted-link " href="https://github.com/appliedAI-Initiative/pyDVL" aria-label="GitHub">
                <svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16">
                    <path fill-rule="evenodd" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.013 8.013 0 0 0 16 8c0-4.42-3.58-8-8-8z"></path>
                </svg>
            </a>
              
            </div>
          </div>
        </div>
        
      </footer>
    </div>
    <aside class="toc-drawer">
      
      
      <div class="toc-sticky toc-scroll">
        <div class="toc-title-container">
          <span class="toc-title">
            On this page
          </span>
        </div>
        <div class="toc-tree-container">
          <div class="toc-tree">
            <ul>
<li><a class="reference internal" href="#">Influence functions for neural networks</a><ul>
<li><a class="reference internal" href="#Imports-and-setup">Imports and setup</a></li>
<li><a class="reference internal" href="#Loading-and-preprocessing-the-dataset">Loading and preprocessing the dataset</a></li>
<li><a class="reference internal" href="#Model-definition-and-training">Model definition and training</a></li>
<li><a class="reference internal" href="#Influence-computation">Influence computation</a></li>
<li><a class="reference internal" href="#Analysing-influences">Analysing influences</a><ul>
<li><a class="reference internal" href="#Influence-on-a-single-test-image">Influence on a single test image</a></li>
<li><a class="reference internal" href="#Analysing-the-average-influence-on-test-samples">Analysing the average influence on test samples</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Detecting-corrupted-data">Detecting corrupted data</a></li>
</ul>
</li>
<li><a class="reference internal" href="#Theory-of-influence-functions-for-neural-networks">Theory of influence functions for neural networks</a><ul>
<li><a class="reference internal" href="#Upweighting-points">Upweighting points</a></li>
<li><a class="reference internal" href="#Approximating-the-influence-of-a-point">Approximating the influence of a point</a></li>
<li><a class="reference internal" href="#Regularizing-the-Hessian">Regularizing the Hessian</a></li>
</ul>
</li>
</ul>

          </div>
        </div>
      </div>
      
      
    </aside>
  </div>
</div><script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/sphinx_highlight.js"></script>
    <script src="../_static/scripts/furo.js"></script>
    <script src="../_static/js/hoverxref.js"></script>
    <script src="../_static/js/tooltipster.bundle.min.js"></script>
    <script src="../_static/js/micromodal.min.js"></script>
    <script src="../_static/design-tabs.js"></script>
    <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>window.MathJax = {"tex": {"inlineMath": [["\\(", "\\)"]], "processEscapes": true, "displayMath": [["\\[", "\\]"]]}, "options": {"ignoreHtmlClass": "tex2jax_ignore|mathjax_ignore|document", "processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    </body>
</html>